{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%pip install watermark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylnIzVfhVxEg",
        "outputId": "f73dc2d4-abb4-4823-8a56-407d5b5a5dae"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting watermark\n",
            "  Downloading watermark-2.5.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: ipython>=6.0 in /usr/local/lib/python3.12/dist-packages (from watermark) (7.34.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /usr/local/lib/python3.12/dist-packages (from watermark) (8.7.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from watermark) (75.2.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib-metadata>=1.4->watermark) (3.23.0)\n",
            "Collecting jedi>=0.16 (from ipython>=6.0->watermark)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=6.0->watermark) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=6.0->watermark) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.0->watermark) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.0->watermark) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=6.0->watermark) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=6.0->watermark) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.12/dist-packages (from ipython>=6.0->watermark) (0.1.7)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=6.0->watermark) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=6.0->watermark) (0.8.4)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=6.0->watermark) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=6.0->watermark) (0.2.13)\n",
            "Downloading watermark-2.5.0-py2.py3-none-any.whl (7.7 kB)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi, watermark\n",
            "Successfully installed jedi-0.19.2 watermark-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext watermark"
      ],
      "metadata": {
        "id": "ybbG3EUrhj3N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!lscpu"
      ],
      "metadata": {
        "id": "LElcNuMDiwsV",
        "outputId": "26a0fdb9-3bad-4030-c6a2-458a0b6ebc08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Architecture:             x86_64\n",
            "  CPU op-mode(s):         32-bit, 64-bit\n",
            "  Address sizes:          46 bits physical, 48 bits virtual\n",
            "  Byte Order:             Little Endian\n",
            "CPU(s):                   2\n",
            "  On-line CPU(s) list:    0,1\n",
            "Vendor ID:                GenuineIntel\n",
            "  Model name:             Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "    CPU family:           6\n",
            "    Model:                85\n",
            "    Thread(s) per core:   2\n",
            "    Core(s) per socket:   1\n",
            "    Socket(s):            1\n",
            "    Stepping:             3\n",
            "    BogoMIPS:             4000.31\n",
            "    Flags:                fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge m\n",
            "                          ca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht sysc\n",
            "                          all nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xt\n",
            "                          opology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq\n",
            "                           ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt\n",
            "                           aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dno\n",
            "                          wprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase\n",
            "                           tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm m\n",
            "                          px avx512f avx512dq rdseed adx smap clflushopt clwb av\n",
            "                          x512cd avx512bw avx512vl xsaveopt xsavec xgetbv1 xsave\n",
            "                          s arat md_clear arch_capabilities\n",
            "Virtualization features:  \n",
            "  Hypervisor vendor:      KVM\n",
            "  Virtualization type:    full\n",
            "Caches (sum of all):      \n",
            "  L1d:                    32 KiB (1 instance)\n",
            "  L1i:                    32 KiB (1 instance)\n",
            "  L2:                     1 MiB (1 instance)\n",
            "  L3:                     38.5 MiB (1 instance)\n",
            "NUMA:                     \n",
            "  NUMA node(s):           1\n",
            "  NUMA node0 CPU(s):      0,1\n",
            "Vulnerabilities:          \n",
            "  Gather data sampling:   Not affected\n",
            "  Itlb multihit:          Not affected\n",
            "  L1tf:                   Mitigation; PTE Inversion\n",
            "  Mds:                    Vulnerable; SMT Host state unknown\n",
            "  Meltdown:               Vulnerable\n",
            "  Mmio stale data:        Vulnerable\n",
            "  Reg file data sampling: Not affected\n",
            "  Retbleed:               Vulnerable\n",
            "  Spec rstack overflow:   Not affected\n",
            "  Spec store bypass:      Vulnerable\n",
            "  Spectre v1:             Vulnerable: __user pointer sanitization and usercopy b\n",
            "                          arriers only; no swapgs barriers\n",
            "  Spectre v2:             Vulnerable; IBPB: disabled; STIBP: disabled; PBRSB-eIB\n",
            "                          RS: Not affected; BHI: Vulnerable\n",
            "  Srbds:                  Not affected\n",
            "  Tsx async abort:        Vulnerable\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "VFiJ1mFci9XD",
        "outputId": "80c5d516-f032-481b-ec91-ae33f6dd962c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Aug 24 15:03:18 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   63C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!free -h"
      ],
      "metadata": {
        "id": "O_8ZXG7kjJu_",
        "outputId": "fd9dc9d7-e85e-480a-def3-758b88a89b85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            12Gi       881Mi       8.4Gi       1.0Mi       3.4Gi        11Gi\n",
            "Swap:             0B          0B          0B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!df -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Es2yDmgMmGNI",
        "outputId": "6bf6ac6f-e421-48c7-b328-73fb6f07b617"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         113G   39G   74G  35% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "shm             5.7G     0  5.7G   0% /dev/shm\n",
            "/dev/root       2.0G  1.2G  775M  61% /usr/sbin/docker-init\n",
            "tmpfs           6.4G   84K  6.4G   1% /var/colab\n",
            "/dev/sda1        74G   42G   33G  56% /kaggle/input\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%watermark -a 'CulicidaeLab' -u -d -iv -h -m -w\n",
        "import torch\n",
        "from huggingface_hub import hf_hub_download\n",
        "from fastai.learner import load_learner\n",
        "from huggingface_hub import login\n",
        "from torch.utils.mobile_optimizer import optimize_for_mobile\n",
        "from IPython.display import FileLink"
      ],
      "metadata": {
        "id": "J-0XoCGHRlhi",
        "outputId": "48600b68-7ace-495a-e9d3-5ea37b87b283",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: CulicidaeLab\n",
            "\n",
            "Last updated: 2025-08-24\n",
            "\n",
            "Compiler    : GCC 11.4.0\n",
            "OS          : Linux\n",
            "Release     : 6.1.123+\n",
            "Machine     : x86_64\n",
            "Processor   : x86_64\n",
            "CPU cores   : 2\n",
            "Architecture: 64bit\n",
            "\n",
            "Hostname: f4cf2ca4b7ae\n",
            "\n",
            "Watermark: 2.5.0\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/iloncka-ds/culicidaelab.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW44aFuJmk6M",
        "outputId": "54308d31-f378-494e-e0d5-f09f37d27cca"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'culicidaelab'...\n",
            "remote: Enumerating objects: 2029, done.\u001b[K\n",
            "remote: Counting objects: 100% (757/757), done.\u001b[K\n",
            "remote: Compressing objects: 100% (389/389), done.\u001b[K\n",
            "remote: Total 2029 (delta 420), reused 588 (delta 311), pack-reused 1272 (from 1)\u001b[K\n",
            "Receiving objects: 100% (2029/2029), 52.30 MiB | 14.65 MiB/s, done.\n",
            "Resolving deltas: 100% (1112/1112), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd culicidaelab && pip install -e .[dev] -qq"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tCJ5VZskw8i",
        "outputId": "0c2b1a9c-d1e1-41fe-d28c-02453cbfb339"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.8/234.8 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.6/766.6 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m80.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m102.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m81.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m90.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.8/131.8 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.0/181.0 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m81.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.9/201.9 kB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.3/325.3 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/84.2 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m85.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.8/137.8 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.6/251.6 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.2/99.2 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.3/112.3 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m266.2/266.2 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.5/49.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m128.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m469.0/469.0 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m804.0/804.0 kB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.1/126.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building editable for culicidaelab (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for iopath (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires ipykernel==6.17.1, but you have ipykernel 6.16.2 which is incompatible.\n",
            "torchaudio 2.8.0+cu126 requires torch==2.8.0, but you have torch 2.6.0 which is incompatible.\n",
            "gradio 5.42.0 requires ruff>=0.9.3; sys_platform != \"emscripten\", but you have ruff 0.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!free -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLfWjNRHlpCc",
        "outputId": "58d2f31a-a855-4908-db85-d9ce88acf49a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               total        used        free      shared  buff/cache   available\n",
            "Mem:            12Gi       1.1Gi       2.8Gi       4.0Mi       8.8Gi        11Gi\n",
            "Swap:             0B          0B          0B\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!df -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrspry2vl68t",
        "outputId": "0f1d0091-14e1-4ad6-a700-77c201319945"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         113G   48G   66G  42% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "shm             5.7G     0  5.7G   0% /dev/shm\n",
            "/dev/root       2.0G  1.2G  775M  61% /usr/sbin/docker-init\n",
            "tmpfs           6.4G  3.0M  6.4G   1% /var/colab\n",
            "/dev/sda1        74G   54G   21G  73% /kaggle/input\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip cache purge"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEFDgsQwlP8V",
        "outputId": "b0029134-9ec2-4932-cae1-8b532a5e8866"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files removed: 528\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!df -h"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNHo4eQSmhi7",
        "outputId": "c4a6c687-8c48-4040-b755-c17669954959"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         113G   45G   69G  40% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "shm             5.7G     0  5.7G   0% /dev/shm\n",
            "/dev/root       2.0G  1.2G  775M  61% /usr/sbin/docker-init\n",
            "tmpfs           6.4G  3.1M  6.4G   1% /var/colab\n",
            "/dev/sda1        74G   54G   21G  73% /kaggle/input\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd culicidaelab && python -m tests.performance.test_performance --model-name classifier --device cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QX0c86MFRRyT",
        "outputId": "35ce416a-6e30-4f65-9420-5f935ea18e53"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "---\n",
            "Running test with default system thread settings.\n",
            "---\n",
            "\n",
            "Running test: 'model_loading'...\n",
            "  Warm-up run 1/1...\n",
            "Forcing device setting: 'predictors.classifier.device' = 'cuda'\n",
            "Model weights for 'classifier' not found. Attempting to download...\n",
            "Ensuring destination directory exists: /root/.local/share/culicidaelab/models/weights/classification\n",
            "culico-net-cls-v1-17.pkl: 100% 99.3M/99.3M [00:00<00:00, 326MB/s]\n",
            "Downloaded weights to: /root/.local/share/culicidaelab/models/weights/classification/culico-net-cls-v1-17.pkl\n",
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "  Measurement run 1/5...\n",
            "Forcing device setting: 'predictors.classifier.device' = 'cuda'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/classification/culico-net-cls-v1-17.pkl\n",
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "  Measurement run 2/5...\n",
            "Forcing device setting: 'predictors.classifier.device' = 'cuda'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/classification/culico-net-cls-v1-17.pkl\n",
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "  Measurement run 3/5...\n",
            "Forcing device setting: 'predictors.classifier.device' = 'cuda'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/classification/culico-net-cls-v1-17.pkl\n",
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "  Measurement run 4/5...\n",
            "Forcing device setting: 'predictors.classifier.device' = 'cuda'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/classification/culico-net-cls-v1-17.pkl\n",
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "  Measurement run 5/5...\n",
            "Forcing device setting: 'predictors.classifier.device' = 'cuda'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/classification/culico-net-cls-v1-17.pkl\n",
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "Forcing device setting: 'predictors.classifier.device' = 'cuda'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/classification/culico-net-cls-v1-17.pkl\n",
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "\n",
            "Running test: 'prediction_batch_1'...\n",
            "  Warm-up run 1/1...\n",
            "  Measurement run 1/5...\n",
            "  Measurement run 2/5...\n",
            "  Measurement run 3/5...\n",
            "  Measurement run 4/5...\n",
            "  Measurement run 5/5...\n",
            "\n",
            "Running test: 'prediction_batch_8'...\n",
            "  Warm-up run 1/1...\n",
            "  Measurement run 1/5...\n",
            "  Measurement run 2/5...\n",
            "  Measurement run 3/5...\n",
            "  Measurement run 4/5...\n",
            "  Measurement run 5/5...\n",
            "\n",
            "--- Performance Summary ---\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "| Test Name          | Batch Size   |   Avg Time (s) |   Avg CPU Time (s) |   RAM Final (MB) |   GPU Mem Final (MB) |\n",
            "+====================+==============+================+====================+==================+======================+\n",
            "| model_loading      | N/A          |         0.1123 |              0.114 |          1175.61 |                  614 |\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "| prediction_batch_1 | 1            |         0.1725 |              0.172 |          1294.58 |                  706 |\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "| prediction_batch_8 | 8            |         1.8277 |              1.704 |          1366.68 |                  706 |\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "\n",
            "All results saved to tests/performance/performance_logs/classifier_cuda_performance.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd culicidaelab && python -m tests.performance.test_performance --model-name classifier --device cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__eIbdQk2K5w",
        "outputId": "e0cc11cf-cbf2-41d5-c8ff-0524229d2939"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "Running test with default system thread settings.\n",
            "---\n",
            "\n",
            "Running test: 'model_loading'...\n",
            "  Warm-up run 1/1...\n",
            "Forcing device setting: 'predictors.classifier.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/classification/culico-net-cls-v1-17.pkl\n",
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "  Measurement run 1/5...\n",
            "Forcing device setting: 'predictors.classifier.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/classification/culico-net-cls-v1-17.pkl\n",
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "  Measurement run 2/5...\n",
            "Forcing device setting: 'predictors.classifier.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/classification/culico-net-cls-v1-17.pkl\n",
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "  Measurement run 3/5...\n",
            "Forcing device setting: 'predictors.classifier.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/classification/culico-net-cls-v1-17.pkl\n",
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "  Measurement run 4/5...\n",
            "Forcing device setting: 'predictors.classifier.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/classification/culico-net-cls-v1-17.pkl\n",
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "  Measurement run 5/5...\n",
            "Forcing device setting: 'predictors.classifier.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/classification/culico-net-cls-v1-17.pkl\n",
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "Forcing device setting: 'predictors.classifier.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/classification/culico-net-cls-v1-17.pkl\n",
            "/usr/local/lib/python3.12/dist-packages/fastai/learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\n",
            "If you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n",
            "  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\n",
            "\n",
            "Running test: 'prediction_batch_1'...\n",
            "  Warm-up run 1/1...\n",
            "  Measurement run 1/5...\n",
            "  Measurement run 2/5...\n",
            "  Measurement run 3/5...\n",
            "  Measurement run 4/5...\n",
            "  Measurement run 5/5...\n",
            "\n",
            "Running test: 'prediction_batch_8'...\n",
            "  Warm-up run 1/1...\n",
            "  Measurement run 1/5...\n",
            "  Measurement run 2/5...\n",
            "  Measurement run 3/5...\n",
            "  Measurement run 4/5...\n",
            "  Measurement run 5/5...\n",
            "\n",
            "--- Performance Summary ---\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "| Test Name          | Batch Size   |   Avg Time (s) |   Avg CPU Time (s) |   RAM Final (MB) |   GPU Mem Final (MB) |\n",
            "+====================+==============+================+====================+==================+======================+\n",
            "| model_loading      | N/A          |         0.0929 |              0.094 |          1463.07 |                    0 |\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "| prediction_batch_1 | 1            |         0.1732 |              0.17  |          1633.47 |                    2 |\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "| prediction_batch_8 | 8            |         1.7994 |              1.678 |          1706.54 |                    2 |\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "\n",
            "All results saved to tests/performance/performance_logs/classifier_cpu_performance.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd culicidaelab && python -m tests.performance.test_performance --model-name detector --device cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsDjc9q42_vo",
        "outputId": "8008db11-6fe3-4328-f532-0d4401c8f051"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "Running test with default system thread settings.\n",
            "---\n",
            "\n",
            "Running test: 'model_loading'...\n",
            "  Warm-up run 1/1...\n",
            "Forcing device setting: 'predictors.detector.device' = 'cuda'\n",
            "Model weights for 'detector' not found. Attempting to download...\n",
            "Ensuring destination directory exists: /root/.local/share/culicidaelab/models/weights/detection\n",
            "culico-net-det-v1-nano.pt: 100% 5.45M/5.45M [00:00<00:00, 185MB/s]\n",
            "Downloaded weights to: /root/.local/share/culicidaelab/models/weights/detection/culico-net-det-v1-nano.pt\n",
            "  Measurement run 1/5...\n",
            "Forcing device setting: 'predictors.detector.device' = 'cuda'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/detection/culico-net-det-v1-nano.pt\n",
            "  Measurement run 2/5...\n",
            "Forcing device setting: 'predictors.detector.device' = 'cuda'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/detection/culico-net-det-v1-nano.pt\n",
            "  Measurement run 3/5...\n",
            "Forcing device setting: 'predictors.detector.device' = 'cuda'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/detection/culico-net-det-v1-nano.pt\n",
            "  Measurement run 4/5...\n",
            "Forcing device setting: 'predictors.detector.device' = 'cuda'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/detection/culico-net-det-v1-nano.pt\n",
            "  Measurement run 5/5...\n",
            "Forcing device setting: 'predictors.detector.device' = 'cuda'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/detection/culico-net-det-v1-nano.pt\n",
            "Forcing device setting: 'predictors.detector.device' = 'cuda'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/detection/culico-net-det-v1-nano.pt\n",
            "\n",
            "Running test: 'prediction_batch_1'...\n",
            "  Warm-up run 1/1...\n",
            "  Measurement run 1/5...\n",
            "  Measurement run 2/5...\n",
            "  Measurement run 3/5...\n",
            "  Measurement run 4/5...\n",
            "  Measurement run 5/5...\n",
            "\n",
            "Running test: 'prediction_batch_8'...\n",
            "  Warm-up run 1/1...\n",
            "  Measurement run 1/5...\n",
            "  Measurement run 2/5...\n",
            "  Measurement run 3/5...\n",
            "  Measurement run 4/5...\n",
            "  Measurement run 5/5...\n",
            "\n",
            "--- Performance Summary ---\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "| Test Name          | Batch Size   |   Avg Time (s) |   Avg CPU Time (s) |   RAM Final (MB) |   GPU Mem Final (MB) |\n",
            "+====================+==============+================+====================+==================+======================+\n",
            "| model_loading      | N/A          |         0.0997 |              0.1   |           982.64 |                  140 |\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "| prediction_batch_1 | 1            |         0.0125 |              0.014 |          1349.95 |                  244 |\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "| prediction_batch_8 | 8            |         0.0675 |              0.066 |          1366.72 |                  446 |\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "\n",
            "All results saved to tests/performance/performance_logs/detector_cuda_performance.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd culicidaelab && python -m tests.performance.test_performance --model-name detector --device cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DYYWB9nC3JbQ",
        "outputId": "c2d4bad3-40e2-4a0b-d9dc-4df9e9ab2eb4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "Running test with default system thread settings.\n",
            "---\n",
            "\n",
            "Running test: 'model_loading'...\n",
            "  Warm-up run 1/1...\n",
            "Forcing device setting: 'predictors.detector.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/detection/culico-net-det-v1-nano.pt\n",
            "  Measurement run 1/5...\n",
            "Forcing device setting: 'predictors.detector.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/detection/culico-net-det-v1-nano.pt\n",
            "  Measurement run 2/5...\n",
            "Forcing device setting: 'predictors.detector.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/detection/culico-net-det-v1-nano.pt\n",
            "  Measurement run 3/5...\n",
            "Forcing device setting: 'predictors.detector.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/detection/culico-net-det-v1-nano.pt\n",
            "  Measurement run 4/5...\n",
            "Forcing device setting: 'predictors.detector.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/detection/culico-net-det-v1-nano.pt\n",
            "  Measurement run 5/5...\n",
            "Forcing device setting: 'predictors.detector.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/detection/culico-net-det-v1-nano.pt\n",
            "Forcing device setting: 'predictors.detector.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/detection/culico-net-det-v1-nano.pt\n",
            "\n",
            "Running test: 'prediction_batch_1'...\n",
            "  Warm-up run 1/1...\n",
            "  Measurement run 1/5...\n",
            "  Measurement run 2/5...\n",
            "  Measurement run 3/5...\n",
            "  Measurement run 4/5...\n",
            "  Measurement run 5/5...\n",
            "\n",
            "Running test: 'prediction_batch_8'...\n",
            "  Warm-up run 1/1...\n",
            "  Measurement run 1/5...\n",
            "  Measurement run 2/5...\n",
            "  Measurement run 3/5...\n",
            "  Measurement run 4/5...\n",
            "  Measurement run 5/5...\n",
            "\n",
            "--- Performance Summary ---\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "| Test Name          | Batch Size   |   Avg Time (s) |   Avg CPU Time (s) |   RAM Final (MB) |   GPU Mem Final (MB) |\n",
            "+====================+==============+================+====================+==================+======================+\n",
            "| model_loading      | N/A          |         0.0892 |              0.088 |           863.03 |                    0 |\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "| prediction_batch_1 | 1            |         0.1436 |              0.14  |           895.48 |                    2 |\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "| prediction_batch_8 | 8            |         1.2135 |              1.208 |          1179.34 |                    2 |\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "\n",
            "All results saved to tests/performance/performance_logs/detector_cpu_performance.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd culicidaelab && python -m tests.performance.test_performance --model-name segmenter --device cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JeWoawUA3NK8",
        "outputId": "59657ec8-632b-491d-a9d2-8706409d1e21"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "Running test with default system thread settings.\n",
            "---\n",
            "\n",
            "Running test: 'model_loading'...\n",
            "  Warm-up run 1/1...\n",
            "Forcing device setting: 'predictors.segmenter.device' = 'cpu'\n",
            "Model weights for 'segmenter' not found. Attempting to download...\n",
            "Ensuring destination directory exists: /root/.local/share/culicidaelab/models/weights/segmentation\n",
            "sam2.1_hiera_tiny.pt: 100% 156M/156M [00:00<00:00, 318MB/s]\n",
            "Downloaded weights to: /root/.local/share/culicidaelab/models/weights/segmentation/sam2.1_hiera_tiny.pt\n",
            "  Measurement run 1/5...\n",
            "Forcing device setting: 'predictors.segmenter.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/segmentation/sam2.1_t.pt\n",
            "  Measurement run 2/5...\n",
            "Forcing device setting: 'predictors.segmenter.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/segmentation/sam2.1_t.pt\n",
            "  Measurement run 3/5...\n",
            "Forcing device setting: 'predictors.segmenter.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/segmentation/sam2.1_t.pt\n",
            "  Measurement run 4/5...\n",
            "Forcing device setting: 'predictors.segmenter.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/segmentation/sam2.1_t.pt\n",
            "  Measurement run 5/5...\n",
            "Forcing device setting: 'predictors.segmenter.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/segmentation/sam2.1_t.pt\n",
            "Forcing device setting: 'predictors.segmenter.device' = 'cpu'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/segmentation/sam2.1_t.pt\n",
            "\n",
            "Running test: 'prediction_batch_1'...\n",
            "  Warm-up run 1/1...\n",
            "  Measurement run 1/5...\n",
            "  Measurement run 2/5...\n",
            "  Measurement run 3/5...\n",
            "  Measurement run 4/5...\n",
            "  Measurement run 5/5...\n",
            "\n",
            "Running test: 'prediction_batch_8'...\n",
            "  Warm-up run 1/1...\n",
            "  Measurement run 1/5...\n",
            "  Measurement run 2/5...\n",
            "  Measurement run 3/5...\n",
            "  Measurement run 4/5...\n",
            "  Measurement run 5/5...\n",
            "\n",
            "--- Performance Summary ---\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "| Test Name          | Batch Size   |   Avg Time (s) |   Avg CPU Time (s) |   RAM Final (MB) |   GPU Mem Final (MB) |\n",
            "+====================+==============+================+====================+==================+======================+\n",
            "| model_loading      | N/A          |         0.4106 |              0.412 |          1333.56 |                    2 |\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "| prediction_batch_1 | 1            |         4.5783 |              4.484 |          1436.88 |                    2 |\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "| prediction_batch_8 | 8            |        38.3487 |             38.124 |          1436.91 |                    2 |\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "\n",
            "All results saved to tests/performance/performance_logs/segmenter_cpu_performance.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd culicidaelab && python -m tests.performance.test_performance --model-name segmenter --device cuda"
      ],
      "metadata": {
        "id": "8lmlBCHO3RHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "707917fa-b549-481a-e571-88e47e55c370"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---\n",
            "Running test with default system thread settings.\n",
            "---\n",
            "\n",
            "Running test: 'model_loading'...\n",
            "  Warm-up run 1/1...\n",
            "Forcing device setting: 'predictors.segmenter.device' = 'cuda'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/segmentation/sam2.1_t.pt\n",
            "  Measurement run 1/5...\n",
            "Forcing device setting: 'predictors.segmenter.device' = 'cuda'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/segmentation/sam2.1_t.pt\n",
            "  Measurement run 2/5...\n",
            "Forcing device setting: 'predictors.segmenter.device' = 'cuda'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/segmentation/sam2.1_t.pt\n",
            "  Measurement run 3/5...\n",
            "Forcing device setting: 'predictors.segmenter.device' = 'cuda'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/segmentation/sam2.1_t.pt\n",
            "  Measurement run 4/5...\n",
            "Forcing device setting: 'predictors.segmenter.device' = 'cuda'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/segmentation/sam2.1_t.pt\n",
            "  Measurement run 5/5...\n",
            "Forcing device setting: 'predictors.segmenter.device' = 'cuda'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/segmentation/sam2.1_t.pt\n",
            "Forcing device setting: 'predictors.segmenter.device' = 'cuda'\n",
            "Weights file found at: /root/.local/share/culicidaelab/models/weights/segmentation/sam2.1_t.pt\n",
            "\n",
            "Running test: 'prediction_batch_1'...\n",
            "  Warm-up run 1/1...\n",
            "  Measurement run 1/5...\n",
            "  Measurement run 2/5...\n",
            "  Measurement run 3/5...\n",
            "  Measurement run 4/5...\n",
            "  Measurement run 5/5...\n",
            "\n",
            "Running test: 'prediction_batch_8'...\n",
            "  Warm-up run 1/1...\n",
            "  Measurement run 1/5...\n",
            "  Measurement run 2/5...\n",
            "  Measurement run 3/5...\n",
            "  Measurement run 4/5...\n",
            "  Measurement run 5/5...\n",
            "\n",
            "--- Performance Summary ---\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "| Test Name          | Batch Size   |   Avg Time (s) |   Avg CPU Time (s) |   RAM Final (MB) |   GPU Mem Final (MB) |\n",
            "+====================+==============+================+====================+==================+======================+\n",
            "| model_loading      | N/A          |         0.511  |              0.512 |          1188.41 |                  406 |\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "| prediction_batch_1 | 1            |         0.1438 |              0.144 |          1707.58 |                  996 |\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "| prediction_batch_8 | 8            |         1.0385 |              1.038 |          1709.2  |                  996 |\n",
            "+--------------------+--------------+----------------+--------------------+------------------+----------------------+\n",
            "\n",
            "All results saved to tests/performance/performance_logs/segmenter_cuda_performance.json\n"
          ]
        }
      ]
    }
  ]
}
