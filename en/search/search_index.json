{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"CulicidaeLab: A Powerful Toolkit for Mosquito Image Analysis","text":"<p>CulicidaeLab is a powerful and flexible Python library designed to provide an end-to-end solution for analyzing mosquito images. Whether you are a biologist, an epidemiologist, or a data scientist, this library provides the tools you need to detect, classify, and segment mosquitoes with state-of-the-art models.</p> <p>Built on a configuration-driven architecture, <code>CulicidaeLab</code> simplifies complex deep learning pipelines, making them accessible and reproducible for researchers and developers alike.</p>"},{"location":"#key-features","title":"Key Features","text":"Feature Description \ud83e\udde0 Pre-trained Models Get started immediately with high-accuracy models for detection, classification, and segmentation. No training required. \u2699\ufe0f Configuration-Driven Manage all aspects of the library\u2014from file paths to model parameters\u2014through simple and clear YAML files. \ud83d\udcca Built-in Evaluation Use integrated tools to assess model performance with standard metrics like Average Precision and IoU. \ud83e\udde9 Extensible &amp; Modular The library is designed with modularity in mind, allowing you to easily add your own models or data providers."},{"location":"#practical-applications-of-the-culicidaelab-library","title":"Practical Applications of the <code>culicidaelab</code> Library","text":"<ul> <li> <p>Automation in Scientific Laboratories:</p> <ul> <li>Bulk Data Processing: Automatically analyzing thousands of images from camera traps or microscopes to assess mosquito populations without manual labor.</li> <li>Reproducibility of Research: Standardizing the data analysis process, which allows other scientists to easily reproduce and verify research results published using this library.</li> </ul> </li> <li> <p>Integration into Governmental and Commercial Systems:</p> <ul> <li>Building Monitoring Systems: Using the library as the core \"engine\" for national or regional epidemiological surveillance systems.</li> <li>Developing Custom Solutions: Rapidly prototyping and creating specialized software products for disinsection services, agro-industrial companies, or environmental organizations.</li> </ul> </li> <li> <p>Analytics and Data Science:</p> <ul> <li>Writing scripts for in-depth data analysis, building distribution maps, and forecasting disease outbreaks based on the presence of vectors.</li> </ul> </li> </ul>"},{"location":"#found-an-issue-or-have-an-idea","title":"Found an Issue or Have an Idea?","text":"<p>This project is open-source and thrives on community feedback. If you encounter a bug or have a suggestion for a new feature, please open an issue on GitHub. We'd love to hear from you!</p>"},{"location":"installation/","title":"Installation","text":"<p>This guide provides all the necessary information to install <code>CulicidaeLab</code>. We cover a simple installation for regular users and a complete development setup for those who wish to contribute to the project.</p>"},{"location":"installation/#prerequisites","title":"Prerequisites","text":"<p>Before you begin, please ensure you have the following installed on your system:</p> <ul> <li>Python 3.11 or higher</li> <li>pip (Python's package installer, usually included with Python)</li> <li>Git (for the development setup)</li> </ul>"},{"location":"installation/#standard-installation-for-users","title":"Standard Installation (For Users)","text":"<p>This is the recommended approach for most users who want to use <code>CulicidaeLab</code> in their own projects. It will install the latest stable version from the Python Package Index (PyPI).</p> <p>We highly recommend working within a virtual environment to avoid conflicts with other projects or system-wide packages.</p>"},{"location":"installation/#recommended-using-uv","title":"Recommended: Using <code>uv</code>","text":"<p><code>uv</code> is an extremely fast, modern Python package installer and resolver that can replace <code>pip</code> and <code>venv</code>.</p> <pre><code># 1. Create and activate a virtual environment\nuv venv\n\n# On macOS/Linux:\nsource .venv/bin/activate\n# On Windows:\n# .venv\\Scripts\\activate\n\n# 2. Install the library\nuv add culicidaelab\n</code></pre>"},{"location":"installation/#alternative-using-pip-and-venv","title":"Alternative: Using <code>pip</code> and <code>venv</code>","text":"<p>If you prefer to use the standard tools built into Python:</p> <pre><code># 1. Create a virtual environment\npython -m venv .venv\n\n# 2. Activate it\n# On macOS/Linux:\nsource .venv/bin/activate\n# On Windows:\n# .venv\\Scripts\\activate\n\n# 3. Install the library using pip\npip install culicidaelab\n</code></pre>"},{"location":"installation/#development-setup-for-contributors","title":"Development Setup (For Contributors)","text":"<p>If you plan to contribute to <code>CulicidaeLab</code>, fix a bug, or add a new feature, you will need to set up a development environment. This involves cloning the repository and installing the project in editable mode.</p> <ol> <li> <p>Fork the Repository     Start by forking the main repository on GitHub to your own account.</p> </li> <li> <p>Clone Your Fork     Clone your forked repository to your local machine:     <pre><code>git clone https://github.com/YOUR_USERNAME/culicidaelab.git\ncd culicidaelab\n</code></pre></p> </li> <li> <p>Create and Activate a Virtual Environment     A virtual environment is essential for development to isolate your dependencies.     <pre><code># Using uv (recommended for speed)\nuv venv\n\n# Or using Python's built-in venv\n# python -m venv .venv\n\n# Activate the environment\n# On macOS/Linux:\nsource .venv/bin/activate\n# On Windows:\n# .venv\\Scripts\\activate\n</code></pre></p> </li> <li> <p>Install Dependencies in Editable Mode     Install the project with the <code>[dev]</code> extra, which includes all tools needed for testing, linting, and documentation. The <code>-e</code> flag installs it in \"editable\" mode, meaning changes you make to the source code will be immediately effective without needing to reinstall.</p> <pre><code># This command installs the library and all development dependencies\nuv pip install -e \".[dev]\"\n</code></pre> </li> <li> <p>Set Up Pre-commit Hooks     We use <code>pre-commit</code> to automatically run code quality checks before each commit. This is a one-time setup step per project clone.     <pre><code>pre-commit install\n</code></pre>     Now, whenever you run <code>git commit</code>, our code formatters and linters will run automatically, ensuring your contributions match the project's standards.</p> </li> </ol>"},{"location":"installation/#verifying-the-installation","title":"Verifying the Installation","text":"<p>To ensure that <code>CulicidaeLab</code> was installed correctly, you can run the following Python code snippet:</p> <pre><code>try:\n    from culicidaelab import get_settings\n    settings = get_settings()\n    print(\"\u2705 CulicidaeLab installation successful!\")\n    print(f\"Default model directory: {settings.model_dir}\")\nexcept ImportError:\n    print(\"\u274c CulicidaeLab installation failed. Please check the steps above.\")\n</code></pre> <p>You're all set! Now you're ready to explore the library's features.</p>"},{"location":"quickstart/","title":"Quick Start Guide","text":"<p>This guide is designed to get you from zero to your first mosquito classification in under five minutes. We will walk through a single, complete code example that you can copy, paste, and run to see <code>CulicidaeLab</code> in action.</p> <p>The example will show you how to:</p> <ol> <li>Initialize the library using the central <code>settings</code> object.</li> <li>Load an image of a mosquito.</li> <li>Run the <code>MosquitoClassifier</code> to predict its species.</li> <li>Visualize the result.</li> </ol>"},{"location":"quickstart/#prerequisites","title":"Prerequisites","text":"<p>Before you run the code, you need to have:</p> <ol> <li><code>CulicidaeLab</code> installed. If you haven't installed it yet, please follow the Installation Guide.</li> <li>A test image. Create a folder named <code>test_imgs</code> in your project's root directory. Place an image of a mosquito inside it and name it <code>mosquito.jpg</code>.</li> </ol> <p>Your project structure should look like this: <pre><code>your_project/\n\u251c\u2500\u2500 test_imgs/\n\u2502   \u2514\u2500\u2500 mosquito.jpg\n\u2514\u2500\u2500 your_script.py\n</code></pre></p>"},{"location":"quickstart/#complete-example-from-image-to-classification","title":"Complete Example: From Image to Classification","text":"<p>Copy the code block below into your Python script or a Jupyter Notebook and run it. The library will automatically download and cache the required model on the first run.</p> <pre><code># 1. Imports: Get all the necessary tools\nimport cv2\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\n# Import the main entry point and the classifier from CulicidaeLab\nfrom culicidaelab import get_settings\nfrom culicidaelab.predictors import MosquitoClassifier\n\n# --- Main script ---\n\n# 2. Initialization: Set up the library and the classifier\nprint(\"Initializing CulicidaeLab...\")\n# Get the central settings object, which manages all configurations.\nsettings = get_settings()\n# Ask the settings object to create a classifier. This is the recommended way.\nclassifier = MosquitoClassifier(settings=settings)\nprint(\"Classifier ready.\")\n\n\n# 3. Load Image: Prepare your data for prediction\nprint(\"Loading image...\")\nimage_path = Path(\"test_imgs\") / \"mosquito.jpg\"\ntry:\n    # Use OpenCV to read the image file\n    image = cv2.imread(str(image_path))\n    # The library expects images in RGB format, so we convert from OpenCV's default BGR\n    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    print(\"Image loaded successfully.\")\nexcept Exception as e:\n    print(f\"Error: Could not load image from {image_path}.\")\n    print(\"Please make sure the file exists and the path is correct.\")\n    exit()\n\n\n# 4. Run Prediction: Get the classification result\nprint(\"Running prediction...\")\n# The `model_context()` manager handles loading/unloading the model from memory efficiently.\nwith classifier.model_context():\n    predictions = classifier.predict(image_rgb)\nprint(\"Prediction complete.\")\n\n# The `predictions` object is a list of (species_name, confidence_score) tuples,\n# sorted from most to least likely.\ntop_prediction = predictions[0]\nprint(f\"\\n---&gt; Top Result: {top_prediction[0]} (Confidence: {top_prediction[1]:.2%})\")\n\n\n# 5. Visualize the Result: See the prediction on the image\nprint(\"\\nVisualizing result...\")\n# The `.visualize()` method draws the top predictions directly onto the image.\nwith classifier.model_context():\n    annotated_image = classifier.visualize(image_rgb, predictions)\n\n# Display the original and annotated images side-by-side for comparison\nplt.figure(figsize=(15, 7))\n\nplt.subplot(1, 2, 1)\nplt.imshow(image_rgb)\nplt.title(\"Original Image\")\nplt.axis(\"off\")\n\nplt.subplot(1, 2, 2)\nplt.imshow(annotated_image)\nplt.title(\"Classification Result\")\nplt.axis(\"off\")\n\nplt.tight_layout()\nplt.show()\nprint(\"Done!\")\n</code></pre>"},{"location":"api_docs/core/","title":"Core API","text":""},{"location":"api_docs/core/#culicidaelab.core","title":"<code>culicidaelab.core</code>","text":"<p>Core components of the CulicidaeLab library.</p> <p>This module provides the base classes, configuration management, and resource handling functionalities that form the foundation of the library. It exports key classes and functions for convenient access from other parts of the application.</p> <p>Attributes:</p> Name Type Description <code>__all__</code> <code>list[str]</code> <p>A list of the public objects of this module.</p>"},{"location":"api_docs/core/#culicidaelab.core.__all__","title":"<code>__all__ = ['BasePredictor', 'BaseProvider', 'WeightsManagerProtocol', 'BaseInferenceBackend', 'ConfigManager', 'CulicidaeLabConfig', 'PredictorConfig', 'DatasetConfig', 'ProviderConfig', 'SpeciesModel', 'SpeciesConfig', 'BoundingBox', 'Detection', 'DetectionPrediction', 'SegmentationPrediction', 'Classification', 'ClassificationPrediction', 'ProviderService', 'ResourceManager', 'Settings', 'get_settings', 'download_file']</code>  <code>module-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.BasePredictor","title":"<code>BasePredictor</code>","text":"<p>Abstract base class for all predictors.</p> <p>This class defines the common interface for all predictors (e.g., detector, segmenter, classifier). It relies on the main Settings object for configuration and a backend for model execution.</p> <p>Attributes:</p> Name Type Description <code>settings</code> <code>Settings</code> <p>The main settings object for the library.</p> <code>predictor_type</code> <code>str</code> <p>The key for this predictor in the configuration (e.g., 'classifier').</p> <code>backend</code> <code>BaseInferenceBackend</code> <p>An object that inherits from BaseInferenceBackend for model loading and inference.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>class BasePredictor(Generic[InputDataType, PredictionType, GroundTruthType], ABC):\n    \"\"\"Abstract base class for all predictors.\n\n    This class defines the common interface for all predictors (e.g., detector,\n    segmenter, classifier). It relies on the main Settings object for\n    configuration and a backend for model execution.\n\n    Attributes:\n        settings (Settings): The main settings object for the library.\n        predictor_type (str): The key for this predictor in the configuration\n            (e.g., 'classifier').\n        backend (BaseInferenceBackend): An object that inherits from\n            BaseInferenceBackend for model loading and inference.\n    \"\"\"\n\n    def __init__(\n        self,\n        settings: Settings,\n        predictor_type: str,\n        backend: BaseInferenceBackend,\n        load_model: bool = False,\n    ):\n        \"\"\"Initializes the predictor.\n\n        Args:\n            settings (Settings): The main Settings object for the library.\n            predictor_type (str): The key for this predictor in the configuration\n                (e.g., 'classifier').\n            backend (BaseInferenceBackend): An object that inherits from\n                BaseInferenceBackend for model loading and inference.\n            load_model (bool): If True, loads the model immediately upon\n                initialization.\n        \"\"\"\n        self.settings = settings\n        self.predictor_type = predictor_type\n        self.backend = backend\n        self._config: PredictorConfig = self._get_predictor_config()\n        self._logger = logging.getLogger(\n            f\"culicidaelab.predictor.{self.predictor_type}\",\n        )\n\n        if load_model:\n            self.load_model()\n\n    def __call__(self, input_data: InputDataType, **kwargs: Any) -&gt; Any:\n        \"\"\"Convenience method that calls `predict()`.\n\n        This allows the predictor instance to be called as a function.\n\n        Args:\n            input_data (InputDataType): The input data for the prediction.\n            **kwargs (Any): Additional arguments to pass to the `predict` method.\n\n        Returns:\n            Any: The result of the prediction.\n        \"\"\"\n        if not self.backend.is_loaded:\n            self.load_model()\n        return self.predict(input_data, **kwargs)\n\n    def __enter__(self):\n        \"\"\"Context manager entry.\n\n        Loads the model if it is not already loaded.\n\n        Returns:\n            BasePredictor: The predictor instance.\n        \"\"\"\n        if not self.backend.is_loaded:\n            self.load_model()\n        return self\n\n    def __exit__(self, exc_type, exc_val, exc_tb):\n        \"\"\"Context manager exit.\n\n        This default implementation does nothing, but can be overridden to handle\n        resource cleanup.\n        \"\"\"\n        pass\n\n    @property\n    def config(self) -&gt; PredictorConfig:\n        \"\"\"Get the predictor configuration Pydantic model.\n\n        Returns:\n            PredictorConfig: The configuration object for this predictor.\n        \"\"\"\n        return self._config\n\n    @property\n    def model_loaded(self) -&gt; bool:\n        \"\"\"Check if the model is loaded.\n\n        Returns:\n            bool: True if the model is loaded, False otherwise.\n        \"\"\"\n        return self.backend.is_loaded\n\n    @contextmanager\n    def model_context(self):\n        \"\"\"A context manager for temporary model loading.\n\n        Ensures the model is loaded upon entering the context and unloaded\n        upon exiting if it was not loaded before. This is useful for managing\n        memory in pipelines.\n\n        Yields:\n            BasePredictor: The predictor instance itself.\n\n        Example:\n            &gt;&gt;&gt; with predictor.model_context():\n            ...     predictions = predictor.predict(data)\n        \"\"\"\n        was_loaded = self.backend.is_loaded\n        try:\n            if not was_loaded:\n                self.load_model()\n            yield self\n        finally:\n            if not was_loaded and self.backend.is_loaded:\n                self.unload_model()\n\n    def evaluate(\n        self,\n        ground_truth: GroundTruthType,\n        prediction: PredictionType | None = None,\n        input_data: InputDataType | None = None,\n        **predict_kwargs: Any,\n    ) -&gt; dict[str, float]:\n        \"\"\"Evaluate a prediction against a ground truth.\n\n        Either `prediction` or `input_data` must be provided. If `prediction`\n        is provided, it is used directly. If `prediction` is None, `input_data`\n        is used to generate a new prediction.\n\n        Args:\n            ground_truth (GroundTruthType): The ground truth annotation.\n            prediction (PredictionType, optional): A pre-computed prediction.\n            input_data (InputDataType, optional): Input data to generate a\n                prediction from, if one isn't provided.\n            **predict_kwargs (Any): Additional arguments passed to the `predict`\n                method.\n\n        Returns:\n            dict[str, float]: Dictionary containing evaluation metrics for a\n            single item.\n\n        Raises:\n            ValueError: If neither `prediction` nor `input_data` is provided.\n        \"\"\"\n        if prediction is None:\n            if input_data is not None:\n                prediction = self.predict(input_data, **predict_kwargs)\n            else:\n                raise ValueError(\n                    \"Either 'prediction' or 'input_data' must be provided.\",\n                )\n        return self._evaluate_from_prediction(\n            prediction=prediction,\n            ground_truth=ground_truth,\n        )\n\n    def evaluate_batch(\n        self,\n        ground_truth_batch: Sequence[GroundTruthType],\n        predictions_batch: Sequence[PredictionType] | None = None,\n        input_data_batch: Sequence[InputDataType] | None = None,\n        num_workers: int = 1,\n        show_progress: bool = False,\n        **predict_kwargs: Any,\n    ) -&gt; dict[str, Any]:\n        \"\"\"Evaluate on a batch of items using parallel processing.\n\n        Either `predictions_batch` or `input_data_batch` must be provided.\n\n        Args:\n            ground_truth_batch (Sequence[GroundTruthType]): List of corresponding\n                ground truth annotations.\n            predictions_batch (Sequence[PredictionType], optional): A pre-computed\n                list of predictions.\n            input_data_batch (Sequence[InputDataType], optional): List of input data\n                to generate predictions from.\n            num_workers (int): Number of parallel workers for calculating metrics.\n            show_progress (bool): Whether to show a progress bar.\n            **predict_kwargs (Any): Additional arguments passed to `predict_batch`.\n\n        Returns:\n            dict[str, Any]: Dictionary containing aggregated evaluation metrics.\n\n        Raises:\n            ValueError: If the number of predictions does not match the number\n                of ground truths, or if required inputs are missing.\n        \"\"\"\n        if predictions_batch is None:\n            if input_data_batch is not None:\n                predictions_batch = self.predict_batch(\n                    input_data_batch,\n                    show_progress=show_progress,\n                    **predict_kwargs,\n                )\n            else:\n                raise ValueError(\n                    \"Either 'predictions_batch' or 'input_data_batch' must be provided.\",\n                )\n\n        if len(predictions_batch) != len(ground_truth_batch):\n            raise ValueError(\n                f\"Number of predictions ({len(predictions_batch)}) must match \"\n                f\"number of ground truths ({len(ground_truth_batch)}).\",\n            )\n\n        per_item_metrics = self._calculate_metrics_parallel(\n            predictions_batch,\n            ground_truth_batch,\n            num_workers,\n            show_progress,\n        )\n        aggregated_metrics = self._aggregate_metrics(per_item_metrics)\n        final_report = self._finalize_evaluation_report(\n            aggregated_metrics,\n            predictions_batch,\n            ground_truth_batch,\n        )\n        return final_report\n\n    def get_model_info(self) -&gt; dict[str, Any]:\n        \"\"\"Gets information about the loaded model.\n\n        Returns:\n            dict[str, Any]: A dictionary containing details about the model, such\n            as architecture, path, etc.\n        \"\"\"\n        return {\n            \"predictor_type\": self.predictor_type,\n            \"model_loaded\": self.backend.is_loaded,\n            \"config\": self.config.model_dump(),\n        }\n\n    def load_model(self) -&gt; None:\n        \"\"\"Delegates model loading to the configured backend.\"\"\"\n        if not self.backend.is_loaded:\n            self._logger.info(\n                f\"Loading model for {self.predictor_type} using {self.backend.__class__.__name__}\",\n            )\n            try:\n                self.backend.load_model()\n                self._logger.info(f\"Successfully loaded model for {self.predictor_type}\")\n            except Exception as e:\n                self._logger.error(f\"Failed to load model for {self.predictor_type}: {e}\")\n                raise RuntimeError(f\"Failed to load model for {self.predictor_type}: {e}\") from e\n\n    def predict(\n        self,\n        input_data: InputDataType,\n        **kwargs: Any,\n    ) -&gt; PredictionType:\n        \"\"\"Makes a prediction on a single input data sample.\n\n        Args:\n            input_data (InputDataType): The input data (e.g., an image as a NumPy\n                array) to make a prediction on.\n            **kwargs (Any): Additional predictor-specific arguments.\n\n        Returns:\n            PredictionType: The prediction result, with a format specific to the\n            predictor type.\n\n        Raises:\n            RuntimeError: If the model is not loaded before calling this method.\n        \"\"\"\n        if not self.backend.is_loaded:\n            try:\n                self.load_model()\n            except Exception as e:\n                raise RuntimeError(f\"Failed to load model: {e}\") from e\n\n        image = self._load_and_validate_image(input_data)\n\n        raw_output = self.backend.predict(image, **kwargs)\n\n        return self._convert_raw_to_prediction(raw_output)\n\n    def predict_batch(\n        self,\n        input_data_batch: Sequence[InputDataType],\n        show_progress: bool = False,\n        **kwargs: Any,\n    ) -&gt; list[PredictionType]:\n        \"\"\"Makes predictions on a batch of inputs by delegating to the backend.\n\n        Args:\n            input_data_batch (Sequence[InputDataType]): A sequence of inputs.\n            show_progress (bool): If True, displays a progress bar.\n            **kwargs (Any): Additional arguments for the backend's `predict_batch`.\n\n        Returns:\n            list[PredictionType]: A list of prediction results.\n        \"\"\"\n        if not input_data_batch:\n            return []\n\n        if not self.backend.is_loaded:\n            self.load_model()\n\n        raw_predictions = self.backend.predict_batch(list(input_data_batch), **kwargs)\n        final_predictions = [self._convert_raw_to_prediction(raw_pred) for raw_pred in raw_predictions]\n        return final_predictions\n\n    def unload_model(self) -&gt; None:\n        \"\"\"Unloads the model to free memory.\"\"\"\n        if self.backend.is_loaded:\n            self.backend.unload_model()\n            self._logger.info(f\"Unloaded model for {self.predictor_type}\")\n\n    @abstractmethod\n    def _evaluate_from_prediction(\n        self,\n        prediction: PredictionType,\n        ground_truth: GroundTruthType,\n    ) -&gt; dict[str, float]:\n        \"\"\"The core metric calculation logic for a single item.\n\n        This method must be implemented by subclasses to define how a prediction\n        is evaluated against a ground truth.\n\n        Args:\n            prediction (PredictionType): Model prediction.\n            ground_truth (GroundTruthType): Ground truth annotation.\n\n        Returns:\n            dict[str, float]: Dictionary containing evaluation metrics.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def _convert_raw_to_prediction(self, raw_prediction: Any) -&gt; PredictionType:\n        \"\"\"Converts raw backend output to a structured prediction model.\n\n        Subclasses MUST implement this to convert raw output (e.g., a numpy array)\n        from the backend into the final Pydantic prediction model.\n\n        Args:\n            raw_prediction (Any): The raw output from the inference backend.\n\n        Returns:\n            PredictionType: The structured prediction object.\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def visualize(\n        self,\n        input_data: InputDataType,\n        predictions: PredictionType,\n        save_path: str | Path | None = None,\n    ) -&gt; np.ndarray:\n        \"\"\"Visualizes the predictions on the input data.\n\n        Args:\n            input_data (InputDataType): The original input data (e.g., an image).\n            predictions (PredictionType): The prediction result obtained from\n                the `predict` method.\n            save_path (str | Path, optional): An optional path to save the\n                visualization to a file.\n\n        Returns:\n            np.ndarray: A NumPy array representing the visualized image.\n        \"\"\"\n        pass\n\n    def _aggregate_metrics(\n        self,\n        metrics_list: list[dict[str, float]],\n    ) -&gt; dict[str, float]:\n        \"\"\"Aggregates metrics from multiple evaluations.\n\n        Calculates the mean and standard deviation for each metric across a list\n        of evaluation results.\n\n        Args:\n            metrics_list (list[dict[str, float]]): A list of metric dictionaries.\n\n        Returns:\n            dict[str, float]: A dictionary with aggregated metrics (mean, std).\n        \"\"\"\n        if not metrics_list:\n            return {}\n\n        valid_metrics = [m for m in metrics_list if m]\n        if not valid_metrics:\n            self._logger.warning(\"No valid metrics found for aggregation\")\n            return {}\n\n        all_keys = {k for m in valid_metrics for k in m.keys()}\n        aggregated = {}\n        for key in all_keys:\n            values = [m[key] for m in valid_metrics if key in m]\n            if values:\n                aggregated[f\"{key}_mean\"] = float(np.mean(values))\n                aggregated[f\"{key}_std\"] = float(np.std(values))\n\n        aggregated[\"count\"] = len(valid_metrics)\n        return aggregated\n\n    def _calculate_metrics_parallel(\n        self,\n        predictions: Sequence[PredictionType],\n        ground_truths: Sequence[GroundTruthType],\n        num_workers: int = 4,\n        show_progress: bool = True,\n    ) -&gt; list[dict[str, float]]:\n        \"\"\"Calculates metrics for individual items in parallel.\n\n        Args:\n            predictions (Sequence[PredictionType]): A sequence of predictions.\n            ground_truths (Sequence[GroundTruthType]): A sequence of ground truths.\n            num_workers (int): The number of threads to use.\n            show_progress (bool): Whether to display a progress bar.\n\n        Returns:\n            list[dict[str, float]]: A list of metric dictionaries, one for each item.\n        \"\"\"\n        per_item_metrics = []\n\n        with ThreadPoolExecutor(max_workers=num_workers) as executor:\n            future_to_idx = {\n                executor.submit(\n                    self._evaluate_from_prediction,\n                    predictions[i],\n                    ground_truths[i],\n                ): i\n                for i in range(len(predictions))\n            }\n\n            iterator = as_completed(future_to_idx)\n            if show_progress:\n                iterator = progress_bar(\n                    iterator,\n                    total=len(future_to_idx),\n                )\n            for future in iterator:\n                try:\n                    per_item_metrics.append(future.result())\n                except Exception as e:\n                    idx = future_to_idx.get(future, \"unknown\")\n                    self._logger.error(\n                        f\"Error calculating metrics for item {idx}: {e}\",\n                    )\n                    per_item_metrics.append({})\n        return per_item_metrics\n\n    def _finalize_evaluation_report(\n        self,\n        aggregated_metrics: dict[str, float],\n        predictions: Sequence[PredictionType],\n        ground_truths: Sequence[GroundTruthType],\n    ) -&gt; dict[str, Any]:\n        \"\"\"Optional hook to post-process the final evaluation report.\n\n        This method can be overridden by subclasses to add more details to the\n        final report.\n\n        Args:\n            aggregated_metrics (dict[str, float]): The aggregated metrics.\n            predictions (Sequence[PredictionType]): The list of predictions.\n            ground_truths (Sequence[GroundTruthType]): The list of ground truths.\n\n        Returns:\n            dict[str, Any]: The finalized evaluation report.\n        \"\"\"\n        return aggregated_metrics\n\n    def _get_predictor_config(self) -&gt; PredictorConfig:\n        \"\"\"Gets the configuration for this predictor.\n\n        Returns:\n            PredictorConfig: A Pydantic `PredictorConfig` model for this\n            predictor instance.\n\n        Raises:\n            ValueError: If the configuration is invalid or not found.\n        \"\"\"\n        config = self.settings.get_config(f\"predictors.{self.predictor_type}\")\n        if not isinstance(config, PredictorConfig):\n            raise ValueError(\n                f\"Configuration for predictor '{self.predictor_type}' not found or is invalid.\",\n            )\n        return config\n\n    def _load_and_validate_image(self, input_data: InputDataType) -&gt; Image.Image:\n        \"\"\"Loads and validates an input image from various formats.\n\n        Args:\n            input_data: input data type (numpy array, file path, PIL Image, bytes,\n                or io.BytesIO).\n\n        Returns:\n            A validated PIL Image in RGB format.\n\n        Raises:\n            ValueError: If input format is invalid or image cannot be loaded.\n            FileNotFoundError: If image file path does not exist.\n            TypeError: If the input type is not supported.\n        \"\"\"\n        if isinstance(input_data, (str, Path)):\n            image_path = Path(input_data)\n            if not image_path.exists():\n                raise FileNotFoundError(f\"Image file not found: {image_path}\")\n            try:\n                image = Image.open(image_path).convert(\"RGB\")\n                return image\n            except Exception as e:\n                raise ValueError(f\"Cannot load image from {image_path}: {e}\")\n\n        elif isinstance(input_data, Image.Image):\n            return input_data.convert(\"RGB\")\n\n        elif isinstance(input_data, np.ndarray):\n            if input_data.ndim != 3 or input_data.shape[2] != 3:\n                raise ValueError(\n                    f\"Expected 3D RGB image, got shape: {input_data.shape}\",\n                )\n            if input_data.dtype == np.uint8:\n                return Image.fromarray(input_data)\n            elif input_data.dtype in [np.float32, np.float64]:\n                if input_data.max() &gt; 1.0 or input_data.min() &lt; 0.0:\n                    raise ValueError(\"Float images must be in range [0, 1]\")\n                return Image.fromarray((input_data * 255).astype(np.uint8))\n            else:\n                raise ValueError(f\"Unsupported numpy dtype: {input_data.dtype}\")\n\n        elif isinstance(input_data, bytes):\n            try:\n                return Image.open(io.BytesIO(input_data)).convert(\"RGB\")\n            except Exception as e:\n                raise ValueError(f\"Cannot load image from bytes: {e}\")\n\n        elif isinstance(input_data, io.BytesIO):\n            try:\n                return Image.open(input_data).convert(\"RGB\")\n            except Exception as e:\n                raise ValueError(f\"Cannot load image from BytesIO stream: {e}\")\n\n        else:\n            raise TypeError(\n                f\"Unsupported input type: {type(input_data)}. \"\n                f\"Expected np.ndarray, str, pathlib.Path, PIL.Image.Image, bytes, or io.BytesIO\",\n            )\n\n    def _prepare_batch_images(\n        self,\n        input_data_batch: Sequence[InputDataType],\n    ) -&gt; tuple[list[Image.Image], list[int]]:\n        \"\"\"Prepares and validates a batch of images for processing.\n\n        Args:\n            input_data_batch: A sequence of input images.\n\n        Returns:\n            A tuple of (valid_images, valid_indices) where valid_indices\n            tracks the original position of each valid image.\n        \"\"\"\n        valid_images = []\n        valid_indices = []\n        for idx, input_data in enumerate(input_data_batch):\n            try:\n                image = self._load_and_validate_image(input_data)\n                valid_images.append(image)\n                valid_indices.append(idx)\n            except Exception as e:\n                self._logger.warning(f\"Skipping image at index {idx}: {e}\")\n        return valid_images, valid_indices\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BasePredictor.settings","title":"<code>settings = settings</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.BasePredictor.predictor_type","title":"<code>predictor_type = predictor_type</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.BasePredictor.backend","title":"<code>backend = backend</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.BasePredictor.config","title":"<code>config: PredictorConfig</code>  <code>property</code>","text":"<p>Get the predictor configuration Pydantic model.</p> <p>Returns:</p> Name Type Description <code>PredictorConfig</code> <code>PredictorConfig</code> <p>The configuration object for this predictor.</p>"},{"location":"api_docs/core/#culicidaelab.core.BasePredictor.model_loaded","title":"<code>model_loaded: bool</code>  <code>property</code>","text":"<p>Check if the model is loaded.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the model is loaded, False otherwise.</p>"},{"location":"api_docs/core/#culicidaelab.core.BasePredictor.__init__","title":"<code>__init__(settings: Settings, predictor_type: str, backend: BaseInferenceBackend, load_model: bool = False)</code>","text":"<p>Initializes the predictor.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>Settings</code> <p>The main Settings object for the library.</p> required <code>predictor_type</code> <code>str</code> <p>The key for this predictor in the configuration (e.g., 'classifier').</p> required <code>backend</code> <code>BaseInferenceBackend</code> <p>An object that inherits from BaseInferenceBackend for model loading and inference.</p> required <code>load_model</code> <code>bool</code> <p>If True, loads the model immediately upon initialization.</p> <code>False</code> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def __init__(\n    self,\n    settings: Settings,\n    predictor_type: str,\n    backend: BaseInferenceBackend,\n    load_model: bool = False,\n):\n    \"\"\"Initializes the predictor.\n\n    Args:\n        settings (Settings): The main Settings object for the library.\n        predictor_type (str): The key for this predictor in the configuration\n            (e.g., 'classifier').\n        backend (BaseInferenceBackend): An object that inherits from\n            BaseInferenceBackend for model loading and inference.\n        load_model (bool): If True, loads the model immediately upon\n            initialization.\n    \"\"\"\n    self.settings = settings\n    self.predictor_type = predictor_type\n    self.backend = backend\n    self._config: PredictorConfig = self._get_predictor_config()\n    self._logger = logging.getLogger(\n        f\"culicidaelab.predictor.{self.predictor_type}\",\n    )\n\n    if load_model:\n        self.load_model()\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BasePredictor.__call__","title":"<code>__call__(input_data: InputDataType, **kwargs: Any) -&gt; Any</code>","text":"<p>Convenience method that calls <code>predict()</code>.</p> <p>This allows the predictor instance to be called as a function.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>InputDataType</code> <p>The input data for the prediction.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments to pass to the <code>predict</code> method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The result of the prediction.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def __call__(self, input_data: InputDataType, **kwargs: Any) -&gt; Any:\n    \"\"\"Convenience method that calls `predict()`.\n\n    This allows the predictor instance to be called as a function.\n\n    Args:\n        input_data (InputDataType): The input data for the prediction.\n        **kwargs (Any): Additional arguments to pass to the `predict` method.\n\n    Returns:\n        Any: The result of the prediction.\n    \"\"\"\n    if not self.backend.is_loaded:\n        self.load_model()\n    return self.predict(input_data, **kwargs)\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BasePredictor.__enter__","title":"<code>__enter__()</code>","text":"<p>Context manager entry.</p> <p>Loads the model if it is not already loaded.</p> <p>Returns:</p> Name Type Description <code>BasePredictor</code> <p>The predictor instance.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def __enter__(self):\n    \"\"\"Context manager entry.\n\n    Loads the model if it is not already loaded.\n\n    Returns:\n        BasePredictor: The predictor instance.\n    \"\"\"\n    if not self.backend.is_loaded:\n        self.load_model()\n    return self\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BasePredictor.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Context manager exit.</p> <p>This default implementation does nothing, but can be overridden to handle resource cleanup.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Context manager exit.\n\n    This default implementation does nothing, but can be overridden to handle\n    resource cleanup.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BasePredictor.model_context","title":"<code>model_context()</code>","text":"<p>A context manager for temporary model loading.</p> <p>Ensures the model is loaded upon entering the context and unloaded upon exiting if it was not loaded before. This is useful for managing memory in pipelines.</p> <p>Yields:</p> Name Type Description <code>BasePredictor</code> <p>The predictor instance itself.</p> Example <p>with predictor.model_context(): ...     predictions = predictor.predict(data)</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>@contextmanager\ndef model_context(self):\n    \"\"\"A context manager for temporary model loading.\n\n    Ensures the model is loaded upon entering the context and unloaded\n    upon exiting if it was not loaded before. This is useful for managing\n    memory in pipelines.\n\n    Yields:\n        BasePredictor: The predictor instance itself.\n\n    Example:\n        &gt;&gt;&gt; with predictor.model_context():\n        ...     predictions = predictor.predict(data)\n    \"\"\"\n    was_loaded = self.backend.is_loaded\n    try:\n        if not was_loaded:\n            self.load_model()\n        yield self\n    finally:\n        if not was_loaded and self.backend.is_loaded:\n            self.unload_model()\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BasePredictor.evaluate","title":"<code>evaluate(ground_truth: GroundTruthType, prediction: PredictionType | None = None, input_data: InputDataType | None = None, **predict_kwargs: Any) -&gt; dict[str, float]</code>","text":"<p>Evaluate a prediction against a ground truth.</p> <p>Either <code>prediction</code> or <code>input_data</code> must be provided. If <code>prediction</code> is provided, it is used directly. If <code>prediction</code> is None, <code>input_data</code> is used to generate a new prediction.</p> <p>Parameters:</p> Name Type Description Default <code>ground_truth</code> <code>GroundTruthType</code> <p>The ground truth annotation.</p> required <code>prediction</code> <code>PredictionType</code> <p>A pre-computed prediction.</p> <code>None</code> <code>input_data</code> <code>InputDataType</code> <p>Input data to generate a prediction from, if one isn't provided.</p> <code>None</code> <code>**predict_kwargs</code> <code>Any</code> <p>Additional arguments passed to the <code>predict</code> method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>dict[str, float]: Dictionary containing evaluation metrics for a</p> <code>dict[str, float]</code> <p>single item.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither <code>prediction</code> nor <code>input_data</code> is provided.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def evaluate(\n    self,\n    ground_truth: GroundTruthType,\n    prediction: PredictionType | None = None,\n    input_data: InputDataType | None = None,\n    **predict_kwargs: Any,\n) -&gt; dict[str, float]:\n    \"\"\"Evaluate a prediction against a ground truth.\n\n    Either `prediction` or `input_data` must be provided. If `prediction`\n    is provided, it is used directly. If `prediction` is None, `input_data`\n    is used to generate a new prediction.\n\n    Args:\n        ground_truth (GroundTruthType): The ground truth annotation.\n        prediction (PredictionType, optional): A pre-computed prediction.\n        input_data (InputDataType, optional): Input data to generate a\n            prediction from, if one isn't provided.\n        **predict_kwargs (Any): Additional arguments passed to the `predict`\n            method.\n\n    Returns:\n        dict[str, float]: Dictionary containing evaluation metrics for a\n        single item.\n\n    Raises:\n        ValueError: If neither `prediction` nor `input_data` is provided.\n    \"\"\"\n    if prediction is None:\n        if input_data is not None:\n            prediction = self.predict(input_data, **predict_kwargs)\n        else:\n            raise ValueError(\n                \"Either 'prediction' or 'input_data' must be provided.\",\n            )\n    return self._evaluate_from_prediction(\n        prediction=prediction,\n        ground_truth=ground_truth,\n    )\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BasePredictor.evaluate_batch","title":"<code>evaluate_batch(ground_truth_batch: Sequence[GroundTruthType], predictions_batch: Sequence[PredictionType] | None = None, input_data_batch: Sequence[InputDataType] | None = None, num_workers: int = 1, show_progress: bool = False, **predict_kwargs: Any) -&gt; dict[str, Any]</code>","text":"<p>Evaluate on a batch of items using parallel processing.</p> <p>Either <code>predictions_batch</code> or <code>input_data_batch</code> must be provided.</p> <p>Parameters:</p> Name Type Description Default <code>ground_truth_batch</code> <code>Sequence[GroundTruthType]</code> <p>List of corresponding ground truth annotations.</p> required <code>predictions_batch</code> <code>Sequence[PredictionType]</code> <p>A pre-computed list of predictions.</p> <code>None</code> <code>input_data_batch</code> <code>Sequence[InputDataType]</code> <p>List of input data to generate predictions from.</p> <code>None</code> <code>num_workers</code> <code>int</code> <p>Number of parallel workers for calculating metrics.</p> <code>1</code> <code>show_progress</code> <code>bool</code> <p>Whether to show a progress bar.</p> <code>False</code> <code>**predict_kwargs</code> <code>Any</code> <p>Additional arguments passed to <code>predict_batch</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Dictionary containing aggregated evaluation metrics.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the number of predictions does not match the number of ground truths, or if required inputs are missing.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def evaluate_batch(\n    self,\n    ground_truth_batch: Sequence[GroundTruthType],\n    predictions_batch: Sequence[PredictionType] | None = None,\n    input_data_batch: Sequence[InputDataType] | None = None,\n    num_workers: int = 1,\n    show_progress: bool = False,\n    **predict_kwargs: Any,\n) -&gt; dict[str, Any]:\n    \"\"\"Evaluate on a batch of items using parallel processing.\n\n    Either `predictions_batch` or `input_data_batch` must be provided.\n\n    Args:\n        ground_truth_batch (Sequence[GroundTruthType]): List of corresponding\n            ground truth annotations.\n        predictions_batch (Sequence[PredictionType], optional): A pre-computed\n            list of predictions.\n        input_data_batch (Sequence[InputDataType], optional): List of input data\n            to generate predictions from.\n        num_workers (int): Number of parallel workers for calculating metrics.\n        show_progress (bool): Whether to show a progress bar.\n        **predict_kwargs (Any): Additional arguments passed to `predict_batch`.\n\n    Returns:\n        dict[str, Any]: Dictionary containing aggregated evaluation metrics.\n\n    Raises:\n        ValueError: If the number of predictions does not match the number\n            of ground truths, or if required inputs are missing.\n    \"\"\"\n    if predictions_batch is None:\n        if input_data_batch is not None:\n            predictions_batch = self.predict_batch(\n                input_data_batch,\n                show_progress=show_progress,\n                **predict_kwargs,\n            )\n        else:\n            raise ValueError(\n                \"Either 'predictions_batch' or 'input_data_batch' must be provided.\",\n            )\n\n    if len(predictions_batch) != len(ground_truth_batch):\n        raise ValueError(\n            f\"Number of predictions ({len(predictions_batch)}) must match \"\n            f\"number of ground truths ({len(ground_truth_batch)}).\",\n        )\n\n    per_item_metrics = self._calculate_metrics_parallel(\n        predictions_batch,\n        ground_truth_batch,\n        num_workers,\n        show_progress,\n    )\n    aggregated_metrics = self._aggregate_metrics(per_item_metrics)\n    final_report = self._finalize_evaluation_report(\n        aggregated_metrics,\n        predictions_batch,\n        ground_truth_batch,\n    )\n    return final_report\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BasePredictor.get_model_info","title":"<code>get_model_info() -&gt; dict[str, Any]</code>","text":"<p>Gets information about the loaded model.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing details about the model, such</p> <code>dict[str, Any]</code> <p>as architecture, path, etc.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def get_model_info(self) -&gt; dict[str, Any]:\n    \"\"\"Gets information about the loaded model.\n\n    Returns:\n        dict[str, Any]: A dictionary containing details about the model, such\n        as architecture, path, etc.\n    \"\"\"\n    return {\n        \"predictor_type\": self.predictor_type,\n        \"model_loaded\": self.backend.is_loaded,\n        \"config\": self.config.model_dump(),\n    }\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BasePredictor.load_model","title":"<code>load_model() -&gt; None</code>","text":"<p>Delegates model loading to the configured backend.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def load_model(self) -&gt; None:\n    \"\"\"Delegates model loading to the configured backend.\"\"\"\n    if not self.backend.is_loaded:\n        self._logger.info(\n            f\"Loading model for {self.predictor_type} using {self.backend.__class__.__name__}\",\n        )\n        try:\n            self.backend.load_model()\n            self._logger.info(f\"Successfully loaded model for {self.predictor_type}\")\n        except Exception as e:\n            self._logger.error(f\"Failed to load model for {self.predictor_type}: {e}\")\n            raise RuntimeError(f\"Failed to load model for {self.predictor_type}: {e}\") from e\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BasePredictor.predict","title":"<code>predict(input_data: InputDataType, **kwargs: Any) -&gt; PredictionType</code>","text":"<p>Makes a prediction on a single input data sample.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>InputDataType</code> <p>The input data (e.g., an image as a NumPy array) to make a prediction on.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional predictor-specific arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>PredictionType</code> <code>PredictionType</code> <p>The prediction result, with a format specific to the</p> <code>PredictionType</code> <p>predictor type.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the model is not loaded before calling this method.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def predict(\n    self,\n    input_data: InputDataType,\n    **kwargs: Any,\n) -&gt; PredictionType:\n    \"\"\"Makes a prediction on a single input data sample.\n\n    Args:\n        input_data (InputDataType): The input data (e.g., an image as a NumPy\n            array) to make a prediction on.\n        **kwargs (Any): Additional predictor-specific arguments.\n\n    Returns:\n        PredictionType: The prediction result, with a format specific to the\n        predictor type.\n\n    Raises:\n        RuntimeError: If the model is not loaded before calling this method.\n    \"\"\"\n    if not self.backend.is_loaded:\n        try:\n            self.load_model()\n        except Exception as e:\n            raise RuntimeError(f\"Failed to load model: {e}\") from e\n\n    image = self._load_and_validate_image(input_data)\n\n    raw_output = self.backend.predict(image, **kwargs)\n\n    return self._convert_raw_to_prediction(raw_output)\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BasePredictor.predict_batch","title":"<code>predict_batch(input_data_batch: Sequence[InputDataType], show_progress: bool = False, **kwargs: Any) -&gt; list[PredictionType]</code>","text":"<p>Makes predictions on a batch of inputs by delegating to the backend.</p> <p>Parameters:</p> Name Type Description Default <code>input_data_batch</code> <code>Sequence[InputDataType]</code> <p>A sequence of inputs.</p> required <code>show_progress</code> <code>bool</code> <p>If True, displays a progress bar.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments for the backend's <code>predict_batch</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[PredictionType]</code> <p>list[PredictionType]: A list of prediction results.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def predict_batch(\n    self,\n    input_data_batch: Sequence[InputDataType],\n    show_progress: bool = False,\n    **kwargs: Any,\n) -&gt; list[PredictionType]:\n    \"\"\"Makes predictions on a batch of inputs by delegating to the backend.\n\n    Args:\n        input_data_batch (Sequence[InputDataType]): A sequence of inputs.\n        show_progress (bool): If True, displays a progress bar.\n        **kwargs (Any): Additional arguments for the backend's `predict_batch`.\n\n    Returns:\n        list[PredictionType]: A list of prediction results.\n    \"\"\"\n    if not input_data_batch:\n        return []\n\n    if not self.backend.is_loaded:\n        self.load_model()\n\n    raw_predictions = self.backend.predict_batch(list(input_data_batch), **kwargs)\n    final_predictions = [self._convert_raw_to_prediction(raw_pred) for raw_pred in raw_predictions]\n    return final_predictions\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BasePredictor.unload_model","title":"<code>unload_model() -&gt; None</code>","text":"<p>Unloads the model to free memory.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def unload_model(self) -&gt; None:\n    \"\"\"Unloads the model to free memory.\"\"\"\n    if self.backend.is_loaded:\n        self.backend.unload_model()\n        self._logger.info(f\"Unloaded model for {self.predictor_type}\")\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BasePredictor.visualize","title":"<code>visualize(input_data: InputDataType, predictions: PredictionType, save_path: str | Path | None = None) -&gt; np.ndarray</code>  <code>abstractmethod</code>","text":"<p>Visualizes the predictions on the input data.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>InputDataType</code> <p>The original input data (e.g., an image).</p> required <code>predictions</code> <code>PredictionType</code> <p>The prediction result obtained from the <code>predict</code> method.</p> required <code>save_path</code> <code>str | Path</code> <p>An optional path to save the visualization to a file.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: A NumPy array representing the visualized image.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>@abstractmethod\ndef visualize(\n    self,\n    input_data: InputDataType,\n    predictions: PredictionType,\n    save_path: str | Path | None = None,\n) -&gt; np.ndarray:\n    \"\"\"Visualizes the predictions on the input data.\n\n    Args:\n        input_data (InputDataType): The original input data (e.g., an image).\n        predictions (PredictionType): The prediction result obtained from\n            the `predict` method.\n        save_path (str | Path, optional): An optional path to save the\n            visualization to a file.\n\n    Returns:\n        np.ndarray: A NumPy array representing the visualized image.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BaseProvider","title":"<code>BaseProvider</code>","text":"<p>Abstract base class for all data and model providers.</p> <p>This class defines the contract for providers that fetch resources like datasets and model weights.</p> Source code in <code>culicidaelab\\core\\base_provider.py</code> <pre><code>class BaseProvider(ABC):\n    \"\"\"Abstract base class for all data and model providers.\n\n    This class defines the contract for providers that fetch resources like\n    datasets and model weights.\n    \"\"\"\n\n    @abstractmethod\n    def download_dataset(\n        self,\n        dataset_name: str,\n        save_dir: Path | None = None,\n        *args: Any,\n        **kwargs: Any,\n    ) -&gt; Path:\n        \"\"\"Downloads a dataset from a source.\n\n        Args:\n            dataset_name (str): The name or identifier of the dataset to download.\n            save_dir (Path | None, optional): The directory to save the dataset.\n                If None, a default directory may be used. Defaults to None.\n            *args: Additional positional arguments for the provider's implementation.\n            **kwargs: Additional keyword arguments for the provider's implementation.\n\n        Returns:\n            Path: The path to the downloaded dataset directory or file.\n\n        Raises:\n            NotImplementedError: If the method is not implemented by a subclass.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses must implement this method\")\n\n    @abstractmethod\n    def download_model_weights(\n        self,\n        repo_id: str,\n        filename: str,\n        local_dir: Path,\n        *args: Any,\n        **kwargs: Any,\n    ) -&gt; Path:\n        \"\"\"Downloads model weights and returns the path to them.\n\n        Args:\n            repo_id (str): The repository ID from which to download the model\n                (e.g., 'culicidae/mosquito-detector').\n            filename (str): The name of the weights file in the repository.\n            local_dir (Path): The local directory to save the weights file.\n            *args: Additional positional arguments for the provider's implementation.\n            **kwargs: Additional keyword arguments for the provider's implementation.\n\n        Returns:\n            Path: The local path to the downloaded model weights file.\n\n        Raises:\n            NotImplementedError: If the method is not implemented by a subclass.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses must implement this method\")\n\n    @abstractmethod\n    def get_provider_name(self) -&gt; str:\n        \"\"\"Gets the unique name of the provider.\n\n        Returns:\n            str: A string representing the provider's name (e.g., 'huggingface').\n        \"\"\"\n        pass\n\n    @abstractmethod\n    def load_dataset(\n        self,\n        dataset_path: str | Path,\n        **kwargs: Any,\n    ) -&gt; Any:\n        \"\"\"Loads a dataset from a local path.\n\n        This method is responsible for loading a dataset that has already been\n        downloaded to the local filesystem.\n\n        Args:\n            dataset_path (str | Path): The local path to the dataset, typically\n                a path returned by `download_dataset`.\n            **kwargs: Additional keyword arguments for loading the dataset, which\n                may vary by provider and dataset format.\n\n        Returns:\n            Any: The loaded dataset object, which could be a Hugging Face Dataset,\n            a PyTorch Dataset, a Pandas DataFrame, or another format.\n\n        Raises:\n            NotImplementedError: If the method is not implemented by a subclass.\n        \"\"\"\n        raise NotImplementedError(\"Subclasses must implement this method\")\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BaseProvider.download_dataset","title":"<code>download_dataset(dataset_name: str, save_dir: Path | None = None, *args: Any, **kwargs: Any) -&gt; Path</code>  <code>abstractmethod</code>","text":"<p>Downloads a dataset from a source.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>The name or identifier of the dataset to download.</p> required <code>save_dir</code> <code>Path | None</code> <p>The directory to save the dataset. If None, a default directory may be used. Defaults to None.</p> <code>None</code> <code>*args</code> <code>Any</code> <p>Additional positional arguments for the provider's implementation.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for the provider's implementation.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>The path to the downloaded dataset directory or file.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the method is not implemented by a subclass.</p> Source code in <code>culicidaelab\\core\\base_provider.py</code> <pre><code>@abstractmethod\ndef download_dataset(\n    self,\n    dataset_name: str,\n    save_dir: Path | None = None,\n    *args: Any,\n    **kwargs: Any,\n) -&gt; Path:\n    \"\"\"Downloads a dataset from a source.\n\n    Args:\n        dataset_name (str): The name or identifier of the dataset to download.\n        save_dir (Path | None, optional): The directory to save the dataset.\n            If None, a default directory may be used. Defaults to None.\n        *args: Additional positional arguments for the provider's implementation.\n        **kwargs: Additional keyword arguments for the provider's implementation.\n\n    Returns:\n        Path: The path to the downloaded dataset directory or file.\n\n    Raises:\n        NotImplementedError: If the method is not implemented by a subclass.\n    \"\"\"\n    raise NotImplementedError(\"Subclasses must implement this method\")\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BaseProvider.download_model_weights","title":"<code>download_model_weights(repo_id: str, filename: str, local_dir: Path, *args: Any, **kwargs: Any) -&gt; Path</code>  <code>abstractmethod</code>","text":"<p>Downloads model weights and returns the path to them.</p> <p>Parameters:</p> Name Type Description Default <code>repo_id</code> <code>str</code> <p>The repository ID from which to download the model (e.g., 'culicidae/mosquito-detector').</p> required <code>filename</code> <code>str</code> <p>The name of the weights file in the repository.</p> required <code>local_dir</code> <code>Path</code> <p>The local directory to save the weights file.</p> required <code>*args</code> <code>Any</code> <p>Additional positional arguments for the provider's implementation.</p> <code>()</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for the provider's implementation.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>The local path to the downloaded model weights file.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the method is not implemented by a subclass.</p> Source code in <code>culicidaelab\\core\\base_provider.py</code> <pre><code>@abstractmethod\ndef download_model_weights(\n    self,\n    repo_id: str,\n    filename: str,\n    local_dir: Path,\n    *args: Any,\n    **kwargs: Any,\n) -&gt; Path:\n    \"\"\"Downloads model weights and returns the path to them.\n\n    Args:\n        repo_id (str): The repository ID from which to download the model\n            (e.g., 'culicidae/mosquito-detector').\n        filename (str): The name of the weights file in the repository.\n        local_dir (Path): The local directory to save the weights file.\n        *args: Additional positional arguments for the provider's implementation.\n        **kwargs: Additional keyword arguments for the provider's implementation.\n\n    Returns:\n        Path: The local path to the downloaded model weights file.\n\n    Raises:\n        NotImplementedError: If the method is not implemented by a subclass.\n    \"\"\"\n    raise NotImplementedError(\"Subclasses must implement this method\")\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BaseProvider.get_provider_name","title":"<code>get_provider_name() -&gt; str</code>  <code>abstractmethod</code>","text":"<p>Gets the unique name of the provider.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A string representing the provider's name (e.g., 'huggingface').</p> Source code in <code>culicidaelab\\core\\base_provider.py</code> <pre><code>@abstractmethod\ndef get_provider_name(self) -&gt; str:\n    \"\"\"Gets the unique name of the provider.\n\n    Returns:\n        str: A string representing the provider's name (e.g., 'huggingface').\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BaseProvider.load_dataset","title":"<code>load_dataset(dataset_path: str | Path, **kwargs: Any) -&gt; Any</code>  <code>abstractmethod</code>","text":"<p>Loads a dataset from a local path.</p> <p>This method is responsible for loading a dataset that has already been downloaded to the local filesystem.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_path</code> <code>str | Path</code> <p>The local path to the dataset, typically a path returned by <code>download_dataset</code>.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments for loading the dataset, which may vary by provider and dataset format.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The loaded dataset object, which could be a Hugging Face Dataset,</p> <code>Any</code> <p>a PyTorch Dataset, a Pandas DataFrame, or another format.</p> <p>Raises:</p> Type Description <code>NotImplementedError</code> <p>If the method is not implemented by a subclass.</p> Source code in <code>culicidaelab\\core\\base_provider.py</code> <pre><code>@abstractmethod\ndef load_dataset(\n    self,\n    dataset_path: str | Path,\n    **kwargs: Any,\n) -&gt; Any:\n    \"\"\"Loads a dataset from a local path.\n\n    This method is responsible for loading a dataset that has already been\n    downloaded to the local filesystem.\n\n    Args:\n        dataset_path (str | Path): The local path to the dataset, typically\n            a path returned by `download_dataset`.\n        **kwargs: Additional keyword arguments for loading the dataset, which\n            may vary by provider and dataset format.\n\n    Returns:\n        Any: The loaded dataset object, which could be a Hugging Face Dataset,\n        a PyTorch Dataset, a Pandas DataFrame, or another format.\n\n    Raises:\n        NotImplementedError: If the method is not implemented by a subclass.\n    \"\"\"\n    raise NotImplementedError(\"Subclasses must implement this method\")\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.WeightsManagerProtocol","title":"<code>WeightsManagerProtocol</code>","text":"Source code in <code>culicidaelab\\core\\weights_manager_protocol.py</code> <pre><code>class WeightsManagerProtocol(Protocol):\n    def ensure_weights(self, predictor_type: str, backend_type: str) -&gt; Path:\n        \"\"\"Ensures model weights are available locally and returns their path.\n\n        This method is responsible for managing model weight files, including checking\n        their existence, downloading if necessary, and providing the absolute path to\n        the weights file. It abstracts away the details of weight file management from\n        the rest of the system.\n\n        Args:\n            predictor_type (str): The type of predictor requiring the weights.\n                Common values include 'classifier', 'detector', or 'segmenter'.\n            backend_type (str): The backend framework for which the weights are needed.\n                Examples include 'fastai', 'onnx', 'yolo', or 'sam'.\n\n        Returns:\n            Path: Absolute path to the model weights file. The returned path is\n                guaranteed to exist and be accessible.\n\n        Example:\n            ```python\n            from your_module import WeightsManager\n\n            weights_manager = WeightsManager()\n\n            # Get weights for a FastAI classifier\n            classifier_weights = weights_manager.ensure_weights(\n                predictor_type=\"classifier\",\n                backend_type=\"fastai\"\n            )\n\n            # Use the weights in a model\n            model.load_state_dict(torch.load(classifier_weights))\n            ```\n\n        Note:\n            Implementations should handle various scenarios such as:\n            - Checking if weights exist locally\n            - Downloading weights from remote sources if needed\n            - Validating weight file integrity\n            - Managing weight file versions\n            - Handling download failures and retry logic\n        \"\"\"\n        ...\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.WeightsManagerProtocol.ensure_weights","title":"<code>ensure_weights(predictor_type: str, backend_type: str) -&gt; Path</code>","text":"<p>Ensures model weights are available locally and returns their path.</p> <p>This method is responsible for managing model weight files, including checking their existence, downloading if necessary, and providing the absolute path to the weights file. It abstracts away the details of weight file management from the rest of the system.</p> <p>Parameters:</p> Name Type Description Default <code>predictor_type</code> <code>str</code> <p>The type of predictor requiring the weights. Common values include 'classifier', 'detector', or 'segmenter'.</p> required <code>backend_type</code> <code>str</code> <p>The backend framework for which the weights are needed. Examples include 'fastai', 'onnx', 'yolo', or 'sam'.</p> required <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>Absolute path to the model weights file. The returned path is guaranteed to exist and be accessible.</p> Example <pre><code>from your_module import WeightsManager\n\nweights_manager = WeightsManager()\n\n# Get weights for a FastAI classifier\nclassifier_weights = weights_manager.ensure_weights(\n    predictor_type=\"classifier\",\n    backend_type=\"fastai\"\n)\n\n# Use the weights in a model\nmodel.load_state_dict(torch.load(classifier_weights))\n</code></pre> Note <p>Implementations should handle various scenarios such as: - Checking if weights exist locally - Downloading weights from remote sources if needed - Validating weight file integrity - Managing weight file versions - Handling download failures and retry logic</p> Source code in <code>culicidaelab\\core\\weights_manager_protocol.py</code> <pre><code>def ensure_weights(self, predictor_type: str, backend_type: str) -&gt; Path:\n    \"\"\"Ensures model weights are available locally and returns their path.\n\n    This method is responsible for managing model weight files, including checking\n    their existence, downloading if necessary, and providing the absolute path to\n    the weights file. It abstracts away the details of weight file management from\n    the rest of the system.\n\n    Args:\n        predictor_type (str): The type of predictor requiring the weights.\n            Common values include 'classifier', 'detector', or 'segmenter'.\n        backend_type (str): The backend framework for which the weights are needed.\n            Examples include 'fastai', 'onnx', 'yolo', or 'sam'.\n\n    Returns:\n        Path: Absolute path to the model weights file. The returned path is\n            guaranteed to exist and be accessible.\n\n    Example:\n        ```python\n        from your_module import WeightsManager\n\n        weights_manager = WeightsManager()\n\n        # Get weights for a FastAI classifier\n        classifier_weights = weights_manager.ensure_weights(\n            predictor_type=\"classifier\",\n            backend_type=\"fastai\"\n        )\n\n        # Use the weights in a model\n        model.load_state_dict(torch.load(classifier_weights))\n        ```\n\n    Note:\n        Implementations should handle various scenarios such as:\n        - Checking if weights exist locally\n        - Downloading weights from remote sources if needed\n        - Validating weight file integrity\n        - Managing weight file versions\n        - Handling download failures and retry logic\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BaseInferenceBackend","title":"<code>BaseInferenceBackend</code>","text":"<p>Abstract base class for an inference backend.</p> <p>This class defines the required methods for an inference backend, which is responsible for loading a model and running predictions. It includes a default implementation for batch prediction that iterates through single predictions.</p> <p>Attributes:</p> Name Type Description <code>predictor_type</code> <code>str</code> <p>The type of predictor this backend serves (e.g., 'classifier').</p> <code>model</code> <code>Any</code> <p>The loaded model object. Initially None.</p> Source code in <code>culicidaelab\\core\\base_inference_backend.py</code> <pre><code>class BaseInferenceBackend(Generic[InputDataType, PredictionType], ABC):\n    \"\"\"Abstract base class for an inference backend.\n\n    This class defines the required methods for an inference backend, which is\n    responsible for loading a model and running predictions. It includes a default\n    implementation for batch prediction that iterates through single predictions.\n\n    Attributes:\n        predictor_type (str): The type of predictor this backend serves (e.g., 'classifier').\n        model (Any): The loaded model object. Initially None.\n    \"\"\"\n\n    def __init__(\n        self,\n        predictor_type: str,\n    ):\n        \"\"\"Initializes the BaseInferenceBackend.\n\n        Args:\n            predictor_type: The type of predictor (e.g., 'classifier', 'detector').\n        \"\"\"\n        self.predictor_type = predictor_type\n        self.model: Any = None\n\n    @abstractmethod\n    def load_model(self, **kwargs: Any) -&gt; None:\n        \"\"\"Loads the model into memory.\n\n        This method should handle all aspects of model loading, such as reading\n        weights from a file and preparing the model for inference.\n\n        Args:\n            **kwargs: Backend-specific arguments for model loading.\n        \"\"\"\n        ...\n\n    @abstractmethod\n    def predict(self, input_data: InputDataType, **kwargs: Any) -&gt; PredictionType:\n        \"\"\"Runs a prediction on a single input.\n\n        Args:\n            input_data: The data to be processed by the model.\n            **kwargs: Additional backend-specific arguments for prediction.\n\n        Returns:\n            The prediction result.\n        \"\"\"\n        ...\n\n    def unload_model(self) -&gt; None:\n        \"\"\"Unloads the model and releases resources.\n\n        This method is intended to free up memory (especially GPU memory) by\n        deleting the model instance.\n        \"\"\"\n        self.model = None\n        logger.info(f\"Model for {self.predictor_type} has been unloaded.\")\n\n    @property\n    def is_loaded(self) -&gt; bool:\n        \"\"\"Checks if the model is loaded into memory.\n\n        Returns:\n            True if the model is loaded, False otherwise.\n        \"\"\"\n        return self.model is not None\n\n    def predict_batch(\n        self,\n        input_data_batch: list[InputDataType],\n        show_progress: bool = False,\n        **kwargs: Any,\n    ) -&gt; list[PredictionType]:\n        \"\"\"Makes predictions on a batch of inputs.\n\n        This method provides a default implementation that iterates through the batch\n        and calls `predict` for each item. Backends that support native batching\n        should override this method for better performance.\n\n        Args:\n            input_data_batch: A list of inputs to process.\n            show_progress: If True, displays a progress bar.\n            **kwargs: Additional arguments to pass to the `predict` method.\n\n        Returns:\n            A list of prediction results.\n        \"\"\"\n        if not input_data_batch:\n            return []\n\n        if not self.is_loaded:\n            self.load_model(**kwargs)\n\n        iterator = input_data_batch\n        if show_progress:\n            iterator = progress_bar(input_data_batch, total=len(input_data_batch))\n\n        # The core logic for iterative batch prediction.\n        raw_predictions = [self.predict(input_data, **kwargs) for input_data in iterator]\n        return raw_predictions\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BaseInferenceBackend.predictor_type","title":"<code>predictor_type = predictor_type</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.BaseInferenceBackend.model","title":"<code>model: Any = None</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.BaseInferenceBackend.is_loaded","title":"<code>is_loaded: bool</code>  <code>property</code>","text":"<p>Checks if the model is loaded into memory.</p> <p>Returns:</p> Type Description <code>bool</code> <p>True if the model is loaded, False otherwise.</p>"},{"location":"api_docs/core/#culicidaelab.core.BaseInferenceBackend.__init__","title":"<code>__init__(predictor_type: str)</code>","text":"<p>Initializes the BaseInferenceBackend.</p> <p>Parameters:</p> Name Type Description Default <code>predictor_type</code> <code>str</code> <p>The type of predictor (e.g., 'classifier', 'detector').</p> required Source code in <code>culicidaelab\\core\\base_inference_backend.py</code> <pre><code>def __init__(\n    self,\n    predictor_type: str,\n):\n    \"\"\"Initializes the BaseInferenceBackend.\n\n    Args:\n        predictor_type: The type of predictor (e.g., 'classifier', 'detector').\n    \"\"\"\n    self.predictor_type = predictor_type\n    self.model: Any = None\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BaseInferenceBackend.load_model","title":"<code>load_model(**kwargs: Any) -&gt; None</code>  <code>abstractmethod</code>","text":"<p>Loads the model into memory.</p> <p>This method should handle all aspects of model loading, such as reading weights from a file and preparing the model for inference.</p> <p>Parameters:</p> Name Type Description Default <code>**kwargs</code> <code>Any</code> <p>Backend-specific arguments for model loading.</p> <code>{}</code> Source code in <code>culicidaelab\\core\\base_inference_backend.py</code> <pre><code>@abstractmethod\ndef load_model(self, **kwargs: Any) -&gt; None:\n    \"\"\"Loads the model into memory.\n\n    This method should handle all aspects of model loading, such as reading\n    weights from a file and preparing the model for inference.\n\n    Args:\n        **kwargs: Backend-specific arguments for model loading.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BaseInferenceBackend.predict","title":"<code>predict(input_data: InputDataType, **kwargs: Any) -&gt; PredictionType</code>  <code>abstractmethod</code>","text":"<p>Runs a prediction on a single input.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>InputDataType</code> <p>The data to be processed by the model.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional backend-specific arguments for prediction.</p> <code>{}</code> <p>Returns:</p> Type Description <code>PredictionType</code> <p>The prediction result.</p> Source code in <code>culicidaelab\\core\\base_inference_backend.py</code> <pre><code>@abstractmethod\ndef predict(self, input_data: InputDataType, **kwargs: Any) -&gt; PredictionType:\n    \"\"\"Runs a prediction on a single input.\n\n    Args:\n        input_data: The data to be processed by the model.\n        **kwargs: Additional backend-specific arguments for prediction.\n\n    Returns:\n        The prediction result.\n    \"\"\"\n    ...\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BaseInferenceBackend.unload_model","title":"<code>unload_model() -&gt; None</code>","text":"<p>Unloads the model and releases resources.</p> <p>This method is intended to free up memory (especially GPU memory) by deleting the model instance.</p> Source code in <code>culicidaelab\\core\\base_inference_backend.py</code> <pre><code>def unload_model(self) -&gt; None:\n    \"\"\"Unloads the model and releases resources.\n\n    This method is intended to free up memory (especially GPU memory) by\n    deleting the model instance.\n    \"\"\"\n    self.model = None\n    logger.info(f\"Model for {self.predictor_type} has been unloaded.\")\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BaseInferenceBackend.predict_batch","title":"<code>predict_batch(input_data_batch: list[InputDataType], show_progress: bool = False, **kwargs: Any) -&gt; list[PredictionType]</code>","text":"<p>Makes predictions on a batch of inputs.</p> <p>This method provides a default implementation that iterates through the batch and calls <code>predict</code> for each item. Backends that support native batching should override this method for better performance.</p> <p>Parameters:</p> Name Type Description Default <code>input_data_batch</code> <code>list[InputDataType]</code> <p>A list of inputs to process.</p> required <code>show_progress</code> <code>bool</code> <p>If True, displays a progress bar.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments to pass to the <code>predict</code> method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[PredictionType]</code> <p>A list of prediction results.</p> Source code in <code>culicidaelab\\core\\base_inference_backend.py</code> <pre><code>def predict_batch(\n    self,\n    input_data_batch: list[InputDataType],\n    show_progress: bool = False,\n    **kwargs: Any,\n) -&gt; list[PredictionType]:\n    \"\"\"Makes predictions on a batch of inputs.\n\n    This method provides a default implementation that iterates through the batch\n    and calls `predict` for each item. Backends that support native batching\n    should override this method for better performance.\n\n    Args:\n        input_data_batch: A list of inputs to process.\n        show_progress: If True, displays a progress bar.\n        **kwargs: Additional arguments to pass to the `predict` method.\n\n    Returns:\n        A list of prediction results.\n    \"\"\"\n    if not input_data_batch:\n        return []\n\n    if not self.is_loaded:\n        self.load_model(**kwargs)\n\n    iterator = input_data_batch\n    if show_progress:\n        iterator = progress_bar(input_data_batch, total=len(input_data_batch))\n\n    # The core logic for iterative batch prediction.\n    raw_predictions = [self.predict(input_data, **kwargs) for input_data in iterator]\n    return raw_predictions\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ConfigManager","title":"<code>ConfigManager</code>","text":"<p>Handles loading, merging, and validating configurations for the library.</p> <p>This manager implements a robust loading strategy: 1. Loads default YAML configurations bundled with the library. 2. Loads user-provided YAML configurations from a specified directory. 3. Merges the user's configuration on top of the defaults. 4. Validates the final merged configuration against Pydantic models.</p> <p>Attributes:</p> Name Type Description <code>user_config_dir</code> <code>Path | None</code> <p>The user configuration directory.</p> <code>default_config_path</code> <code>Path</code> <p>The path to the default config directory.</p> <code>config</code> <code>CulicidaeLabConfig</code> <p>The validated configuration object.</p> Source code in <code>culicidaelab\\core\\config_manager.py</code> <pre><code>class ConfigManager:\n    \"\"\"Handles loading, merging, and validating configurations for the library.\n\n    This manager implements a robust loading strategy:\n    1. Loads default YAML configurations bundled with the library.\n    2. Loads user-provided YAML configurations from a specified directory.\n    3. Merges the user's configuration on top of the defaults.\n    4. Validates the final merged configuration against Pydantic models.\n\n    Attributes:\n        user_config_dir (Path | None): The user configuration directory.\n        default_config_path (Path): The path to the default config directory.\n        config (CulicidaeLabConfig): The validated configuration object.\n    \"\"\"\n\n    def __init__(self, user_config_dir: str | Path | None = None):\n        \"\"\"Initializes the ConfigManager.\n\n        Args:\n            user_config_dir (str | Path, optional): Path to a directory containing\n                user-defined YAML configuration files. These will override the\n                defaults. Defaults to None.\n        \"\"\"\n        self.user_config_dir = Path(user_config_dir) if user_config_dir else None\n        self.default_config_path = self._get_default_config_path()\n        self.config: CulicidaeLabConfig = self._load()\n\n    def get_config(self) -&gt; CulicidaeLabConfig:\n        \"\"\"Returns the fully validated Pydantic configuration object.\n\n        Returns:\n            CulicidaeLabConfig: The `CulicidaeLabConfig` Pydantic model instance.\n        \"\"\"\n        return self.config\n\n    def instantiate_from_config(\n        self,\n        config_obj: Any,\n        extra_params: dict[str, Any] | None = None,\n        **kwargs: Any,\n    ) -&gt; Any:\n        \"\"\"Instantiates a Python object from its Pydantic config model.\n\n        The config model must have a `target` field specifying the fully\n        qualified class path (e.g., 'my_module.my_class.MyClass').\n\n        Args:\n            config_obj (Any): A Pydantic model instance (e.g., a predictor config).\n            extra_params (dict[str, Any] | None, optional): A dictionary of\n                extra parameters to inject into the constructor. Defaults to None.\n            **kwargs (Any): Additional keyword arguments to pass to the object's\n                constructor, overriding any existing parameters in the config.\n\n        Returns:\n            Any: An instantiated Python object.\n\n        Raises:\n            ValueError: If the `target` key is not found in the config object.\n            ImportError: If the class could not be imported and instantiated.\n        \"\"\"\n        if not hasattr(config_obj, \"target\"):\n            raise ValueError(\"Target key 'target' not found in configuration object\")\n\n        targetpath = config_obj.target\n        config_params = config_obj.model_dump()\n        config_params.pop(\"target\", None)\n        final_params = {}\n        if extra_params:\n            final_params.update(extra_params)\n        final_params.update(config_params)\n        final_params.update(kwargs)\n\n        try:\n            module_path, class_name = targetpath.rsplit(\".\", 1)\n            module = __import__(module_path, fromlist=[class_name])\n            cls = getattr(module, class_name)\n\n            sig = inspect.signature(cls)\n\n            has_kwargs = any(p.kind == p.VAR_KEYWORD for p in sig.parameters.values())\n\n            if not has_kwargs:\n                # Filter final_params to only include keys that are in the signature\n                allowed_keys = set(sig.parameters.keys())\n                filtered_params = {k: v for k, v in final_params.items() if k in allowed_keys}\n            else:\n                filtered_params = final_params\n\n            return cls(**filtered_params)\n        except (ValueError, ImportError, AttributeError, TypeError) as e:\n            raise ImportError(\n                f\"Could not import and instantiate '{targetpath}': {e}\",\n            )\n\n    def save_config(self, file_path: str | Path) -&gt; None:\n        \"\"\"Saves the current configuration state to a YAML file.\n\n        This is useful for exporting the fully merged and validated config.\n\n        Args:\n            file_path (str | Path): The path where the YAML config will be saved.\n        \"\"\"\n        path = Path(file_path)\n        path.parent.mkdir(parents=True, exist_ok=True)\n        config_dict = self.config.model_dump(mode=\"json\")\n        OmegaConf.save(config=config_dict, f=path)\n\n    def _get_default_config_path(self) -&gt; Path:\n        \"\"\"Reliably finds the path to the bundled 'conf' directory.\n\n        Returns:\n            Path: The absolute path to the default configuration directory.\n\n        Raises:\n            FileNotFoundError: If the default 'conf' directory cannot be found.\n        \"\"\"\n        try:\n            files = resources.files(\"culicidaelab\")\n            # Check for Traversable with _path (for installed packages)\n            if hasattr(files, \"_path\"):\n                return Path(files._path) / \"conf\"\n            # Otherwise, use string representation (for zip files, etc.)\n            else:\n                return Path(str(files)) / \"conf\"\n        except (ModuleNotFoundError, FileNotFoundError):\n            # Fallback for development mode\n            dev_path = Path(__file__).parent.parent / \"conf\"\n            if dev_path.exists():\n                return dev_path\n            raise FileNotFoundError(\n                \"Could not find the default 'conf' directory. \"\n                \"Ensure the 'culicidaelab' package is installed correctly or \"\n                \"you are in the project root.\",\n            )\n\n    def _load(self) -&gt; CulicidaeLabConfig:\n        \"\"\"Executes the full load, merge, and validation process.\n\n        Returns:\n            CulicidaeLabConfig: The validated configuration object.\n\n        Raises:\n            ValidationError: If the merged configuration fails Pydantic validation.\n        \"\"\"\n        default_config_dict = self._load_config_from_dir(\n            cast(Path, self.default_config_path),\n        )\n        user_config_dict = self._load_config_from_dir(self.user_config_dir)\n\n        # User configs override defaults\n        merged_config = _deep_merge(user_config_dict, default_config_dict)\n\n        try:\n            validated_config = CulicidaeLabConfig(**merged_config)\n            return validated_config\n        except ValidationError as e:\n            print(\n                \"FATAL: Configuration validation failed. Please check your \" \"YAML files or environment variables.\",\n            )\n            print(e)\n            raise\n\n    def _load_config_from_dir(self, config_dir: Path | None) -&gt; ConfigDict:\n        \"\"\"Loads all YAML files from a directory into a nested dictionary.\n\n        The dictionary structure mirrors the directory structure.\n\n        Args:\n            config_dir (Path | None): Directory containing YAML config files, or None.\n\n        Returns:\n            ConfigDict: A nested dictionary containing the loaded configuration.\n        \"\"\"\n        config_dict: ConfigDict = {}\n        if config_dir is None or not config_dir.is_dir():\n            return config_dict\n\n        for yaml_file in config_dir.glob(\"**/*.yaml\"):\n            try:\n                with yaml_file.open(\"r\") as f:\n                    data = yaml.safe_load(f)\n                    if data is None:\n                        continue\n\n                relative_path = yaml_file.relative_to(config_dir)\n                keys = list(relative_path.parts[:-1]) + [relative_path.stem]\n\n                d = config_dict\n                for key in keys[:-1]:\n                    d = d.setdefault(key, {})\n                d[keys[-1]] = data\n            except Exception as e:\n                print(f\"Warning: Could not load or parse {yaml_file}: {e}\")\n        return config_dict\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ConfigManager.user_config_dir","title":"<code>user_config_dir = Path(user_config_dir) if user_config_dir else None</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.ConfigManager.default_config_path","title":"<code>default_config_path = self._get_default_config_path()</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.ConfigManager.config","title":"<code>config: CulicidaeLabConfig = self._load()</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.ConfigManager.__init__","title":"<code>__init__(user_config_dir: str | Path | None = None)</code>","text":"<p>Initializes the ConfigManager.</p> <p>Parameters:</p> Name Type Description Default <code>user_config_dir</code> <code>str | Path</code> <p>Path to a directory containing user-defined YAML configuration files. These will override the defaults. Defaults to None.</p> <code>None</code> Source code in <code>culicidaelab\\core\\config_manager.py</code> <pre><code>def __init__(self, user_config_dir: str | Path | None = None):\n    \"\"\"Initializes the ConfigManager.\n\n    Args:\n        user_config_dir (str | Path, optional): Path to a directory containing\n            user-defined YAML configuration files. These will override the\n            defaults. Defaults to None.\n    \"\"\"\n    self.user_config_dir = Path(user_config_dir) if user_config_dir else None\n    self.default_config_path = self._get_default_config_path()\n    self.config: CulicidaeLabConfig = self._load()\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ConfigManager.get_config","title":"<code>get_config() -&gt; CulicidaeLabConfig</code>","text":"<p>Returns the fully validated Pydantic configuration object.</p> <p>Returns:</p> Name Type Description <code>CulicidaeLabConfig</code> <code>CulicidaeLabConfig</code> <p>The <code>CulicidaeLabConfig</code> Pydantic model instance.</p> Source code in <code>culicidaelab\\core\\config_manager.py</code> <pre><code>def get_config(self) -&gt; CulicidaeLabConfig:\n    \"\"\"Returns the fully validated Pydantic configuration object.\n\n    Returns:\n        CulicidaeLabConfig: The `CulicidaeLabConfig` Pydantic model instance.\n    \"\"\"\n    return self.config\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ConfigManager.instantiate_from_config","title":"<code>instantiate_from_config(config_obj: Any, extra_params: dict[str, Any] | None = None, **kwargs: Any) -&gt; Any</code>","text":"<p>Instantiates a Python object from its Pydantic config model.</p> <p>The config model must have a <code>target</code> field specifying the fully qualified class path (e.g., 'my_module.my_class.MyClass').</p> <p>Parameters:</p> Name Type Description Default <code>config_obj</code> <code>Any</code> <p>A Pydantic model instance (e.g., a predictor config).</p> required <code>extra_params</code> <code>dict[str, Any] | None</code> <p>A dictionary of extra parameters to inject into the constructor. Defaults to None.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to pass to the object's constructor, overriding any existing parameters in the config.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>An instantiated Python object.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the <code>target</code> key is not found in the config object.</p> <code>ImportError</code> <p>If the class could not be imported and instantiated.</p> Source code in <code>culicidaelab\\core\\config_manager.py</code> <pre><code>def instantiate_from_config(\n    self,\n    config_obj: Any,\n    extra_params: dict[str, Any] | None = None,\n    **kwargs: Any,\n) -&gt; Any:\n    \"\"\"Instantiates a Python object from its Pydantic config model.\n\n    The config model must have a `target` field specifying the fully\n    qualified class path (e.g., 'my_module.my_class.MyClass').\n\n    Args:\n        config_obj (Any): A Pydantic model instance (e.g., a predictor config).\n        extra_params (dict[str, Any] | None, optional): A dictionary of\n            extra parameters to inject into the constructor. Defaults to None.\n        **kwargs (Any): Additional keyword arguments to pass to the object's\n            constructor, overriding any existing parameters in the config.\n\n    Returns:\n        Any: An instantiated Python object.\n\n    Raises:\n        ValueError: If the `target` key is not found in the config object.\n        ImportError: If the class could not be imported and instantiated.\n    \"\"\"\n    if not hasattr(config_obj, \"target\"):\n        raise ValueError(\"Target key 'target' not found in configuration object\")\n\n    targetpath = config_obj.target\n    config_params = config_obj.model_dump()\n    config_params.pop(\"target\", None)\n    final_params = {}\n    if extra_params:\n        final_params.update(extra_params)\n    final_params.update(config_params)\n    final_params.update(kwargs)\n\n    try:\n        module_path, class_name = targetpath.rsplit(\".\", 1)\n        module = __import__(module_path, fromlist=[class_name])\n        cls = getattr(module, class_name)\n\n        sig = inspect.signature(cls)\n\n        has_kwargs = any(p.kind == p.VAR_KEYWORD for p in sig.parameters.values())\n\n        if not has_kwargs:\n            # Filter final_params to only include keys that are in the signature\n            allowed_keys = set(sig.parameters.keys())\n            filtered_params = {k: v for k, v in final_params.items() if k in allowed_keys}\n        else:\n            filtered_params = final_params\n\n        return cls(**filtered_params)\n    except (ValueError, ImportError, AttributeError, TypeError) as e:\n        raise ImportError(\n            f\"Could not import and instantiate '{targetpath}': {e}\",\n        )\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ConfigManager.save_config","title":"<code>save_config(file_path: str | Path) -&gt; None</code>","text":"<p>Saves the current configuration state to a YAML file.</p> <p>This is useful for exporting the fully merged and validated config.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | Path</code> <p>The path where the YAML config will be saved.</p> required Source code in <code>culicidaelab\\core\\config_manager.py</code> <pre><code>def save_config(self, file_path: str | Path) -&gt; None:\n    \"\"\"Saves the current configuration state to a YAML file.\n\n    This is useful for exporting the fully merged and validated config.\n\n    Args:\n        file_path (str | Path): The path where the YAML config will be saved.\n    \"\"\"\n    path = Path(file_path)\n    path.parent.mkdir(parents=True, exist_ok=True)\n    config_dict = self.config.model_dump(mode=\"json\")\n    OmegaConf.save(config=config_dict, f=path)\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.CulicidaeLabConfig","title":"<code>CulicidaeLabConfig</code>","text":"<p>The root Pydantic model for all CulicidaeLab configurations.</p> <p>This model validates the entire configuration structure after it is loaded from YAML files, serving as the single source of truth for all settings.</p> <p>Attributes:</p> Name Type Description <code>config_version</code> <code>str</code> <p>The version of the configuration schema. This is used to ensure compatibility with the library version.</p> <code>app_settings</code> <code>AppSettings</code> <p>Core application settings.</p> <code>processing</code> <code>ProcessingConfig</code> <p>Default processing parameters.</p> <code>datasets</code> <code>dict[str, DatasetConfig]</code> <p>A mapping of dataset names to their configs.</p> <code>predictors</code> <code>dict[str, PredictorConfig]</code> <p>A mapping of predictor names to their configs.</p> <code>providers</code> <code>dict[str, ProviderConfig]</code> <p>A mapping of provider names to their configs.</p> <code>species</code> <code>SpeciesModel</code> <p>Configuration and metadata related to all species.</p> Source code in <code>culicidaelab\\core\\config_models.py</code> <pre><code>class CulicidaeLabConfig(BaseModel):\n    \"\"\"The root Pydantic model for all CulicidaeLab configurations.\n\n    This model validates the entire configuration structure after it is loaded\n    from YAML files, serving as the single source of truth for all settings.\n\n    Attributes:\n        config_version (str): The version of the configuration schema. This is used\n            to ensure compatibility with the library version.\n        app_settings (AppSettings): Core application settings.\n        processing (ProcessingConfig): Default processing parameters.\n        datasets (dict[str, DatasetConfig]): A mapping of dataset names to their configs.\n        predictors (dict[str, PredictorConfig]): A mapping of predictor names to their configs.\n        providers (dict[str, ProviderConfig]): A mapping of provider names to their configs.\n        species (SpeciesModel): Configuration and metadata related to all species.\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n    config_version: str = Field(default=CONFIG_SCHEMA_VERSION)\n    app_settings: AppSettings = Field(default_factory=AppSettings)\n    processing: ProcessingConfig = Field(default_factory=ProcessingConfig)\n    datasets: dict[str, DatasetConfig] = Field(default_factory=dict)\n    predictors: dict[str, PredictorConfig] = Field(default_factory=dict)\n    providers: dict[str, ProviderConfig] = Field(default_factory=dict)\n    species: SpeciesModel = Field(default_factory=SpeciesModel)\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.CulicidaeLabConfig.model_config","title":"<code>model_config = ConfigDict(extra='allow')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.CulicidaeLabConfig.config_version","title":"<code>config_version: str = Field(default=CONFIG_SCHEMA_VERSION)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.CulicidaeLabConfig.app_settings","title":"<code>app_settings: AppSettings = Field(default_factory=AppSettings)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.CulicidaeLabConfig.processing","title":"<code>processing: ProcessingConfig = Field(default_factory=ProcessingConfig)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.CulicidaeLabConfig.datasets","title":"<code>datasets: dict[str, DatasetConfig] = Field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.CulicidaeLabConfig.predictors","title":"<code>predictors: dict[str, PredictorConfig] = Field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.CulicidaeLabConfig.providers","title":"<code>providers: dict[str, ProviderConfig] = Field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.CulicidaeLabConfig.species","title":"<code>species: SpeciesModel = Field(default_factory=SpeciesModel)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.DatasetConfig","title":"<code>DatasetConfig</code>","text":"<p>Configuration for a single dataset.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>The unique internal name for the dataset.</p> <code>path</code> <code>str</code> <p>The local directory path for storing the dataset.</p> <code>format</code> <code>str</code> <p>The dataset format (e.g., \"imagefolder\", \"coco\", \"yolo\").</p> <code>classes</code> <code>list[str]</code> <p>A list of class names present in the dataset.</p> <code>provider_name</code> <code>str</code> <p>The name of the data provider (e.g., \"huggingface\").</p> <code>repository</code> <code>str</code> <p>The repository ID on the provider's platform.</p> <code>config_name</code> <code>str | None</code> <p>The specific configuration of a Hugging Face dataset.</p> <code>derived_datasets</code> <code>list[str] | None</code> <p>A list of Hugging Face repository IDs for datasets that were derived from this one. Defaults to None.</p> <code>trained_models_repositories</code> <code>list[str] | None</code> <p>A list of Hugging Face repository IDs for models trained on this dataset. Defaults to None.</p> Source code in <code>culicidaelab\\core\\config_models.py</code> <pre><code>class DatasetConfig(BaseModel):\n    \"\"\"Configuration for a single dataset.\n\n    Attributes:\n        name (str): The unique internal name for the dataset.\n        path (str): The local directory path for storing the dataset.\n        format (str): The dataset format (e.g., \"imagefolder\", \"coco\", \"yolo\").\n        classes (list[str]): A list of class names present in the dataset.\n        provider_name (str): The name of the data provider (e.g., \"huggingface\").\n        repository (str): The repository ID on the provider's platform.\n        config_name (str | None): The specific configuration of a Hugging Face dataset.\n        derived_datasets (list[str] | None): A list of Hugging Face repository IDs\n            for datasets that were derived from this one. Defaults to None.\n        trained_models_repositories (list[str] | None): A list of Hugging Face\n            repository IDs for models trained on this dataset. Defaults to None.\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n    name: str\n    path: str\n    format: str\n    classes: list[str]\n    provider_name: str\n    repository: str\n    config_name: str | None = \"default\"\n    derived_datasets: list[str] | None = None\n    trained_models_repositories: list[str] | None = None\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.DatasetConfig.model_config","title":"<code>model_config = ConfigDict(extra='allow')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.DatasetConfig.name","title":"<code>name: str</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.DatasetConfig.path","title":"<code>path: str</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.DatasetConfig.format","title":"<code>format: str</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.DatasetConfig.classes","title":"<code>classes: list[str]</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.DatasetConfig.provider_name","title":"<code>provider_name: str</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.DatasetConfig.repository","title":"<code>repository: str</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.DatasetConfig.config_name","title":"<code>config_name: str | None = 'default'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.DatasetConfig.derived_datasets","title":"<code>derived_datasets: list[str] | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.DatasetConfig.trained_models_repositories","title":"<code>trained_models_repositories: list[str] | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.PredictorConfig","title":"<code>PredictorConfig</code>","text":"<p>Configuration for a single inference predictor.</p> <p>This model defines how to load and use a specific pre-trained model for inference.</p> <p>Attributes:</p> Name Type Description <code>target</code> <code>str</code> <p>The fully qualified import path to the predictor class (e.g., <code>culicidaelab.models.YOLOv8Predictor</code>).</p> <code>confidence</code> <code>float</code> <p>The default confidence threshold for this predictor.</p> <code>device</code> <code>str</code> <p>The compute device to use (\"cpu\" or \"cuda\").</p> <code>backend</code> <code>str | None</code> <p>The specific inference backend to use (e.g., 'yolo').</p> <code>params</code> <code>dict[str, Any]</code> <p>A dictionary of extra parameters to pass to the predictor's constructor.</p> <code>repository_id</code> <code>str | None</code> <p>The Hugging Face Hub repository ID for the model.</p> <code>weights</code> <code>dict[str, WeightDetails] | None</code> <p>A mapping of backend names to their weight details.</p> <code>provider_name</code> <code>str | None</code> <p>The name of the provider (e.g., \"huggingface\").</p> <code>model_arch</code> <code>str | None</code> <p>The model architecture name (e.g., \"yolov8n-seg\").</p> <code>model_config_path</code> <code>str | None</code> <p>The path to the model's specific config file.</p> <code>model_config_filename</code> <code>str | None</code> <p>The filename of the model's config.</p> <code>visualization</code> <code>VisualizationConfig</code> <p>Custom visualization settings for this predictor.</p> Source code in <code>culicidaelab\\core\\config_models.py</code> <pre><code>class PredictorConfig(BaseModel):\n    \"\"\"Configuration for a single inference predictor.\n\n    This model defines how to load and use a specific pre-trained model for inference.\n\n    Attributes:\n        target (str): The fully qualified import path to the predictor class\n            (e.g., `culicidaelab.models.YOLOv8Predictor`).\n        confidence (float): The default confidence threshold for this predictor.\n        device (str): The compute device to use (\"cpu\" or \"cuda\").\n        backend (str | None): The specific inference backend to use (e.g., 'yolo').\n        params (dict[str, Any]): A dictionary of extra parameters to pass to the\n            predictor's constructor.\n        repository_id (str | None): The Hugging Face Hub repository ID for the model.\n        weights (dict[str, WeightDetails] | None): A mapping of backend names to their\n            weight details.\n        provider_name (str | None): The name of the provider (e.g., \"huggingface\").\n        model_arch (str | None): The model architecture name (e.g., \"yolov8n-seg\").\n        model_config_path (str | None): The path to the model's specific config file.\n        model_config_filename (str | None): The filename of the model's config.\n        visualization (VisualizationConfig): Custom visualization settings for this predictor.\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\", protected_namespaces=())\n    target: str = Field(..., alias=\"target\")\n    confidence: float = 0.5\n    device: str = \"cpu\"\n    backend: str | None = None\n    params: dict[str, Any] = Field(default_factory=dict)\n    repository_id: str | None = None\n    weights: dict[str, WeightDetails] | None = None\n    provider_name: str | None = None\n    model_arch: str | None = None\n    model_config_path: str | None = None\n    model_config_filename: str | None = None\n    visualization: VisualizationConfig = Field(default_factory=VisualizationConfig)\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.PredictorConfig.model_config","title":"<code>model_config = ConfigDict(extra='allow', protected_namespaces=())</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.PredictorConfig.target","title":"<code>target: str = Field(..., alias='target')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.PredictorConfig.confidence","title":"<code>confidence: float = 0.5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.PredictorConfig.device","title":"<code>device: str = 'cpu'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.PredictorConfig.backend","title":"<code>backend: str | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.PredictorConfig.params","title":"<code>params: dict[str, Any] = Field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.PredictorConfig.repository_id","title":"<code>repository_id: str | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.PredictorConfig.weights","title":"<code>weights: dict[str, WeightDetails] | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.PredictorConfig.provider_name","title":"<code>provider_name: str | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.PredictorConfig.model_arch","title":"<code>model_arch: str | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.PredictorConfig.model_config_path","title":"<code>model_config_path: str | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.PredictorConfig.model_config_filename","title":"<code>model_config_filename: str | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.PredictorConfig.visualization","title":"<code>visualization: VisualizationConfig = Field(default_factory=VisualizationConfig)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.ProviderConfig","title":"<code>ProviderConfig</code>","text":"<p>Configuration for a data provider, such as Hugging Face.</p> <p>Attributes:</p> Name Type Description <code>target</code> <code>str</code> <p>The fully qualified import path to the provider's service class.</p> <code>dataset_url</code> <code>str</code> <p>The base URL for accessing datasets from this provider.</p> <code>api_key</code> <code>str | None</code> <p>An optional API key for authentication, if required.</p> Source code in <code>culicidaelab\\core\\config_models.py</code> <pre><code>class ProviderConfig(BaseModel):\n    \"\"\"Configuration for a data provider, such as Hugging Face.\n\n    Attributes:\n        target (str): The fully qualified import path to the provider's\n            service class.\n        dataset_url (str): The base URL for accessing datasets from this provider.\n        api_key (str | None): An optional API key for authentication, if required.\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n    target: str = Field(..., alias=\"target\")\n    dataset_url: str\n    api_key: str | None = None\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ProviderConfig.model_config","title":"<code>model_config = ConfigDict(extra='allow')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.ProviderConfig.target","title":"<code>target: str = Field(..., alias='target')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.ProviderConfig.dataset_url","title":"<code>dataset_url: str</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.ProviderConfig.api_key","title":"<code>api_key: str | None = None</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.SpeciesModel","title":"<code>SpeciesModel</code>","text":"<p>Configuration for the entire 'species' section of the config.</p> <p>Attributes:</p> Name Type Description <code>species_classes</code> <code>dict[int, str]</code> <p>A mapping of integer class IDs to string-based species names.</p> <code>species_metadata</code> <code>SpeciesFiles</code> <p>The aggregated species metadata loaded from the species directory.</p> Source code in <code>culicidaelab\\core\\config_models.py</code> <pre><code>class SpeciesModel(BaseModel):\n    \"\"\"Configuration for the entire 'species' section of the config.\n\n    Attributes:\n        species_classes (dict[int, str]): A mapping of integer class IDs to\n            string-based species names.\n        species_metadata (SpeciesFiles): The aggregated species metadata loaded\n            from the species directory.\n    \"\"\"\n\n    model_config = ConfigDict(extra=\"allow\")\n    species_classes: dict[int, str] = Field(default_factory=dict)\n    species_metadata: SpeciesFiles = Field(default_factory=SpeciesFiles)\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.SpeciesModel.model_config","title":"<code>model_config = ConfigDict(extra='allow')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.SpeciesModel.species_classes","title":"<code>species_classes: dict[int, str] = Field(default_factory=dict)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.SpeciesModel.species_metadata","title":"<code>species_metadata: SpeciesFiles = Field(default_factory=SpeciesFiles)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.SpeciesConfig","title":"<code>SpeciesConfig</code>","text":"<p>A user-friendly facade for accessing and managing species configuration data.</p> <p>This class implements the Facade pattern to simplify access to species-related configuration data. It provides an intuitive interface for managing species information, including class mappings, metadata, and name translations.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>SpeciesModel</code> <p>A validated Pydantic model containing the complete species configuration data.</p> required <p>Attributes:</p> Name Type Description <code>_config</code> <code>SpeciesModel</code> <p>The source configuration model containing raw data.</p> <code>_species_map</code> <code>dict[int, str]</code> <p>Maps numeric class indices to full species names.</p> <code>_reverse_species_map</code> <code>dict[str, int]</code> <p>Maps full species names to their numeric indices.</p> <code>_metadata_store</code> <code>dict</code> <p>Contains detailed metadata for each species.</p> <code>class_to_full_name_map</code> <code>dict[str, str]</code> <p>Maps short class names to full scientific names.</p> <code>reverse_class_to_full_name_map</code> <code>dict[str, str]</code> <p>Maps full scientific names to short class names.</p> Example <pre><code>config = SpeciesModel(...)  # Your validated config\nspecies_helper = SpeciesConfig(config)\n\n# Get full name for a class index\nspecies_name = species_helper.get_species_by_index(0)\n\n# Get metadata for a species\nmetadata = species_helper.get_species_metadata(species_name)\n</code></pre> Source code in <code>culicidaelab\\core\\species_config.py</code> <pre><code>class SpeciesConfig:\n    \"\"\"A user-friendly facade for accessing and managing species configuration data.\n\n    This class implements the Facade pattern to simplify access to species-related\n    configuration data. It provides an intuitive interface for managing species\n    information, including class mappings, metadata, and name translations.\n\n    Args:\n        config (SpeciesModel): A validated Pydantic model containing the complete\n            species configuration data.\n\n    Attributes:\n        _config (SpeciesModel): The source configuration model containing raw data.\n        _species_map (dict[int, str]): Maps numeric class indices to full species names.\n        _reverse_species_map (dict[str, int]): Maps full species names to their numeric indices.\n        _metadata_store (dict): Contains detailed metadata for each species.\n        class_to_full_name_map (dict[str, str]): Maps short class names to full scientific names.\n        reverse_class_to_full_name_map (dict[str, str]): Maps full scientific names to short class names.\n\n    Example:\n        ```python\n        config = SpeciesModel(...)  # Your validated config\n        species_helper = SpeciesConfig(config)\n\n        # Get full name for a class index\n        species_name = species_helper.get_species_by_index(0)\n\n        # Get metadata for a species\n        metadata = species_helper.get_species_metadata(species_name)\n        ```\n    \"\"\"\n\n    def __init__(self, config: SpeciesModel):\n        \"\"\"Initializes the species configuration helper.\n\n        Sets up internal mappings and data structures for efficient species data access.\n        Processes the input configuration to create bidirectional mappings between\n        species names, class names, and indices.\n\n        Args:\n            config (SpeciesModel): The validated species configuration model.\n        \"\"\"\n        self._config = config\n        self._species_map: dict[int, str] = {}\n        self.class_to_full_name_map = self._config.species_metadata.species_info_mapping\n        self.reverse_class_to_full_name_map = {v: k for k, v in self.class_to_full_name_map.items()}\n\n        for idx, class_name in self._config.species_classes.items():\n            full_name = self.class_to_full_name_map.get(class_name, class_name)\n            self._species_map[idx] = full_name\n\n        self._reverse_species_map: dict[str, int] = {name: idx for idx, name in self._species_map.items()}\n        self._metadata_store: dict[\n            str,\n            SingleSpeciesMetadataModel,\n        ] = self._config.species_metadata.species_metadata\n\n    @property\n    def species_map(self) -&gt; dict[int, str]:\n        \"\"\"Gets the mapping of class indices to full, human-readable species names.\n\n        Returns:\n            dict[int, str]: A dictionary mapping numeric class indices to full\n                scientific species names.\n\n        Example:\n            ```python\n            species_config = SpeciesConfig(config)\n            mapping = species_config.species_map\n            # Returns: {0: \"Aedes aegypti\", 1: \"Aedes albopictus\"}\n            ```\n        \"\"\"\n        return self._species_map\n\n    def get_index_by_species(self, species_name: str) -&gt; int | None:\n        \"\"\"Gets the numeric class index for a given species name.\n\n        Looks up the numeric class index used by the model for a given full\n        species name. This is useful for mapping between model predictions\n        and species names.\n\n        Args:\n            species_name (str): The full scientific name of the species\n                (e.g., \"Aedes aegypti\").\n\n        Returns:\n            int | None: The numeric class index used by the model, or None if the\n                species is not found in the configuration.\n\n        Example:\n            ```python\n            index = species_config.get_index_by_species(\"Aedes aegypti\")\n            # Returns: 0\n            ```\n        \"\"\"\n        return self._reverse_species_map.get(species_name)\n\n    def get_species_by_index(self, index: int) -&gt; str | None:\n        \"\"\"Gets the full scientific species name for a given class index.\n\n        Converts a numeric class index used by the model into the corresponding\n        full scientific species name. This is particularly useful when processing\n        model predictions.\n\n        Args:\n            index (int): The numeric class index used by the model.\n\n        Returns:\n            str | None: The full scientific species name as a string, or None if the\n                index is not found in the configuration.\n\n        Example:\n            ```python\n            species = species_config.get_species_by_index(0)\n            # Returns: \"Aedes aegypti\"\n            ```\n        \"\"\"\n        return self._species_map.get(index)\n\n    def get_species_label(self, species_name: str) -&gt; str:\n        \"\"\"Gets the short label/class name for a given full species name.\n\n        Converts a full scientific species name to its corresponding short label\n        used in the dataset and model classifications.\n\n        Args:\n            species_name (str): The full scientific name of the species\n                (e.g., \"Aedes aegypti\").\n\n        Returns:\n            str: The short label/class name used in the dataset\n                (e.g., \"ae_aegypti\").\n\n        Example:\n            ```python\n            label = species_config.get_species_label(\"Aedes aegypti\")\n            # Returns: \"ae_aegypti\"\n            ```\n        \"\"\"\n        return self.reverse_class_to_full_name_map[species_name]\n\n    def get_species_metadata(self, species_name: str) -&gt; dict[str, Any] | None:\n        \"\"\"Gets the detailed metadata for a specific species.\n\n        Retrieves comprehensive metadata about a species, including taxonomic\n        information, characteristics, and any custom metadata fields defined\n        in the configuration.\n\n        Args:\n            species_name (str): The full scientific name of the species\n                (e.g., \"Aedes aegypti\").\n\n        Returns:\n            dict[str, Any] | None: A dictionary containing all metadata fields for the\n                species, or None if the species is not found. The dictionary structure\n                depends on the metadata fields defined in the configuration.\n\n        Example:\n            ```python\n            metadata = species_config.get_species_metadata(\"Aedes aegypti\")\n            # Returns: {\n            #     \"family\": \"Culicidae\",\n            #     \"genus\": \"Aedes\",\n            #     \"species\": \"aegypti\",\n            #     \"common_name\": \"Yellow fever mosquito\",\n            #     ...\n            # }\n            ```\n        \"\"\"\n        model_object = self._metadata_store.get(species_name)\n        return model_object.model_dump() if model_object else None\n\n    def list_species_names(self) -&gt; list[str]:\n        \"\"\"Returns a list of all configured full species names.\n\n        Provides a complete list of all species names that are configured in the system.\n        The names are returned in their full scientific format.\n\n        Returns:\n            list[str]: A list of full scientific species names configured in the system.\n\n        Example:\n            ```python\n            species_list = species_config.list_species_names()\n            # Returns: [\"Aedes aegypti\", \"Aedes albopictus\", ...]\n            ```\n        \"\"\"\n        return list(self._reverse_species_map.keys())\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.SpeciesConfig.class_to_full_name_map","title":"<code>class_to_full_name_map = self._config.species_metadata.species_info_mapping</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.SpeciesConfig.reverse_class_to_full_name_map","title":"<code>reverse_class_to_full_name_map = {v: kfor (k, v) in (self.class_to_full_name_map.items())}</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.SpeciesConfig.species_map","title":"<code>species_map: dict[int, str]</code>  <code>property</code>","text":"<p>Gets the mapping of class indices to full, human-readable species names.</p> <p>Returns:</p> Type Description <code>dict[int, str]</code> <p>dict[int, str]: A dictionary mapping numeric class indices to full scientific species names.</p> Example <pre><code>species_config = SpeciesConfig(config)\nmapping = species_config.species_map\n# Returns: {0: \"Aedes aegypti\", 1: \"Aedes albopictus\"}\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.SpeciesConfig.__init__","title":"<code>__init__(config: SpeciesModel)</code>","text":"<p>Initializes the species configuration helper.</p> <p>Sets up internal mappings and data structures for efficient species data access. Processes the input configuration to create bidirectional mappings between species names, class names, and indices.</p> <p>Parameters:</p> Name Type Description Default <code>config</code> <code>SpeciesModel</code> <p>The validated species configuration model.</p> required Source code in <code>culicidaelab\\core\\species_config.py</code> <pre><code>def __init__(self, config: SpeciesModel):\n    \"\"\"Initializes the species configuration helper.\n\n    Sets up internal mappings and data structures for efficient species data access.\n    Processes the input configuration to create bidirectional mappings between\n    species names, class names, and indices.\n\n    Args:\n        config (SpeciesModel): The validated species configuration model.\n    \"\"\"\n    self._config = config\n    self._species_map: dict[int, str] = {}\n    self.class_to_full_name_map = self._config.species_metadata.species_info_mapping\n    self.reverse_class_to_full_name_map = {v: k for k, v in self.class_to_full_name_map.items()}\n\n    for idx, class_name in self._config.species_classes.items():\n        full_name = self.class_to_full_name_map.get(class_name, class_name)\n        self._species_map[idx] = full_name\n\n    self._reverse_species_map: dict[str, int] = {name: idx for idx, name in self._species_map.items()}\n    self._metadata_store: dict[\n        str,\n        SingleSpeciesMetadataModel,\n    ] = self._config.species_metadata.species_metadata\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.SpeciesConfig.get_index_by_species","title":"<code>get_index_by_species(species_name: str) -&gt; int | None</code>","text":"<p>Gets the numeric class index for a given species name.</p> <p>Looks up the numeric class index used by the model for a given full species name. This is useful for mapping between model predictions and species names.</p> <p>Parameters:</p> Name Type Description Default <code>species_name</code> <code>str</code> <p>The full scientific name of the species (e.g., \"Aedes aegypti\").</p> required <p>Returns:</p> Type Description <code>int | None</code> <p>int | None: The numeric class index used by the model, or None if the species is not found in the configuration.</p> Example <pre><code>index = species_config.get_index_by_species(\"Aedes aegypti\")\n# Returns: 0\n</code></pre> Source code in <code>culicidaelab\\core\\species_config.py</code> <pre><code>def get_index_by_species(self, species_name: str) -&gt; int | None:\n    \"\"\"Gets the numeric class index for a given species name.\n\n    Looks up the numeric class index used by the model for a given full\n    species name. This is useful for mapping between model predictions\n    and species names.\n\n    Args:\n        species_name (str): The full scientific name of the species\n            (e.g., \"Aedes aegypti\").\n\n    Returns:\n        int | None: The numeric class index used by the model, or None if the\n            species is not found in the configuration.\n\n    Example:\n        ```python\n        index = species_config.get_index_by_species(\"Aedes aegypti\")\n        # Returns: 0\n        ```\n    \"\"\"\n    return self._reverse_species_map.get(species_name)\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.SpeciesConfig.get_species_by_index","title":"<code>get_species_by_index(index: int) -&gt; str | None</code>","text":"<p>Gets the full scientific species name for a given class index.</p> <p>Converts a numeric class index used by the model into the corresponding full scientific species name. This is particularly useful when processing model predictions.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>int</code> <p>The numeric class index used by the model.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>str | None: The full scientific species name as a string, or None if the index is not found in the configuration.</p> Example <pre><code>species = species_config.get_species_by_index(0)\n# Returns: \"Aedes aegypti\"\n</code></pre> Source code in <code>culicidaelab\\core\\species_config.py</code> <pre><code>def get_species_by_index(self, index: int) -&gt; str | None:\n    \"\"\"Gets the full scientific species name for a given class index.\n\n    Converts a numeric class index used by the model into the corresponding\n    full scientific species name. This is particularly useful when processing\n    model predictions.\n\n    Args:\n        index (int): The numeric class index used by the model.\n\n    Returns:\n        str | None: The full scientific species name as a string, or None if the\n            index is not found in the configuration.\n\n    Example:\n        ```python\n        species = species_config.get_species_by_index(0)\n        # Returns: \"Aedes aegypti\"\n        ```\n    \"\"\"\n    return self._species_map.get(index)\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.SpeciesConfig.get_species_label","title":"<code>get_species_label(species_name: str) -&gt; str</code>","text":"<p>Gets the short label/class name for a given full species name.</p> <p>Converts a full scientific species name to its corresponding short label used in the dataset and model classifications.</p> <p>Parameters:</p> Name Type Description Default <code>species_name</code> <code>str</code> <p>The full scientific name of the species (e.g., \"Aedes aegypti\").</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The short label/class name used in the dataset (e.g., \"ae_aegypti\").</p> Example <pre><code>label = species_config.get_species_label(\"Aedes aegypti\")\n# Returns: \"ae_aegypti\"\n</code></pre> Source code in <code>culicidaelab\\core\\species_config.py</code> <pre><code>def get_species_label(self, species_name: str) -&gt; str:\n    \"\"\"Gets the short label/class name for a given full species name.\n\n    Converts a full scientific species name to its corresponding short label\n    used in the dataset and model classifications.\n\n    Args:\n        species_name (str): The full scientific name of the species\n            (e.g., \"Aedes aegypti\").\n\n    Returns:\n        str: The short label/class name used in the dataset\n            (e.g., \"ae_aegypti\").\n\n    Example:\n        ```python\n        label = species_config.get_species_label(\"Aedes aegypti\")\n        # Returns: \"ae_aegypti\"\n        ```\n    \"\"\"\n    return self.reverse_class_to_full_name_map[species_name]\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.SpeciesConfig.get_species_metadata","title":"<code>get_species_metadata(species_name: str) -&gt; dict[str, Any] | None</code>","text":"<p>Gets the detailed metadata for a specific species.</p> <p>Retrieves comprehensive metadata about a species, including taxonomic information, characteristics, and any custom metadata fields defined in the configuration.</p> <p>Parameters:</p> Name Type Description Default <code>species_name</code> <code>str</code> <p>The full scientific name of the species (e.g., \"Aedes aegypti\").</p> required <p>Returns:</p> Type Description <code>dict[str, Any] | None</code> <p>dict[str, Any] | None: A dictionary containing all metadata fields for the species, or None if the species is not found. The dictionary structure depends on the metadata fields defined in the configuration.</p> Example <pre><code>metadata = species_config.get_species_metadata(\"Aedes aegypti\")\n# Returns: {\n#     \"family\": \"Culicidae\",\n#     \"genus\": \"Aedes\",\n#     \"species\": \"aegypti\",\n#     \"common_name\": \"Yellow fever mosquito\",\n#     ...\n# }\n</code></pre> Source code in <code>culicidaelab\\core\\species_config.py</code> <pre><code>def get_species_metadata(self, species_name: str) -&gt; dict[str, Any] | None:\n    \"\"\"Gets the detailed metadata for a specific species.\n\n    Retrieves comprehensive metadata about a species, including taxonomic\n    information, characteristics, and any custom metadata fields defined\n    in the configuration.\n\n    Args:\n        species_name (str): The full scientific name of the species\n            (e.g., \"Aedes aegypti\").\n\n    Returns:\n        dict[str, Any] | None: A dictionary containing all metadata fields for the\n            species, or None if the species is not found. The dictionary structure\n            depends on the metadata fields defined in the configuration.\n\n    Example:\n        ```python\n        metadata = species_config.get_species_metadata(\"Aedes aegypti\")\n        # Returns: {\n        #     \"family\": \"Culicidae\",\n        #     \"genus\": \"Aedes\",\n        #     \"species\": \"aegypti\",\n        #     \"common_name\": \"Yellow fever mosquito\",\n        #     ...\n        # }\n        ```\n    \"\"\"\n    model_object = self._metadata_store.get(species_name)\n    return model_object.model_dump() if model_object else None\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.SpeciesConfig.list_species_names","title":"<code>list_species_names() -&gt; list[str]</code>","text":"<p>Returns a list of all configured full species names.</p> <p>Provides a complete list of all species names that are configured in the system. The names are returned in their full scientific format.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of full scientific species names configured in the system.</p> Example <pre><code>species_list = species_config.list_species_names()\n# Returns: [\"Aedes aegypti\", \"Aedes albopictus\", ...]\n</code></pre> Source code in <code>culicidaelab\\core\\species_config.py</code> <pre><code>def list_species_names(self) -&gt; list[str]:\n    \"\"\"Returns a list of all configured full species names.\n\n    Provides a complete list of all species names that are configured in the system.\n    The names are returned in their full scientific format.\n\n    Returns:\n        list[str]: A list of full scientific species names configured in the system.\n\n    Example:\n        ```python\n        species_list = species_config.list_species_names()\n        # Returns: [\"Aedes aegypti\", \"Aedes albopictus\", ...]\n        ```\n    \"\"\"\n    return list(self._reverse_species_map.keys())\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BoundingBox","title":"<code>BoundingBox</code>","text":"<p>Represents a single bounding box with coordinates.</p> <p>Attributes:</p> Name Type Description <code>x1</code> <code>float</code> <p>The top-left x-coordinate of the bounding box.</p> <code>y1</code> <code>float</code> <p>The top-left y-coordinate of the bounding box.</p> <code>x2</code> <code>float</code> <p>The bottom-right x-coordinate of the bounding box.</p> <code>y2</code> <code>float</code> <p>The bottom-right y-coordinate of the bounding box.</p> Source code in <code>culicidaelab\\core\\prediction_models.py</code> <pre><code>class BoundingBox(BaseModel):\n    \"\"\"Represents a single bounding box with coordinates.\n\n    Attributes:\n        x1 (float): The top-left x-coordinate of the bounding box.\n        y1 (float): The top-left y-coordinate of the bounding box.\n        x2 (float): The bottom-right x-coordinate of the bounding box.\n        y2 (float): The bottom-right y-coordinate of the bounding box.\n    \"\"\"\n\n    x1: float = Field(..., description=\"Top-left x-coordinate\")\n    y1: float = Field(..., description=\"Top-left y-coordinate\")\n    x2: float = Field(..., description=\"Bottom-right x-coordinate\")\n    y2: float = Field(..., description=\"Bottom-right y-coordinate\")\n\n    def to_numpy(self) -&gt; np.ndarray:\n        \"\"\"Converts the bounding box to a NumPy array.\n\n        Returns:\n            np.ndarray: A NumPy array of shape (4,) in the format [x1, y1, x2, y2].\n        \"\"\"\n        return np.array([self.x1, self.y1, self.x2, self.y2])\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.BoundingBox.x1","title":"<code>x1: float = Field(..., description='Top-left x-coordinate')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.BoundingBox.y1","title":"<code>y1: float = Field(..., description='Top-left y-coordinate')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.BoundingBox.x2","title":"<code>x2: float = Field(..., description='Bottom-right x-coordinate')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.BoundingBox.y2","title":"<code>y2: float = Field(..., description='Bottom-right y-coordinate')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.BoundingBox.to_numpy","title":"<code>to_numpy() -&gt; np.ndarray</code>","text":"<p>Converts the bounding box to a NumPy array.</p> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: A NumPy array of shape (4,) in the format [x1, y1, x2, y2].</p> Source code in <code>culicidaelab\\core\\prediction_models.py</code> <pre><code>def to_numpy(self) -&gt; np.ndarray:\n    \"\"\"Converts the bounding box to a NumPy array.\n\n    Returns:\n        np.ndarray: A NumPy array of shape (4,) in the format [x1, y1, x2, y2].\n    \"\"\"\n    return np.array([self.x1, self.y1, self.x2, self.y2])\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.Detection","title":"<code>Detection</code>","text":"<p>Represents a single detected object, including its bounding box and confidence.</p> <p>Attributes:</p> Name Type Description <code>box</code> <code>BoundingBox</code> <p>The bounding box of the detected object.</p> <code>confidence</code> <code>float</code> <p>The confidence score of the prediction, between 0.0 and 1.0.</p> Source code in <code>culicidaelab\\core\\prediction_models.py</code> <pre><code>class Detection(BaseModel):\n    \"\"\"Represents a single detected object, including its bounding box and confidence.\n\n    Attributes:\n        box (BoundingBox): The bounding box of the detected object.\n        confidence (float): The confidence score of the prediction, between 0.0 and 1.0.\n    \"\"\"\n\n    box: BoundingBox\n    confidence: float = Field(..., ge=0.0, le=1.0, description=\"Prediction confidence score\")\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.Detection.box","title":"<code>box: BoundingBox</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.Detection.confidence","title":"<code>confidence: float = Field(..., ge=0.0, le=1.0, description='Prediction confidence score')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.DetectionPrediction","title":"<code>DetectionPrediction</code>","text":"<p>Represents the output of a detection model for a single image.</p> <p>Attributes:</p> Name Type Description <code>detections</code> <code>list[Detection]</code> <p>A list of all objects detected in the image.</p> Source code in <code>culicidaelab\\core\\prediction_models.py</code> <pre><code>class DetectionPrediction(BaseModel):\n    \"\"\"Represents the output of a detection model for a single image.\n\n    Attributes:\n        detections (list[Detection]): A list of all objects detected in the image.\n    \"\"\"\n\n    detections: list[Detection]\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.DetectionPrediction.detections","title":"<code>detections: list[Detection]</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.SegmentationPrediction","title":"<code>SegmentationPrediction</code>","text":"<p>Represents the output of a segmentation model for a single image.</p> <p>Attributes:</p> Name Type Description <code>mask</code> <code>ndarray</code> <p>A 2D NumPy array (H, W) representing the binary segmentation mask, where non-zero values indicate the segmented object.</p> <code>pixel_count</code> <code>int</code> <p>The total number of positive (masked) pixels in the mask.</p> Source code in <code>culicidaelab\\core\\prediction_models.py</code> <pre><code>class SegmentationPrediction(BaseModel):\n    \"\"\"Represents the output of a segmentation model for a single image.\n\n    Attributes:\n        mask (np.ndarray): A 2D NumPy array (H, W) representing the binary\n            segmentation mask, where non-zero values indicate the segmented object.\n        pixel_count (int): The total number of positive (masked) pixels in the mask.\n    \"\"\"\n\n    model_config = ConfigDict(arbitrary_types_allowed=True)\n    mask: np.ndarray = Field(..., description=\"Binary segmentation mask as a NumPy array (H, W)\")\n    pixel_count: int = Field(..., description=\"Number of positive (masked) pixels\")\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.SegmentationPrediction.model_config","title":"<code>model_config = ConfigDict(arbitrary_types_allowed=True)</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.SegmentationPrediction.mask","title":"<code>mask: np.ndarray = Field(..., description='Binary segmentation mask as a NumPy array (H, W)')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.SegmentationPrediction.pixel_count","title":"<code>pixel_count: int = Field(..., description='Number of positive (masked) pixels')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.Classification","title":"<code>Classification</code>","text":"<p>Represents a single classification result with species name and confidence.</p> <p>Attributes:</p> Name Type Description <code>species_name</code> <code>str</code> <p>The predicted species name.</p> <code>confidence</code> <code>float</code> <p>The confidence score of the prediction, between 0.0 and 1.0.</p> Source code in <code>culicidaelab\\core\\prediction_models.py</code> <pre><code>class Classification(BaseModel):\n    \"\"\"Represents a single classification result with species name and confidence.\n\n    Attributes:\n        species_name (str): The predicted species name.\n        confidence (float): The confidence score of the prediction, between 0.0 and 1.0.\n    \"\"\"\n\n    species_name: str\n    confidence: float = Field(..., ge=0.0, le=1.0, description=\"Prediction confidence score\")\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.Classification.species_name","title":"<code>species_name: str</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.Classification.confidence","title":"<code>confidence: float = Field(..., ge=0.0, le=1.0, description='Prediction confidence score')</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.ClassificationPrediction","title":"<code>ClassificationPrediction</code>","text":"<p>Represents the full output of a classification model for a single image.</p> <p>The predictions are typically sorted by confidence in descending order.</p> <p>Attributes:</p> Name Type Description <code>predictions</code> <code>list[Classification]</code> <p>A list of classification results.</p> Source code in <code>culicidaelab\\core\\prediction_models.py</code> <pre><code>class ClassificationPrediction(BaseModel):\n    \"\"\"Represents the full output of a classification model for a single image.\n\n    The predictions are typically sorted by confidence in descending order.\n\n    Attributes:\n        predictions (list[Classification]): A list of classification results.\n    \"\"\"\n\n    predictions: list[Classification]\n\n    def top_prediction(self) -&gt; Classification | None:\n        \"\"\"Returns the top prediction (the one with the highest confidence).\n\n        Returns:\n            Classification | None: The top classification result, or None if there\n            are no predictions.\n        \"\"\"\n        return self.predictions[0] if self.predictions else None\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ClassificationPrediction.predictions","title":"<code>predictions: list[Classification]</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.ClassificationPrediction.top_prediction","title":"<code>top_prediction() -&gt; Classification | None</code>","text":"<p>Returns the top prediction (the one with the highest confidence).</p> <p>Returns:</p> Type Description <code>Classification | None</code> <p>Classification | None: The top classification result, or None if there</p> <code>Classification | None</code> <p>are no predictions.</p> Source code in <code>culicidaelab\\core\\prediction_models.py</code> <pre><code>def top_prediction(self) -&gt; Classification | None:\n    \"\"\"Returns the top prediction (the one with the highest confidence).\n\n    Returns:\n        Classification | None: The top classification result, or None if there\n        are no predictions.\n    \"\"\"\n    return self.predictions[0] if self.predictions else None\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ProviderService","title":"<code>ProviderService</code>","text":"<p>Manages the instantiation and lifecycle of data providers.</p> <p>This service acts as a factory and cache for provider instances, ensuring that each provider is a singleton within the application context.</p> <p>Attributes:</p> Name Type Description <code>_settings</code> <code>Settings</code> <p>The settings instance.</p> <code>_providers</code> <code>dict[str, BaseProvider]</code> <p>A cache of instantiated providers, keyed by provider name.</p> Source code in <code>culicidaelab\\core\\provider_service.py</code> <pre><code>class ProviderService:\n    \"\"\"Manages the instantiation and lifecycle of data providers.\n\n    This service acts as a factory and cache for provider instances, ensuring that\n    each provider is a singleton within the application context.\n\n    Attributes:\n        _settings (Settings): The settings instance.\n        _providers (dict[str, BaseProvider]): A cache of instantiated providers,\n            keyed by provider name.\n    \"\"\"\n\n    def __init__(self, settings: Settings):\n        \"\"\"Initializes the ProviderService.\n\n        Args:\n            settings (Settings): The main `Settings` object for the library.\n        \"\"\"\n        self._settings = settings\n        self._providers: dict[str, BaseProvider] = {}\n\n    def get_provider(self, provider_name: str) -&gt; BaseProvider:\n        \"\"\"Retrieves an instantiated provider by its name.\n\n        It looks up the provider's configuration, instantiates it if it hasn't\n        been already, and caches it for future calls.\n\n        Args:\n            provider_name (str): The name of the provider (e.g., 'huggingface').\n\n        Returns:\n            BaseProvider: An instance of a class that inherits from `BaseProvider`.\n\n        Raises:\n            ValueError: If the provider is not found in the configuration.\n        \"\"\"\n        if provider_name not in self._providers:\n            provider_path = f\"providers.{provider_name}\"\n\n            provider_config = self._settings.get_config(provider_path)\n            if not provider_config:\n                raise ValueError(\n                    f\"Provider '{provider_name}' not found in configuration.\",\n                )\n\n            # Use `instantiate_from_config` from `Settings`\n            provider_instance = self._settings.instantiate_from_config(\n                provider_path,\n            )\n            if not isinstance(provider_instance, BaseProvider):\n                raise TypeError(\n                    f\"Instantiated provider '{provider_name}' is not a valid BaseProvider\",\n                )\n\n            self._providers[provider_name] = provider_instance\n\n        return self._providers[provider_name]\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ProviderService.__init__","title":"<code>__init__(settings: Settings)</code>","text":"<p>Initializes the ProviderService.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>Settings</code> <p>The main <code>Settings</code> object for the library.</p> required Source code in <code>culicidaelab\\core\\provider_service.py</code> <pre><code>def __init__(self, settings: Settings):\n    \"\"\"Initializes the ProviderService.\n\n    Args:\n        settings (Settings): The main `Settings` object for the library.\n    \"\"\"\n    self._settings = settings\n    self._providers: dict[str, BaseProvider] = {}\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ProviderService.get_provider","title":"<code>get_provider(provider_name: str) -&gt; BaseProvider</code>","text":"<p>Retrieves an instantiated provider by its name.</p> <p>It looks up the provider's configuration, instantiates it if it hasn't been already, and caches it for future calls.</p> <p>Parameters:</p> Name Type Description Default <code>provider_name</code> <code>str</code> <p>The name of the provider (e.g., 'huggingface').</p> required <p>Returns:</p> Name Type Description <code>BaseProvider</code> <code>BaseProvider</code> <p>An instance of a class that inherits from <code>BaseProvider</code>.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the provider is not found in the configuration.</p> Source code in <code>culicidaelab\\core\\provider_service.py</code> <pre><code>def get_provider(self, provider_name: str) -&gt; BaseProvider:\n    \"\"\"Retrieves an instantiated provider by its name.\n\n    It looks up the provider's configuration, instantiates it if it hasn't\n    been already, and caches it for future calls.\n\n    Args:\n        provider_name (str): The name of the provider (e.g., 'huggingface').\n\n    Returns:\n        BaseProvider: An instance of a class that inherits from `BaseProvider`.\n\n    Raises:\n        ValueError: If the provider is not found in the configuration.\n    \"\"\"\n    if provider_name not in self._providers:\n        provider_path = f\"providers.{provider_name}\"\n\n        provider_config = self._settings.get_config(provider_path)\n        if not provider_config:\n            raise ValueError(\n                f\"Provider '{provider_name}' not found in configuration.\",\n            )\n\n        # Use `instantiate_from_config` from `Settings`\n        provider_instance = self._settings.instantiate_from_config(\n            provider_path,\n        )\n        if not isinstance(provider_instance, BaseProvider):\n            raise TypeError(\n                f\"Instantiated provider '{provider_name}' is not a valid BaseProvider\",\n            )\n\n        self._providers[provider_name] = provider_instance\n\n    return self._providers[provider_name]\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ResourceManager","title":"<code>ResourceManager</code>","text":"<p>Centralized resource management for models, datasets, and temporary files.</p> <p>This class provides thread-safe operations for managing application resources, including models, datasets, cache files, and temporary workspaces. It ensures that all file operations are handled in a consistent and safe manner.</p> <p>Parameters:</p> Name Type Description Default <code>app_name</code> <code>str</code> <p>The name of the application, used for creating dedicated directories. If not provided, it is inferred from the <code>pyproject.toml</code> file. Defaults to None.</p> <code>None</code> <code>custom_base_dir</code> <code>str | Path</code> <p>A custom base directory for storing all resources. If None, system-appropriate default directories are used (e.g., AppData on Windows). Defaults to None.</p> <code>None</code> <p>Attributes:</p> Name Type Description <code>app_name</code> <code>str</code> <p>The application name.</p> <code>user_data_dir</code> <code>Path</code> <p>The root directory for user-specific data.</p> <code>user_cache_dir</code> <code>Path</code> <p>The directory for user-specific cache files.</p> <code>temp_dir</code> <code>Path</code> <p>The directory for temporary runtime files.</p> <code>model_dir</code> <code>Path</code> <p>The directory where model files are stored.</p> <code>dataset_dir</code> <code>Path</code> <p>The directory where datasets are stored.</p> <code>downloads_dir</code> <code>Path</code> <p>The directory for downloaded files.</p> <code>logs_dir</code> <code>Path</code> <p>The directory for log files.</p> <code>config_dir</code> <code>Path</code> <p>The directory for configuration files.</p> <p>Raises:</p> Type Description <code>OSError</code> <p>If the resource directories cannot be created.</p> <code>ValueError</code> <p>If the application name cannot be determined.</p> Source code in <code>culicidaelab\\core\\resource_manager.py</code> <pre><code>class ResourceManager:\n    \"\"\"Centralized resource management for models, datasets, and temporary files.\n\n    This class provides thread-safe operations for managing application resources,\n    including models, datasets, cache files, and temporary workspaces. It ensures\n    that all file operations are handled in a consistent and safe manner.\n\n    Args:\n        app_name (str, optional): The name of the application, used for creating\n            dedicated directories. If not provided, it is inferred from the\n            `pyproject.toml` file. Defaults to None.\n        custom_base_dir (str | Path, optional): A custom base directory for\n            storing all resources. If None, system-appropriate default\n            directories are used (e.g., AppData on Windows). Defaults to None.\n\n    Attributes:\n        app_name (str): The application name.\n        user_data_dir (Path): The root directory for user-specific data.\n        user_cache_dir (Path): The directory for user-specific cache files.\n        temp_dir (Path): The directory for temporary runtime files.\n        model_dir (Path): The directory where model files are stored.\n        dataset_dir (Path): The directory where datasets are stored.\n        downloads_dir (Path): The directory for downloaded files.\n        logs_dir (Path): The directory for log files.\n        config_dir (Path): The directory for configuration files.\n\n    Raises:\n        OSError: If the resource directories cannot be created.\n        ValueError: If the application name cannot be determined.\n    \"\"\"\n\n    def __init__(\n        self,\n        app_name: str | None = None,\n        custom_base_dir: str | Path | None = None,\n    ):\n        \"\"\"Initializes the ResourceManager with cross-platform compatibility.\n\n        Sets up the necessary directory structure for the application's resources.\n        \"\"\"\n        self._lock = Lock()\n        self.app_name = self._determine_app_name(app_name)\n        self._initialize_paths(custom_base_dir)\n        self._initialize_directories()\n        logger.info(f\"ResourceManager initialized for app: {self.app_name}\")\n        logger.debug(f\"Resource directories: {self.get_all_directories()}\")\n\n    def __repr__(self) -&gt; str:\n        \"\"\"Returns a string representation of the ResourceManager instance.\n\n        Returns:\n            str: A string representation of the object.\n        \"\"\"\n        return f\"ResourceManager(app_name='{self.app_name}', \" f\"user_data_dir='{self.user_data_dir}')\"\n\n    @contextmanager\n    def temp_workspace(self, prefix: str = \"workspace\", suffix: str = \"\"):\n        \"\"\"Provides a temporary workspace that is automatically cleaned up.\n\n        This context manager creates a temporary directory and yields its path,\n        ensuring the directory and its contents are removed upon exiting the\n        context, even if errors occur.\n\n        Args:\n            prefix (str): A prefix for the temporary directory's name.\n            suffix (str): A suffix for the temporary directory's name.\n\n        Yields:\n            Path: The path to the temporary workspace.\n\n        Example:\n            &gt;&gt;&gt; resource_manager = ResourceManager()\n            &gt;&gt;&gt; with resource_manager.temp_workspace(prefix=\"job_\") as ws:\n            ...     # Perform temporary operations within this workspace\n            ...     (ws / \"temp_file.txt\").write_text(\"some data\")\n            ...     print(f\"Workspace created at: {ws}\")\n            # The workspace directory is automatically removed here.\n        \"\"\"\n        workspace_path = None\n        try:\n            # Create the temp directory inside the app's main temp_dir\n            workspace_path_str = tempfile.mkdtemp(\n                prefix=prefix,\n                suffix=suffix,\n                dir=self.temp_dir,\n            )\n            workspace_path = Path(workspace_path_str)\n            logger.info(f\"Created temporary workspace: {workspace_path}\")\n            yield workspace_path\n        finally:\n            if workspace_path and workspace_path.exists():\n                try:\n                    shutil.rmtree(workspace_path)\n                    logger.info(f\"Cleaned up temporary workspace: {workspace_path}\")\n                except Exception as e:\n                    # Log the error but do not raise it to avoid masking other exceptions\n                    logger.error(\n                        f\"Failed to clean up workspace {workspace_path}: {e}\",\n                    )\n\n    def clean_old_files(\n        self,\n        days: int = 5,\n        include_cache: bool = True,\n    ) -&gt; dict[str, int]:\n        \"\"\"Cleans up old files from download and temporary directories.\n\n        Args:\n            days (int): The age in days for a file to be considered old.\n            include_cache (bool): If True, the cache directory is also cleaned.\n\n        Returns:\n            dict[str, int]: A dictionary containing statistics of the cleanup.\n\n        Raises:\n            ValueError: If `days` is a negative number.\n        \"\"\"\n        if days &lt; 0:\n            raise ValueError(\"Days must be a non-negative number.\")\n\n        cleanup_stats = {\"downloads_cleaned\": 0, \"temp_cleaned\": 0, \"cache_cleaned\": 0}\n        cutoff_time = time.time() - (days * 86400)\n\n        cleanup_stats[\"downloads_cleaned\"] = self._clean_directory(\n            self.downloads_dir,\n            cutoff_time,\n        )\n        cleanup_stats[\"temp_cleaned\"] = self._clean_directory(\n            self.temp_dir,\n            cutoff_time,\n        )\n        if include_cache:\n            cleanup_stats[\"cache_cleaned\"] = self._clean_directory(\n                self.user_cache_dir,\n                cutoff_time,\n            )\n\n        logger.info(f\"Cleanup completed: {cleanup_stats}\")\n        return cleanup_stats\n\n    def create_checksum(self, file_path: str | Path, algorithm: str = \"md5\") -&gt; str:\n        \"\"\"Creates a checksum for a given file.\n\n        Args:\n            file_path (str | Path): The path to the file.\n            algorithm (str): The hashing algorithm to use (e.g., 'md5', 'sha256').\n\n        Returns:\n            str: The hexadecimal checksum string.\n\n        Raises:\n            FileNotFoundError: If the specified file does not exist.\n            OSError: If there is an error reading the file.\n        \"\"\"\n        file_path = Path(file_path)\n        if not file_path.exists():\n            msg = f\"File not found: {file_path}\"\n            logger.error(msg)\n            raise FileNotFoundError(msg)\n\n        try:\n            hash_obj = hashlib.new(algorithm)\n            with open(file_path, \"rb\") as f:\n                # Read the file in chunks to handle large files efficiently\n                for chunk in iter(lambda: f.read(4096), b\"\"):\n                    hash_obj.update(chunk)\n            return hash_obj.hexdigest()\n        except Exception as e:\n            msg = f\"Failed to create checksum for {file_path}: {e}\"\n            logger.error(msg)\n            raise OSError(msg) from e\n\n    def get_all_directories(self) -&gt; dict[str, Path]:\n        \"\"\"Retrieves all managed directory paths.\n\n        Returns:\n            dict[str, Path]: A dictionary mapping directory names to their paths.\n        \"\"\"\n        return {\n            \"user_data_dir\": self.user_data_dir,\n            \"user_cache_dir\": self.user_cache_dir,\n            \"temp_dir\": self.temp_dir,\n            \"model_dir\": self.model_dir,\n            \"dataset_dir\": self.dataset_dir,\n            \"downloads_dir\": self.downloads_dir,\n            \"logs_dir\": self.logs_dir,\n            \"config_dir\": self.config_dir,\n        }\n\n    def get_dataset_path(\n        self,\n        dataset_name: str,\n        create_if_missing: bool = True,\n    ) -&gt; Path:\n        \"\"\"Constructs a standardized path for a dataset.\n\n        Args:\n            dataset_name (str): The name of the dataset.\n            create_if_missing (bool): If True, creates the directory if it\n                does not exist.\n\n        Returns:\n            Path: The absolute path to the dataset directory.\n\n        Raises:\n            ValueError: If `dataset_name` is empty or contains only whitespace.\n        \"\"\"\n        if not dataset_name or not dataset_name.strip():\n            raise ValueError(\"Dataset name cannot be empty.\")\n\n        safe_dataset_name = create_safe_path(dataset_name)\n        dataset_path = self.dataset_dir / safe_dataset_name\n        if create_if_missing:\n            self._create_directory(dataset_path, \"dataset\")\n        return dataset_path\n\n    def get_disk_usage(self) -&gt; dict[str, dict[str, int | str]]:\n        \"\"\"Calculates disk usage for all managed directories.\n\n        Returns:\n            dict: A dictionary with disk usage details for each directory,\n                  including size in bytes, human-readable size, and file count.\n        \"\"\"\n        directories = {\n            \"user_data\": self.user_data_dir,\n            \"cache\": self.user_cache_dir,\n            \"models\": self.model_dir,\n            \"datasets\": self.dataset_dir,\n            \"downloads\": self.downloads_dir,\n            \"temp\": self.temp_dir,\n        }\n        return {name: self._get_directory_size(path) for name, path in directories.items()}\n\n    def verify_checksum(\n        self,\n        file_path: str | Path,\n        expected_checksum: str,\n        algorithm: str = \"md5\",\n    ) -&gt; bool:\n        \"\"\"Verifies the checksum of a file against an expected value.\n\n        Args:\n            file_path (str | Path): The path to the file.\n            expected_checksum (str): The expected checksum.\n            algorithm (str): The hashing algorithm used for the checksum.\n\n        Returns:\n            bool: True if the checksums match, False otherwise.\n        \"\"\"\n        try:\n            actual_checksum = self.create_checksum(file_path, algorithm)\n            return actual_checksum.lower() == expected_checksum.lower()\n        except (FileNotFoundError, OSError) as e:\n            logger.error(f\"Checksum verification failed for {file_path}: {e}\")\n            return False\n\n    def _clean_directory(self, directory: Path, cutoff_time: float) -&gt; int:\n        \"\"\"Removes files in a directory older than a specified time.\"\"\"\n        cleaned_count = 0\n        if not directory.exists():\n            return cleaned_count\n\n        try:\n            for item in directory.iterdir():\n                try:\n                    # Check if the item's modification time is older than the cutoff\n                    if item.stat().st_mtime &lt; cutoff_time:\n                        if item.is_dir():\n                            shutil.rmtree(item)\n                        else:\n                            item.unlink()\n                        cleaned_count += 1\n                        logger.debug(f\"Removed old item: {item}\")\n                except Exception as e:\n                    logger.warning(f\"Could not remove {item}: {e}\")\n        except Exception as e:\n            logger.error(f\"Error cleaning directory {directory}: {e}\")\n        return cleaned_count\n\n    def _create_directory(self, path: Path, dir_type: str) -&gt; None:\n        \"\"\"Creates a directory if it doesn't exist.\"\"\"\n        try:\n            path.mkdir(parents=True, exist_ok=True)\n        except Exception as e:\n            msg = f\"Failed to create {dir_type} directory at {path}: {e}\"\n            logger.error(msg)\n            raise OSError(msg) from e\n\n    def _determine_app_name(self, app_name: str | None = None) -&gt; str:\n        \"\"\"Determines the application name.\"\"\"\n        if app_name:\n            return app_name\n        try:\n            # Attempt to get the project name from pyproject.toml\n            pyproject_name = self._get_project_name_from_pyproject()\n            if pyproject_name:\n                return pyproject_name\n        except Exception as e:\n            logger.warning(\n                f\"Could not determine app name from pyproject.toml: {e}. \" \"Falling back to default 'culicidaelab'.\",\n            )\n        return \"culicidaelab\"\n\n    def _get_project_name_from_pyproject(self) -&gt; str | None:\n        \"\"\"Reads the project name from the pyproject.toml file.\"\"\"\n        try:\n            # Traverse up to find the project root containing pyproject.toml\n            current_dir = Path(__file__).parent\n            while not (current_dir / \"pyproject.toml\").exists():\n                if current_dir.parent == current_dir:  # Reached the filesystem root\n                    return None\n                current_dir = current_dir.parent\n\n            pyproject_path = current_dir / \"pyproject.toml\"\n            with open(pyproject_path, encoding=\"utf-8\") as f:\n                pyproject_data = toml.load(f)\n\n            return pyproject_data.get(\"project\", {}).get(\"name\")\n        except Exception as e:\n            logger.error(f\"Failed to read project name from pyproject.toml: {e}\")\n            return None\n\n    def _format_bytes(self, bytes_count: int | float) -&gt; str:\n        \"\"\"Formats a byte count into a human-readable string.\"\"\"\n        import math\n\n        if bytes_count is None:\n            raise ValueError(\"bytes_count cannot be None.\")\n        if bytes_count == 0:\n            return \"0 B\"\n        units = [\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\"]\n        # Determine the appropriate unit using logarithm\n        power = int(math.log(bytes_count, 1024)) if bytes_count &gt; 0 else 0\n        unit_index = min(power, len(units) - 1)\n        value = bytes_count / (1024**unit_index)\n        return f\"{value:.1f} {units[unit_index]}\"\n\n    def _get_directory_size(self, path: Path) -&gt; dict[str, int | str]:\n        \"\"\"Calculates the total size and file count of a directory.\"\"\"\n        if not path.exists():\n            return {\"size_bytes\": 0, \"size_human\": \"0 B\", \"file_count\": 0}\n\n        total_size = 0\n        file_count = 0\n        try:\n            for item in path.rglob(\"*\"):\n                if item.is_file():\n                    total_size += item.stat().st_size\n                    file_count += 1\n        except Exception as e:\n            logger.warning(f\"Error calculating size for {path}: {e}\")\n\n        return {\n            \"size_bytes\": total_size,\n            \"size_human\": self._format_bytes(total_size),\n            \"file_count\": file_count,\n        }\n\n    def _initialize_directories(self) -&gt; None:\n        \"\"\"Creates all necessary application directories.\"\"\"\n        directories = self.get_all_directories().values()\n        for directory in directories:\n            try:\n                directory.mkdir(parents=True, exist_ok=True)\n                logger.debug(f\"Ensured directory exists: {directory}\")\n            except Exception as e:\n                msg = f\"Failed to create directory {directory}: {e}\"\n                logger.error(msg)\n                raise OSError(msg) from e\n\n        # Set secure permissions on non-Windows systems\n        if platform.system() != \"Windows\":\n            self._set_directory_permissions(list(directories))\n\n    def _initialize_paths(self, custom_base_dir: str | Path | None = None) -&gt; None:\n        \"\"\"Initializes all resource paths based on the environment.\"\"\"\n        if custom_base_dir:\n            base_dir = Path(custom_base_dir).resolve()\n            self.user_data_dir = base_dir / \"data\"\n            self.user_cache_dir = base_dir / \"cache\"\n        else:\n            # Use system-appropriate directories\n            self.user_data_dir = Path(appdirs.user_data_dir(self.app_name))\n            self.user_cache_dir = Path(appdirs.user_cache_dir(self.app_name))\n\n        self.temp_dir = Path(tempfile.gettempdir()) / self.app_name\n        self.model_dir = self.user_data_dir / \"models\"\n        self.dataset_dir = self.user_data_dir / \"datasets\"\n        self.downloads_dir = self.user_data_dir / \"downloads\"\n        self.logs_dir = self.user_data_dir / \"logs\"\n        self.config_dir = self.user_data_dir / \"config\"\n\n    def _is_safe_to_delete(self, path: Path) -&gt; bool:\n        \"\"\"Checks if a path is within a managed directory and safe to delete.\"\"\"\n        safe_parents = [self.temp_dir, self.user_cache_dir]\n        try:\n            resolved_path = path.resolve()\n            # Ensure the path is a child of one of the safe parent directories\n            return any(resolved_path.is_relative_to(p.resolve()) for p in safe_parents)\n        except Exception:\n            return False\n\n    def _set_directory_permissions(self, directories: list[Path]) -&gt; None:\n        \"\"\"Sets directory permissions to 0o700 on Unix-like systems.\"\"\"\n        try:\n            for directory in directories:\n                os.chmod(directory, 0o700)\n        except Exception as e:\n            logger.warning(f\"Could not set directory permissions: {e}\")\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ResourceManager.app_name","title":"<code>app_name = self._determine_app_name(app_name)</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.ResourceManager.__init__","title":"<code>__init__(app_name: str | None = None, custom_base_dir: str | Path | None = None)</code>","text":"<p>Initializes the ResourceManager with cross-platform compatibility.</p> <p>Sets up the necessary directory structure for the application's resources.</p> Source code in <code>culicidaelab\\core\\resource_manager.py</code> <pre><code>def __init__(\n    self,\n    app_name: str | None = None,\n    custom_base_dir: str | Path | None = None,\n):\n    \"\"\"Initializes the ResourceManager with cross-platform compatibility.\n\n    Sets up the necessary directory structure for the application's resources.\n    \"\"\"\n    self._lock = Lock()\n    self.app_name = self._determine_app_name(app_name)\n    self._initialize_paths(custom_base_dir)\n    self._initialize_directories()\n    logger.info(f\"ResourceManager initialized for app: {self.app_name}\")\n    logger.debug(f\"Resource directories: {self.get_all_directories()}\")\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ResourceManager.__repr__","title":"<code>__repr__() -&gt; str</code>","text":"<p>Returns a string representation of the ResourceManager instance.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A string representation of the object.</p> Source code in <code>culicidaelab\\core\\resource_manager.py</code> <pre><code>def __repr__(self) -&gt; str:\n    \"\"\"Returns a string representation of the ResourceManager instance.\n\n    Returns:\n        str: A string representation of the object.\n    \"\"\"\n    return f\"ResourceManager(app_name='{self.app_name}', \" f\"user_data_dir='{self.user_data_dir}')\"\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ResourceManager.temp_workspace","title":"<code>temp_workspace(prefix: str = 'workspace', suffix: str = '')</code>","text":"<p>Provides a temporary workspace that is automatically cleaned up.</p> <p>This context manager creates a temporary directory and yields its path, ensuring the directory and its contents are removed upon exiting the context, even if errors occur.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>A prefix for the temporary directory's name.</p> <code>'workspace'</code> <code>suffix</code> <code>str</code> <p>A suffix for the temporary directory's name.</p> <code>''</code> <p>Yields:</p> Name Type Description <code>Path</code> <p>The path to the temporary workspace.</p> Example <p>resource_manager = ResourceManager() with resource_manager.temp_workspace(prefix=\"job_\") as ws: ...     # Perform temporary operations within this workspace ...     (ws / \"temp_file.txt\").write_text(\"some data\") ...     print(f\"Workspace created at: {ws}\")</p> Source code in <code>culicidaelab\\core\\resource_manager.py</code> <pre><code>@contextmanager\ndef temp_workspace(self, prefix: str = \"workspace\", suffix: str = \"\"):\n    \"\"\"Provides a temporary workspace that is automatically cleaned up.\n\n    This context manager creates a temporary directory and yields its path,\n    ensuring the directory and its contents are removed upon exiting the\n    context, even if errors occur.\n\n    Args:\n        prefix (str): A prefix for the temporary directory's name.\n        suffix (str): A suffix for the temporary directory's name.\n\n    Yields:\n        Path: The path to the temporary workspace.\n\n    Example:\n        &gt;&gt;&gt; resource_manager = ResourceManager()\n        &gt;&gt;&gt; with resource_manager.temp_workspace(prefix=\"job_\") as ws:\n        ...     # Perform temporary operations within this workspace\n        ...     (ws / \"temp_file.txt\").write_text(\"some data\")\n        ...     print(f\"Workspace created at: {ws}\")\n        # The workspace directory is automatically removed here.\n    \"\"\"\n    workspace_path = None\n    try:\n        # Create the temp directory inside the app's main temp_dir\n        workspace_path_str = tempfile.mkdtemp(\n            prefix=prefix,\n            suffix=suffix,\n            dir=self.temp_dir,\n        )\n        workspace_path = Path(workspace_path_str)\n        logger.info(f\"Created temporary workspace: {workspace_path}\")\n        yield workspace_path\n    finally:\n        if workspace_path and workspace_path.exists():\n            try:\n                shutil.rmtree(workspace_path)\n                logger.info(f\"Cleaned up temporary workspace: {workspace_path}\")\n            except Exception as e:\n                # Log the error but do not raise it to avoid masking other exceptions\n                logger.error(\n                    f\"Failed to clean up workspace {workspace_path}: {e}\",\n                )\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ResourceManager.temp_workspace--the-workspace-directory-is-automatically-removed-here","title":"The workspace directory is automatically removed here.","text":""},{"location":"api_docs/core/#culicidaelab.core.ResourceManager.clean_old_files","title":"<code>clean_old_files(days: int = 5, include_cache: bool = True) -&gt; dict[str, int]</code>","text":"<p>Cleans up old files from download and temporary directories.</p> <p>Parameters:</p> Name Type Description Default <code>days</code> <code>int</code> <p>The age in days for a file to be considered old.</p> <code>5</code> <code>include_cache</code> <code>bool</code> <p>If True, the cache directory is also cleaned.</p> <code>True</code> <p>Returns:</p> Type Description <code>dict[str, int]</code> <p>dict[str, int]: A dictionary containing statistics of the cleanup.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>days</code> is a negative number.</p> Source code in <code>culicidaelab\\core\\resource_manager.py</code> <pre><code>def clean_old_files(\n    self,\n    days: int = 5,\n    include_cache: bool = True,\n) -&gt; dict[str, int]:\n    \"\"\"Cleans up old files from download and temporary directories.\n\n    Args:\n        days (int): The age in days for a file to be considered old.\n        include_cache (bool): If True, the cache directory is also cleaned.\n\n    Returns:\n        dict[str, int]: A dictionary containing statistics of the cleanup.\n\n    Raises:\n        ValueError: If `days` is a negative number.\n    \"\"\"\n    if days &lt; 0:\n        raise ValueError(\"Days must be a non-negative number.\")\n\n    cleanup_stats = {\"downloads_cleaned\": 0, \"temp_cleaned\": 0, \"cache_cleaned\": 0}\n    cutoff_time = time.time() - (days * 86400)\n\n    cleanup_stats[\"downloads_cleaned\"] = self._clean_directory(\n        self.downloads_dir,\n        cutoff_time,\n    )\n    cleanup_stats[\"temp_cleaned\"] = self._clean_directory(\n        self.temp_dir,\n        cutoff_time,\n    )\n    if include_cache:\n        cleanup_stats[\"cache_cleaned\"] = self._clean_directory(\n            self.user_cache_dir,\n            cutoff_time,\n        )\n\n    logger.info(f\"Cleanup completed: {cleanup_stats}\")\n    return cleanup_stats\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ResourceManager.create_checksum","title":"<code>create_checksum(file_path: str | Path, algorithm: str = 'md5') -&gt; str</code>","text":"<p>Creates a checksum for a given file.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | Path</code> <p>The path to the file.</p> required <code>algorithm</code> <code>str</code> <p>The hashing algorithm to use (e.g., 'md5', 'sha256').</p> <code>'md5'</code> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The hexadecimal checksum string.</p> <p>Raises:</p> Type Description <code>FileNotFoundError</code> <p>If the specified file does not exist.</p> <code>OSError</code> <p>If there is an error reading the file.</p> Source code in <code>culicidaelab\\core\\resource_manager.py</code> <pre><code>def create_checksum(self, file_path: str | Path, algorithm: str = \"md5\") -&gt; str:\n    \"\"\"Creates a checksum for a given file.\n\n    Args:\n        file_path (str | Path): The path to the file.\n        algorithm (str): The hashing algorithm to use (e.g., 'md5', 'sha256').\n\n    Returns:\n        str: The hexadecimal checksum string.\n\n    Raises:\n        FileNotFoundError: If the specified file does not exist.\n        OSError: If there is an error reading the file.\n    \"\"\"\n    file_path = Path(file_path)\n    if not file_path.exists():\n        msg = f\"File not found: {file_path}\"\n        logger.error(msg)\n        raise FileNotFoundError(msg)\n\n    try:\n        hash_obj = hashlib.new(algorithm)\n        with open(file_path, \"rb\") as f:\n            # Read the file in chunks to handle large files efficiently\n            for chunk in iter(lambda: f.read(4096), b\"\"):\n                hash_obj.update(chunk)\n        return hash_obj.hexdigest()\n    except Exception as e:\n        msg = f\"Failed to create checksum for {file_path}: {e}\"\n        logger.error(msg)\n        raise OSError(msg) from e\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ResourceManager.get_all_directories","title":"<code>get_all_directories() -&gt; dict[str, Path]</code>","text":"<p>Retrieves all managed directory paths.</p> <p>Returns:</p> Type Description <code>dict[str, Path]</code> <p>dict[str, Path]: A dictionary mapping directory names to their paths.</p> Source code in <code>culicidaelab\\core\\resource_manager.py</code> <pre><code>def get_all_directories(self) -&gt; dict[str, Path]:\n    \"\"\"Retrieves all managed directory paths.\n\n    Returns:\n        dict[str, Path]: A dictionary mapping directory names to their paths.\n    \"\"\"\n    return {\n        \"user_data_dir\": self.user_data_dir,\n        \"user_cache_dir\": self.user_cache_dir,\n        \"temp_dir\": self.temp_dir,\n        \"model_dir\": self.model_dir,\n        \"dataset_dir\": self.dataset_dir,\n        \"downloads_dir\": self.downloads_dir,\n        \"logs_dir\": self.logs_dir,\n        \"config_dir\": self.config_dir,\n    }\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ResourceManager.get_dataset_path","title":"<code>get_dataset_path(dataset_name: str, create_if_missing: bool = True) -&gt; Path</code>","text":"<p>Constructs a standardized path for a dataset.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>The name of the dataset.</p> required <code>create_if_missing</code> <code>bool</code> <p>If True, creates the directory if it does not exist.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>The absolute path to the dataset directory.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>dataset_name</code> is empty or contains only whitespace.</p> Source code in <code>culicidaelab\\core\\resource_manager.py</code> <pre><code>def get_dataset_path(\n    self,\n    dataset_name: str,\n    create_if_missing: bool = True,\n) -&gt; Path:\n    \"\"\"Constructs a standardized path for a dataset.\n\n    Args:\n        dataset_name (str): The name of the dataset.\n        create_if_missing (bool): If True, creates the directory if it\n            does not exist.\n\n    Returns:\n        Path: The absolute path to the dataset directory.\n\n    Raises:\n        ValueError: If `dataset_name` is empty or contains only whitespace.\n    \"\"\"\n    if not dataset_name or not dataset_name.strip():\n        raise ValueError(\"Dataset name cannot be empty.\")\n\n    safe_dataset_name = create_safe_path(dataset_name)\n    dataset_path = self.dataset_dir / safe_dataset_name\n    if create_if_missing:\n        self._create_directory(dataset_path, \"dataset\")\n    return dataset_path\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ResourceManager.get_disk_usage","title":"<code>get_disk_usage() -&gt; dict[str, dict[str, int | str]]</code>","text":"<p>Calculates disk usage for all managed directories.</p> <p>Returns:</p> Name Type Description <code>dict</code> <code>dict[str, dict[str, int | str]]</code> <p>A dictionary with disk usage details for each directory,   including size in bytes, human-readable size, and file count.</p> Source code in <code>culicidaelab\\core\\resource_manager.py</code> <pre><code>def get_disk_usage(self) -&gt; dict[str, dict[str, int | str]]:\n    \"\"\"Calculates disk usage for all managed directories.\n\n    Returns:\n        dict: A dictionary with disk usage details for each directory,\n              including size in bytes, human-readable size, and file count.\n    \"\"\"\n    directories = {\n        \"user_data\": self.user_data_dir,\n        \"cache\": self.user_cache_dir,\n        \"models\": self.model_dir,\n        \"datasets\": self.dataset_dir,\n        \"downloads\": self.downloads_dir,\n        \"temp\": self.temp_dir,\n    }\n    return {name: self._get_directory_size(path) for name, path in directories.items()}\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.ResourceManager.verify_checksum","title":"<code>verify_checksum(file_path: str | Path, expected_checksum: str, algorithm: str = 'md5') -&gt; bool</code>","text":"<p>Verifies the checksum of a file against an expected value.</p> <p>Parameters:</p> Name Type Description Default <code>file_path</code> <code>str | Path</code> <p>The path to the file.</p> required <code>expected_checksum</code> <code>str</code> <p>The expected checksum.</p> required <code>algorithm</code> <code>str</code> <p>The hashing algorithm used for the checksum.</p> <code>'md5'</code> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the checksums match, False otherwise.</p> Source code in <code>culicidaelab\\core\\resource_manager.py</code> <pre><code>def verify_checksum(\n    self,\n    file_path: str | Path,\n    expected_checksum: str,\n    algorithm: str = \"md5\",\n) -&gt; bool:\n    \"\"\"Verifies the checksum of a file against an expected value.\n\n    Args:\n        file_path (str | Path): The path to the file.\n        expected_checksum (str): The expected checksum.\n        algorithm (str): The hashing algorithm used for the checksum.\n\n    Returns:\n        bool: True if the checksums match, False otherwise.\n    \"\"\"\n    try:\n        actual_checksum = self.create_checksum(file_path, algorithm)\n        return actual_checksum.lower() == expected_checksum.lower()\n    except (FileNotFoundError, OSError) as e:\n        logger.error(f\"Checksum verification failed for {file_path}: {e}\")\n        return False\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.Settings","title":"<code>Settings</code>","text":"<p>User-friendly facade for CulicidaeLab configuration management.</p> <p>This class provides a simple, stable interface to access configuration values, resource directories, and application settings. All actual operations are delegated to a validated configuration object managed by ConfigManager and a ResourceManager.</p> <p>The Settings class is implemented as a singleton to ensure consistent configuration state across the application. It manages: - Configuration values through get_config() and set_config() - Resource directories for models, datasets, and cache - Dataset paths and splits - Model weights paths and types - API keys for external services - Temporary workspaces for processing</p> <p>Attributes:</p> Name Type Description <code>config</code> <code>CulicidaeLabConfig</code> <p>The current configuration object</p> <code>model_dir</code> <code>Path</code> <p>Directory for model weights</p> <code>dataset_dir</code> <code>Path</code> <p>Directory for datasets</p> <code>cache_dir</code> <code>Path</code> <p>Directory for cached data</p> <code>config_dir</code> <code>Path</code> <p>Active user configuration directory</p> <code>species_config</code> <code>SpeciesConfig</code> <p>Configuration for species detection</p> Source code in <code>culicidaelab\\core\\settings.py</code> <pre><code>class Settings:\n    \"\"\"\n    User-friendly facade for CulicidaeLab configuration management.\n\n    This class provides a simple, stable interface to access configuration values,\n    resource directories, and application settings. All actual operations\n    are delegated to a validated configuration object managed by ConfigManager\n    and a ResourceManager.\n\n    The Settings class is implemented as a singleton to ensure consistent\n    configuration state across the application. It manages:\n    - Configuration values through get_config() and set_config()\n    - Resource directories for models, datasets, and cache\n    - Dataset paths and splits\n    - Model weights paths and types\n    - API keys for external services\n    - Temporary workspaces for processing\n\n    Attributes:\n        config (CulicidaeLabConfig): The current configuration object\n        model_dir (Path): Directory for model weights\n        dataset_dir (Path): Directory for datasets\n        cache_dir (Path): Directory for cached data\n        config_dir (Path): Active user configuration directory\n        species_config (SpeciesConfig): Configuration for species detection\n    \"\"\"\n\n    _instance: Optional[\"Settings\"] = None\n    _lock = threading.Lock()\n    _initialized = False\n\n    def __init__(self, config_dir: str | Path | None = None) -&gt; None:\n        \"\"\"Initializes the Settings facade.\n\n        This loads the configuration using a ConfigManager and sets up a\n        ResourceManager for file paths.\n\n        Args:\n            config_dir: Optional path to a user-provided configuration directory.\n        \"\"\"\n        if self._initialized:\n            return\n\n        self._config_manager = ConfigManager(user_config_dir=config_dir)\n        self.config: CulicidaeLabConfig = self._config_manager.get_config()\n        self._resource_manager = ResourceManager()\n\n        # Cache for species config (lazy loaded)\n        self._species_config: SpeciesConfig | None = None\n\n        # Store for singleton check\n        self._current_config_dir = self._config_manager.user_config_dir\n\n        self._initialized = True\n\n    # Configuration Access\n    def get_config(self, path: str | None = None, default: Any = None) -&gt; Any:\n        \"\"\"Gets a configuration value using a dot-separated path.\n\n        Example:\n            &gt;&gt;&gt; settings.get_config(\"predictors.classifier.confidence\")\n\n        Args:\n            path: A dot-separated string path to the configuration value.\n                If None, returns the entire configuration object.\n            default: A default value to return if the path is not found.\n\n        Returns:\n            The configuration value, or the default value if not found.\n        \"\"\"\n        if not path:\n            return self.config\n\n        obj = self.config\n        try:\n            for key in path.split(\".\"):\n                if isinstance(obj, dict):\n                    obj = obj.get(key)\n                else:\n                    obj = getattr(obj, key)\n            return obj if obj is not None else default\n        except (AttributeError, KeyError):\n            return default\n\n    def set_config(self, path: str, value: Any) -&gt; None:\n        \"\"\"\n        Sets a configuration value at a specified dot-separated path.\n        This method can traverse both objects (Pydantic models) and dictionaries.\n\n        Note: This modifies the configuration in memory. To make it persistent,\n        call `save_config()`.\n\n        Args:\n            path: A dot-separated string path to the configuration value.\n            value: The new value to set.\n        \"\"\"\n        keys = path.split(\".\")\n        obj = self.config\n\n        for key in keys[:-1]:\n            if isinstance(obj, dict):\n                obj = obj.get(key)\n            else:\n                obj = getattr(obj, key)\n\n            if obj is None:\n                raise KeyError(f\"The path part '{key}' in '{path}' was not found.\")\n\n        last_key = keys[-1]\n        if isinstance(obj, dict):\n            obj[last_key] = value\n        else:\n            setattr(obj, last_key, value)\n\n    def save_config(self, file_path: str | Path | None = None) -&gt; None:\n        \"\"\"Save current configuration to a user config file.\n        Args:\n            file_path: Optional path to save the configuration file.\n                If None, defaults to \"culicidaelab_saved.yaml\" in the user config directory.\n        \"\"\"\n        if file_path is None:\n            if not self._config_manager.user_config_dir:\n                raise ValueError(\"Cannot save config without a specified user config directory.\")\n            file_path = self._config_manager.user_config_dir / \"culicidaelab_saved.yaml\"\n        self._config_manager.save_config(file_path)\n\n    # Resource Directory Access\n    @property\n    def model_dir(self) -&gt; Path:\n        \"\"\"Model weights directory.\"\"\"\n        return self._resource_manager.model_dir\n\n    @property\n    def weights_dir(self) -&gt; Path:\n        \"\"\"Alias for model_dir.\"\"\"\n        return self.model_dir\n\n    @property\n    def dataset_dir(self) -&gt; Path:\n        \"\"\"Datasets directory.\"\"\"\n        return self._resource_manager.dataset_dir\n\n    @property\n    def cache_dir(self) -&gt; Path:\n        \"\"\"Cache directory.\"\"\"\n        return self._resource_manager.user_cache_dir\n\n    @property\n    def config_dir(self) -&gt; Path:\n        \"\"\"The active user configuration directory.\"\"\"\n        return self._config_manager.user_config_dir or self._config_manager.default_config_path\n\n    @property\n    def species_config(self) -&gt; SpeciesConfig:\n        \"\"\"Species configuration (lazily loaded).\"\"\"\n        if self._species_config is None:\n            self._species_config = SpeciesConfig(self.config.species)\n        return self._species_config\n\n    # Dataset Management\n    def get_cache_key_for_split(self, split: str | list[str] | None) -&gt; str:\n        \"\"\"\n        Generates a unique, deterministic hash for any valid split configuration.\n        This hash is used to create unique directory names for dataset splits.\n\n        Args:\n            split (str | list[str] | None): The split configuration to hash.\n                Can be a single split name (e.g., 'train'), a list of splits\n                (e.g., ['train', 'val']), or None.\n\n        Returns:\n            str: A 16-character hexadecimal hash that uniquely identifies the\n                split configuration. This hash is deterministic for the same\n                input.\n\n        Example:\n            &gt;&gt;&gt; settings.get_cache_key_for_split('train')\n            'a1b2c3d4e5f6g7h8'\n            &gt;&gt;&gt; settings.get_cache_key_for_split(['train', 'val'])\n            'h8g7f6e5d4c3b2a1'\n        \"\"\"\n        if isinstance(split, list):\n            split.sort()\n\n        # json.dumps correctly handles None, converting it to the string \"null\"\n        split_str = json.dumps(split, sort_keys=True)\n\n        hasher = hashlib.sha256(split_str.encode(\"utf-8\"))\n        return hasher.hexdigest()[:16]\n\n    def construct_split_path(\n        self,\n        dataset_base_path: Path,\n        split: str | list[str] | None = None,\n    ) -&gt; Path:\n        \"\"\"\n        Gets the standardized, absolute path for a dataset's directory.\n\n        This is the single source of truth for dataset path construction.\n\n        Args:\n            name (str): The name of the dataset (e.g., 'classification').\n            split (str | list[str] | None, optional): If provided, returns the specific\n                cache path for this split configuration. Otherwise, returns the base\n                directory for the dataset.\n            ensure_exists (bool): If True, ensures the directory is created on disk.\n\n        Returns:\n            Path: The absolute path to the dataset directory.\n        \"\"\"\n        # Determine the final path (either base or split-specific)\n        final_path = dataset_base_path\n        if split is not None:\n            split_key = self.get_cache_key_for_split(split)\n            final_path = dataset_base_path / split_key\n\n        return final_path\n\n    def get_dataset_path(self, dataset_type: str, split: str | list[str] | None = None) -&gt; Path:\n        \"\"\"Gets the standardized path for a specific dataset directory.\n\n        Args:\n            dataset_type: The name of the dataset type (e.g., 'classification').\n\n        Returns:\n            An absolute path to the dataset directory.\n        \"\"\"\n        if dataset_type not in self.config.datasets:\n            raise ValueError(f\"Dataset type '{dataset_type}' not configured.\")\n\n        dataset_path_str = self.config.datasets[dataset_type].path\n        filal_path = Path(dataset_path_str)\n        if not filal_path.is_absolute():\n            filal_path = self.dataset_dir / filal_path\n\n        filal_path.mkdir(parents=True, exist_ok=True)\n\n        if split is not None:\n            filal_path = self.construct_split_path(\n                dataset_base_path=filal_path,\n                split=split,\n            )\n        return filal_path\n\n    def list_datasets(self) -&gt; list[str]:\n        \"\"\"Get list of configured dataset types in the application.\n\n        Returns:\n            list[str]: A list of dataset type identifiers that are configured\n                in the application settings. These correspond to the different\n                dataset categories available for training and inference.\n\n        Example:\n            &gt;&gt;&gt; settings.list_datasets()\n            ['classification', 'detection', 'segmentation']\n        \"\"\"\n        return list(self.config.datasets.keys())\n\n    # Model Management\n    def construct_weights_path(\n        self,\n        predictor_type: str,\n        backend: str | None = None,\n    ) -&gt; Path:\n        \"\"\"\n        A pure, static function to construct a fully qualified model weights path.\n\n        This is the single source of truth for model path construction, creating a\n        structured path like: .../models/&lt;predictor_type&gt;/&lt;backend&gt;/&lt;filename&gt;.\n\n        Args:\n            model_dir (Path): The base directory for all models (e.g., '.../culicidaelab/models').\n            predictor_type (str): The type of the predictor (e.g., 'classifier'). Used as a subdirectory.\n            predictor_config (PredictorConfig): The Pydantic model for the predictor's configuration.\n            backend (str | None, optional): The target backend (e.g., 'torch', 'onnx').\n                                            If None, uses the default from the config.\n\n        Returns:\n            Path: The absolute, structured path to the model weights file.\n\n        Raises:\n            ValueError: If a valid backend or weights filename cannot be determined.\n        \"\"\"\n        predictor_config = self.get_config(f\"predictors.{predictor_type}\")\n        final_backend = backend if backend is not None else predictor_config.backend\n        if not final_backend:\n            raise ValueError(f\"No backend specified for model '{predictor_type}'.\")\n\n        if not predictor_config.weights or final_backend not in predictor_config.weights:\n            raise ValueError(f\"Backend '{final_backend}' not defined in weights config for '{predictor_type}'.\")\n\n        filename = predictor_config.weights[final_backend].filename\n        if not filename:\n            raise ValueError(f\"Filename for backend '{final_backend}' is missing in config for '{predictor_type}'.\")\n\n        # Sanitize the components that will become directories\n        predictor_dir = create_safe_path(predictor_type)\n        backend_dir = create_safe_path(final_backend)\n\n        # Assemble the final, structured path\n        return self.model_dir / predictor_dir / backend_dir / filename\n\n    def get_model_weights_path(\n        self,\n        model_type: str,\n        backend: str | None = None,\n    ) -&gt; Path:\n        \"\"\"Gets the configured path to a model's weights file.\n\n        Args:\n            model_type: The name of the model type (e.g., 'classifier').\n\n        Returns:\n            The path to the model weights file.\n        \"\"\"\n        if model_type not in self.config.predictors:\n            raise ValueError(f\"Model type '{model_type}' not configured in 'predictors'.\")\n\n        local_path = self.construct_weights_path(\n            predictor_type=model_type,\n            backend=backend,\n        )\n        return local_path\n\n    def list_model_types(self) -&gt; list[str]:\n        \"\"\"Get list of available model types configured in the application.\n\n        Returns:\n            list[str]: A list of model type identifiers (e.g., ['classifier',\n                'detector', 'segmenter']) that are configured in the application.\n                These types correspond to the different predictors available\n                in the CulicidaeLab system.\n\n        Example:\n            &gt;&gt;&gt; settings.list_model_types()\n            ['classifier', 'detector', 'segmenter']\n        \"\"\"\n        return list(self.config.predictors.keys())\n\n    # API Key Management\n    def get_api_key(self, provider: str) -&gt; str | None:\n        \"\"\"Get API key for external provider from environment variables.\n\n        The method looks for environment variables in the following format:\n        - KAGGLE_API_KEY for 'kaggle' provider\n        - HUGGINGFACE_API_KEY for 'huggingface' provider\n        - ROBOFLOW_API_KEY for 'roboflow' provider\n\n        Args:\n            provider (str): The name of the provider. Must be one of:\n                'kaggle', 'huggingface', or 'roboflow'.\n\n        Returns:\n            str | None: The API key if found in environment variables,\n                None if the provider is not supported or the key is not set.\n\n        Example:\n            &gt;&gt;&gt; api_key = settings.get_api_key('huggingface')\n            &gt;&gt;&gt; if api_key:\n            ...     # Use the API key\n            ... else:\n            ...     # Handle missing key\n        \"\"\"\n        api_keys = {\n            \"kaggle\": \"KAGGLE_API_KEY\",\n            \"huggingface\": \"HUGGINGFACE_API_KEY\",\n            \"roboflow\": \"ROBOFLOW_API_KEY\",\n        }\n        if provider in api_keys:\n            return os.getenv(api_keys[provider])\n        return None\n\n    # Utility Methods (delegated to ResourceManager)\n    @contextmanager\n    def temp_workspace(self, prefix: str = \"workspace\"):\n        \"\"\"Creates a temporary workspace directory that is automatically cleaned up.\n\n        This context manager creates a temporary directory for processing operations\n        and automatically cleans it up when the context is exited.\n\n        Args:\n            prefix (str, optional): Prefix for the temporary directory name.\n                Defaults to \"workspace\".\n\n        Yields:\n            Path: Path to the temporary workspace directory.\n\n        Example:\n            &gt;&gt;&gt; with settings.temp_workspace(prefix='processing') as workspace:\n            ...     # Do some work in the temporary directory\n            ...     (workspace / 'output.txt').write_text('results')\n            # Directory is automatically cleaned up after the with block\n        \"\"\"\n        with self._resource_manager.temp_workspace(prefix) as workspace:\n            yield workspace\n\n    # Instantiation\n    def instantiate_from_config(self, config_path: str, **kwargs: Any) -&gt; Any:\n        \"\"\"Instantiates an object from a configuration path.\n\n        This is a convenience method that finds a config object by its path\n        and uses the underlying ConfigManager to instantiate it.\n\n        Args:\n            config_path: A dot-separated path to the configuration object\n                (e.g., \"predictors.classifier\").\n            **kwargs: Additional keyword arguments to pass to the constructor.\n\n        Returns:\n            The instantiated object.\n        \"\"\"\n\n        config_obj = self.get_config(config_path)\n        if not config_obj:\n            raise ValueError(f\"No configuration object found at path: {config_path}\")\n\n        extra_deps = {\"settings\": self}\n\n        return self._config_manager.instantiate_from_config(\n            config_obj,\n            extra_params=extra_deps,\n            **kwargs,\n        )\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.Settings.config","title":"<code>config: CulicidaeLabConfig = self._config_manager.get_config()</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/core/#culicidaelab.core.Settings.model_dir","title":"<code>model_dir: Path</code>  <code>property</code>","text":"<p>Model weights directory.</p>"},{"location":"api_docs/core/#culicidaelab.core.Settings.weights_dir","title":"<code>weights_dir: Path</code>  <code>property</code>","text":"<p>Alias for model_dir.</p>"},{"location":"api_docs/core/#culicidaelab.core.Settings.dataset_dir","title":"<code>dataset_dir: Path</code>  <code>property</code>","text":"<p>Datasets directory.</p>"},{"location":"api_docs/core/#culicidaelab.core.Settings.cache_dir","title":"<code>cache_dir: Path</code>  <code>property</code>","text":"<p>Cache directory.</p>"},{"location":"api_docs/core/#culicidaelab.core.Settings.config_dir","title":"<code>config_dir: Path</code>  <code>property</code>","text":"<p>The active user configuration directory.</p>"},{"location":"api_docs/core/#culicidaelab.core.Settings.species_config","title":"<code>species_config: SpeciesConfig</code>  <code>property</code>","text":"<p>Species configuration (lazily loaded).</p>"},{"location":"api_docs/core/#culicidaelab.core.Settings.__init__","title":"<code>__init__(config_dir: str | Path | None = None) -&gt; None</code>","text":"<p>Initializes the Settings facade.</p> <p>This loads the configuration using a ConfigManager and sets up a ResourceManager for file paths.</p> <p>Parameters:</p> Name Type Description Default <code>config_dir</code> <code>str | Path | None</code> <p>Optional path to a user-provided configuration directory.</p> <code>None</code> Source code in <code>culicidaelab\\core\\settings.py</code> <pre><code>def __init__(self, config_dir: str | Path | None = None) -&gt; None:\n    \"\"\"Initializes the Settings facade.\n\n    This loads the configuration using a ConfigManager and sets up a\n    ResourceManager for file paths.\n\n    Args:\n        config_dir: Optional path to a user-provided configuration directory.\n    \"\"\"\n    if self._initialized:\n        return\n\n    self._config_manager = ConfigManager(user_config_dir=config_dir)\n    self.config: CulicidaeLabConfig = self._config_manager.get_config()\n    self._resource_manager = ResourceManager()\n\n    # Cache for species config (lazy loaded)\n    self._species_config: SpeciesConfig | None = None\n\n    # Store for singleton check\n    self._current_config_dir = self._config_manager.user_config_dir\n\n    self._initialized = True\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.Settings.get_config","title":"<code>get_config(path: str | None = None, default: Any = None) -&gt; Any</code>","text":"<p>Gets a configuration value using a dot-separated path.</p> Example <p>settings.get_config(\"predictors.classifier.confidence\")</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | None</code> <p>A dot-separated string path to the configuration value. If None, returns the entire configuration object.</p> <code>None</code> <code>default</code> <code>Any</code> <p>A default value to return if the path is not found.</p> <code>None</code> <p>Returns:</p> Type Description <code>Any</code> <p>The configuration value, or the default value if not found.</p> Source code in <code>culicidaelab\\core\\settings.py</code> <pre><code>def get_config(self, path: str | None = None, default: Any = None) -&gt; Any:\n    \"\"\"Gets a configuration value using a dot-separated path.\n\n    Example:\n        &gt;&gt;&gt; settings.get_config(\"predictors.classifier.confidence\")\n\n    Args:\n        path: A dot-separated string path to the configuration value.\n            If None, returns the entire configuration object.\n        default: A default value to return if the path is not found.\n\n    Returns:\n        The configuration value, or the default value if not found.\n    \"\"\"\n    if not path:\n        return self.config\n\n    obj = self.config\n    try:\n        for key in path.split(\".\"):\n            if isinstance(obj, dict):\n                obj = obj.get(key)\n            else:\n                obj = getattr(obj, key)\n        return obj if obj is not None else default\n    except (AttributeError, KeyError):\n        return default\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.Settings.set_config","title":"<code>set_config(path: str, value: Any) -&gt; None</code>","text":"<p>Sets a configuration value at a specified dot-separated path. This method can traverse both objects (Pydantic models) and dictionaries.</p> <p>Note: This modifies the configuration in memory. To make it persistent, call <code>save_config()</code>.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str</code> <p>A dot-separated string path to the configuration value.</p> required <code>value</code> <code>Any</code> <p>The new value to set.</p> required Source code in <code>culicidaelab\\core\\settings.py</code> <pre><code>def set_config(self, path: str, value: Any) -&gt; None:\n    \"\"\"\n    Sets a configuration value at a specified dot-separated path.\n    This method can traverse both objects (Pydantic models) and dictionaries.\n\n    Note: This modifies the configuration in memory. To make it persistent,\n    call `save_config()`.\n\n    Args:\n        path: A dot-separated string path to the configuration value.\n        value: The new value to set.\n    \"\"\"\n    keys = path.split(\".\")\n    obj = self.config\n\n    for key in keys[:-1]:\n        if isinstance(obj, dict):\n            obj = obj.get(key)\n        else:\n            obj = getattr(obj, key)\n\n        if obj is None:\n            raise KeyError(f\"The path part '{key}' in '{path}' was not found.\")\n\n    last_key = keys[-1]\n    if isinstance(obj, dict):\n        obj[last_key] = value\n    else:\n        setattr(obj, last_key, value)\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.Settings.save_config","title":"<code>save_config(file_path: str | Path | None = None) -&gt; None</code>","text":"<p>Save current configuration to a user config file. Args:     file_path: Optional path to save the configuration file.         If None, defaults to \"culicidaelab_saved.yaml\" in the user config directory.</p> Source code in <code>culicidaelab\\core\\settings.py</code> <pre><code>def save_config(self, file_path: str | Path | None = None) -&gt; None:\n    \"\"\"Save current configuration to a user config file.\n    Args:\n        file_path: Optional path to save the configuration file.\n            If None, defaults to \"culicidaelab_saved.yaml\" in the user config directory.\n    \"\"\"\n    if file_path is None:\n        if not self._config_manager.user_config_dir:\n            raise ValueError(\"Cannot save config without a specified user config directory.\")\n        file_path = self._config_manager.user_config_dir / \"culicidaelab_saved.yaml\"\n    self._config_manager.save_config(file_path)\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.Settings.get_cache_key_for_split","title":"<code>get_cache_key_for_split(split: str | list[str] | None) -&gt; str</code>","text":"<p>Generates a unique, deterministic hash for any valid split configuration. This hash is used to create unique directory names for dataset splits.</p> <p>Parameters:</p> Name Type Description Default <code>split</code> <code>str | list[str] | None</code> <p>The split configuration to hash. Can be a single split name (e.g., 'train'), a list of splits (e.g., ['train', 'val']), or None.</p> required <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>A 16-character hexadecimal hash that uniquely identifies the split configuration. This hash is deterministic for the same input.</p> Example <p>settings.get_cache_key_for_split('train') 'a1b2c3d4e5f6g7h8' settings.get_cache_key_for_split(['train', 'val']) 'h8g7f6e5d4c3b2a1'</p> Source code in <code>culicidaelab\\core\\settings.py</code> <pre><code>def get_cache_key_for_split(self, split: str | list[str] | None) -&gt; str:\n    \"\"\"\n    Generates a unique, deterministic hash for any valid split configuration.\n    This hash is used to create unique directory names for dataset splits.\n\n    Args:\n        split (str | list[str] | None): The split configuration to hash.\n            Can be a single split name (e.g., 'train'), a list of splits\n            (e.g., ['train', 'val']), or None.\n\n    Returns:\n        str: A 16-character hexadecimal hash that uniquely identifies the\n            split configuration. This hash is deterministic for the same\n            input.\n\n    Example:\n        &gt;&gt;&gt; settings.get_cache_key_for_split('train')\n        'a1b2c3d4e5f6g7h8'\n        &gt;&gt;&gt; settings.get_cache_key_for_split(['train', 'val'])\n        'h8g7f6e5d4c3b2a1'\n    \"\"\"\n    if isinstance(split, list):\n        split.sort()\n\n    # json.dumps correctly handles None, converting it to the string \"null\"\n    split_str = json.dumps(split, sort_keys=True)\n\n    hasher = hashlib.sha256(split_str.encode(\"utf-8\"))\n    return hasher.hexdigest()[:16]\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.Settings.construct_split_path","title":"<code>construct_split_path(dataset_base_path: Path, split: str | list[str] | None = None) -&gt; Path</code>","text":"<p>Gets the standardized, absolute path for a dataset's directory.</p> <p>This is the single source of truth for dataset path construction.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the dataset (e.g., 'classification').</p> required <code>split</code> <code>str | list[str] | None</code> <p>If provided, returns the specific cache path for this split configuration. Otherwise, returns the base directory for the dataset.</p> <code>None</code> <code>ensure_exists</code> <code>bool</code> <p>If True, ensures the directory is created on disk.</p> required <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>The absolute path to the dataset directory.</p> Source code in <code>culicidaelab\\core\\settings.py</code> <pre><code>def construct_split_path(\n    self,\n    dataset_base_path: Path,\n    split: str | list[str] | None = None,\n) -&gt; Path:\n    \"\"\"\n    Gets the standardized, absolute path for a dataset's directory.\n\n    This is the single source of truth for dataset path construction.\n\n    Args:\n        name (str): The name of the dataset (e.g., 'classification').\n        split (str | list[str] | None, optional): If provided, returns the specific\n            cache path for this split configuration. Otherwise, returns the base\n            directory for the dataset.\n        ensure_exists (bool): If True, ensures the directory is created on disk.\n\n    Returns:\n        Path: The absolute path to the dataset directory.\n    \"\"\"\n    # Determine the final path (either base or split-specific)\n    final_path = dataset_base_path\n    if split is not None:\n        split_key = self.get_cache_key_for_split(split)\n        final_path = dataset_base_path / split_key\n\n    return final_path\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.Settings.get_dataset_path","title":"<code>get_dataset_path(dataset_type: str, split: str | list[str] | None = None) -&gt; Path</code>","text":"<p>Gets the standardized path for a specific dataset directory.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_type</code> <code>str</code> <p>The name of the dataset type (e.g., 'classification').</p> required <p>Returns:</p> Type Description <code>Path</code> <p>An absolute path to the dataset directory.</p> Source code in <code>culicidaelab\\core\\settings.py</code> <pre><code>def get_dataset_path(self, dataset_type: str, split: str | list[str] | None = None) -&gt; Path:\n    \"\"\"Gets the standardized path for a specific dataset directory.\n\n    Args:\n        dataset_type: The name of the dataset type (e.g., 'classification').\n\n    Returns:\n        An absolute path to the dataset directory.\n    \"\"\"\n    if dataset_type not in self.config.datasets:\n        raise ValueError(f\"Dataset type '{dataset_type}' not configured.\")\n\n    dataset_path_str = self.config.datasets[dataset_type].path\n    filal_path = Path(dataset_path_str)\n    if not filal_path.is_absolute():\n        filal_path = self.dataset_dir / filal_path\n\n    filal_path.mkdir(parents=True, exist_ok=True)\n\n    if split is not None:\n        filal_path = self.construct_split_path(\n            dataset_base_path=filal_path,\n            split=split,\n        )\n    return filal_path\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.Settings.list_datasets","title":"<code>list_datasets() -&gt; list[str]</code>","text":"<p>Get list of configured dataset types in the application.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of dataset type identifiers that are configured in the application settings. These correspond to the different dataset categories available for training and inference.</p> Example <p>settings.list_datasets() ['classification', 'detection', 'segmentation']</p> Source code in <code>culicidaelab\\core\\settings.py</code> <pre><code>def list_datasets(self) -&gt; list[str]:\n    \"\"\"Get list of configured dataset types in the application.\n\n    Returns:\n        list[str]: A list of dataset type identifiers that are configured\n            in the application settings. These correspond to the different\n            dataset categories available for training and inference.\n\n    Example:\n        &gt;&gt;&gt; settings.list_datasets()\n        ['classification', 'detection', 'segmentation']\n    \"\"\"\n    return list(self.config.datasets.keys())\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.Settings.construct_weights_path","title":"<code>construct_weights_path(predictor_type: str, backend: str | None = None) -&gt; Path</code>","text":"<p>A pure, static function to construct a fully qualified model weights path.</p> <p>This is the single source of truth for model path construction, creating a structured path like: .../models///. <p>Parameters:</p> Name Type Description Default <code>model_dir</code> <code>Path</code> <p>The base directory for all models (e.g., '.../culicidaelab/models').</p> required <code>predictor_type</code> <code>str</code> <p>The type of the predictor (e.g., 'classifier'). Used as a subdirectory.</p> required <code>predictor_config</code> <code>PredictorConfig</code> <p>The Pydantic model for the predictor's configuration.</p> required <code>backend</code> <code>str | None</code> <p>The target backend (e.g., 'torch', 'onnx').                             If None, uses the default from the config.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>The absolute, structured path to the model weights file.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If a valid backend or weights filename cannot be determined.</p> Source code in <code>culicidaelab\\core\\settings.py</code> <pre><code>def construct_weights_path(\n    self,\n    predictor_type: str,\n    backend: str | None = None,\n) -&gt; Path:\n    \"\"\"\n    A pure, static function to construct a fully qualified model weights path.\n\n    This is the single source of truth for model path construction, creating a\n    structured path like: .../models/&lt;predictor_type&gt;/&lt;backend&gt;/&lt;filename&gt;.\n\n    Args:\n        model_dir (Path): The base directory for all models (e.g., '.../culicidaelab/models').\n        predictor_type (str): The type of the predictor (e.g., 'classifier'). Used as a subdirectory.\n        predictor_config (PredictorConfig): The Pydantic model for the predictor's configuration.\n        backend (str | None, optional): The target backend (e.g., 'torch', 'onnx').\n                                        If None, uses the default from the config.\n\n    Returns:\n        Path: The absolute, structured path to the model weights file.\n\n    Raises:\n        ValueError: If a valid backend or weights filename cannot be determined.\n    \"\"\"\n    predictor_config = self.get_config(f\"predictors.{predictor_type}\")\n    final_backend = backend if backend is not None else predictor_config.backend\n    if not final_backend:\n        raise ValueError(f\"No backend specified for model '{predictor_type}'.\")\n\n    if not predictor_config.weights or final_backend not in predictor_config.weights:\n        raise ValueError(f\"Backend '{final_backend}' not defined in weights config for '{predictor_type}'.\")\n\n    filename = predictor_config.weights[final_backend].filename\n    if not filename:\n        raise ValueError(f\"Filename for backend '{final_backend}' is missing in config for '{predictor_type}'.\")\n\n    # Sanitize the components that will become directories\n    predictor_dir = create_safe_path(predictor_type)\n    backend_dir = create_safe_path(final_backend)\n\n    # Assemble the final, structured path\n    return self.model_dir / predictor_dir / backend_dir / filename\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.Settings.get_model_weights_path","title":"<code>get_model_weights_path(model_type: str, backend: str | None = None) -&gt; Path</code>","text":"<p>Gets the configured path to a model's weights file.</p> <p>Parameters:</p> Name Type Description Default <code>model_type</code> <code>str</code> <p>The name of the model type (e.g., 'classifier').</p> required <p>Returns:</p> Type Description <code>Path</code> <p>The path to the model weights file.</p> Source code in <code>culicidaelab\\core\\settings.py</code> <pre><code>def get_model_weights_path(\n    self,\n    model_type: str,\n    backend: str | None = None,\n) -&gt; Path:\n    \"\"\"Gets the configured path to a model's weights file.\n\n    Args:\n        model_type: The name of the model type (e.g., 'classifier').\n\n    Returns:\n        The path to the model weights file.\n    \"\"\"\n    if model_type not in self.config.predictors:\n        raise ValueError(f\"Model type '{model_type}' not configured in 'predictors'.\")\n\n    local_path = self.construct_weights_path(\n        predictor_type=model_type,\n        backend=backend,\n    )\n    return local_path\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.Settings.list_model_types","title":"<code>list_model_types() -&gt; list[str]</code>","text":"<p>Get list of available model types configured in the application.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>list[str]: A list of model type identifiers (e.g., ['classifier', 'detector', 'segmenter']) that are configured in the application. These types correspond to the different predictors available in the CulicidaeLab system.</p> Example <p>settings.list_model_types() ['classifier', 'detector', 'segmenter']</p> Source code in <code>culicidaelab\\core\\settings.py</code> <pre><code>def list_model_types(self) -&gt; list[str]:\n    \"\"\"Get list of available model types configured in the application.\n\n    Returns:\n        list[str]: A list of model type identifiers (e.g., ['classifier',\n            'detector', 'segmenter']) that are configured in the application.\n            These types correspond to the different predictors available\n            in the CulicidaeLab system.\n\n    Example:\n        &gt;&gt;&gt; settings.list_model_types()\n        ['classifier', 'detector', 'segmenter']\n    \"\"\"\n    return list(self.config.predictors.keys())\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.Settings.get_api_key","title":"<code>get_api_key(provider: str) -&gt; str | None</code>","text":"<p>Get API key for external provider from environment variables.</p> <p>The method looks for environment variables in the following format: - KAGGLE_API_KEY for 'kaggle' provider - HUGGINGFACE_API_KEY for 'huggingface' provider - ROBOFLOW_API_KEY for 'roboflow' provider</p> <p>Parameters:</p> Name Type Description Default <code>provider</code> <code>str</code> <p>The name of the provider. Must be one of: 'kaggle', 'huggingface', or 'roboflow'.</p> required <p>Returns:</p> Type Description <code>str | None</code> <p>str | None: The API key if found in environment variables, None if the provider is not supported or the key is not set.</p> Example <p>api_key = settings.get_api_key('huggingface') if api_key: ...     # Use the API key ... else: ...     # Handle missing key</p> Source code in <code>culicidaelab\\core\\settings.py</code> <pre><code>def get_api_key(self, provider: str) -&gt; str | None:\n    \"\"\"Get API key for external provider from environment variables.\n\n    The method looks for environment variables in the following format:\n    - KAGGLE_API_KEY for 'kaggle' provider\n    - HUGGINGFACE_API_KEY for 'huggingface' provider\n    - ROBOFLOW_API_KEY for 'roboflow' provider\n\n    Args:\n        provider (str): The name of the provider. Must be one of:\n            'kaggle', 'huggingface', or 'roboflow'.\n\n    Returns:\n        str | None: The API key if found in environment variables,\n            None if the provider is not supported or the key is not set.\n\n    Example:\n        &gt;&gt;&gt; api_key = settings.get_api_key('huggingface')\n        &gt;&gt;&gt; if api_key:\n        ...     # Use the API key\n        ... else:\n        ...     # Handle missing key\n    \"\"\"\n    api_keys = {\n        \"kaggle\": \"KAGGLE_API_KEY\",\n        \"huggingface\": \"HUGGINGFACE_API_KEY\",\n        \"roboflow\": \"ROBOFLOW_API_KEY\",\n    }\n    if provider in api_keys:\n        return os.getenv(api_keys[provider])\n    return None\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.Settings.temp_workspace","title":"<code>temp_workspace(prefix: str = 'workspace')</code>","text":"<p>Creates a temporary workspace directory that is automatically cleaned up.</p> <p>This context manager creates a temporary directory for processing operations and automatically cleans it up when the context is exited.</p> <p>Parameters:</p> Name Type Description Default <code>prefix</code> <code>str</code> <p>Prefix for the temporary directory name. Defaults to \"workspace\".</p> <code>'workspace'</code> <p>Yields:</p> Name Type Description <code>Path</code> <p>Path to the temporary workspace directory.</p> Example <p>with settings.temp_workspace(prefix='processing') as workspace: ...     # Do some work in the temporary directory ...     (workspace / 'output.txt').write_text('results')</p> Source code in <code>culicidaelab\\core\\settings.py</code> <pre><code>@contextmanager\ndef temp_workspace(self, prefix: str = \"workspace\"):\n    \"\"\"Creates a temporary workspace directory that is automatically cleaned up.\n\n    This context manager creates a temporary directory for processing operations\n    and automatically cleans it up when the context is exited.\n\n    Args:\n        prefix (str, optional): Prefix for the temporary directory name.\n            Defaults to \"workspace\".\n\n    Yields:\n        Path: Path to the temporary workspace directory.\n\n    Example:\n        &gt;&gt;&gt; with settings.temp_workspace(prefix='processing') as workspace:\n        ...     # Do some work in the temporary directory\n        ...     (workspace / 'output.txt').write_text('results')\n        # Directory is automatically cleaned up after the with block\n    \"\"\"\n    with self._resource_manager.temp_workspace(prefix) as workspace:\n        yield workspace\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.Settings.temp_workspace--directory-is-automatically-cleaned-up-after-the-with-block","title":"Directory is automatically cleaned up after the with block","text":""},{"location":"api_docs/core/#culicidaelab.core.Settings.instantiate_from_config","title":"<code>instantiate_from_config(config_path: str, **kwargs: Any) -&gt; Any</code>","text":"<p>Instantiates an object from a configuration path.</p> <p>This is a convenience method that finds a config object by its path and uses the underlying ConfigManager to instantiate it.</p> <p>Parameters:</p> Name Type Description Default <code>config_path</code> <code>str</code> <p>A dot-separated path to the configuration object (e.g., \"predictors.classifier\").</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to pass to the constructor.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Any</code> <p>The instantiated object.</p> Source code in <code>culicidaelab\\core\\settings.py</code> <pre><code>def instantiate_from_config(self, config_path: str, **kwargs: Any) -&gt; Any:\n    \"\"\"Instantiates an object from a configuration path.\n\n    This is a convenience method that finds a config object by its path\n    and uses the underlying ConfigManager to instantiate it.\n\n    Args:\n        config_path: A dot-separated path to the configuration object\n            (e.g., \"predictors.classifier\").\n        **kwargs: Additional keyword arguments to pass to the constructor.\n\n    Returns:\n        The instantiated object.\n    \"\"\"\n\n    config_obj = self.get_config(config_path)\n    if not config_obj:\n        raise ValueError(f\"No configuration object found at path: {config_path}\")\n\n    extra_deps = {\"settings\": self}\n\n    return self._config_manager.instantiate_from_config(\n        config_obj,\n        extra_params=extra_deps,\n        **kwargs,\n    )\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.get_settings","title":"<code>get_settings(config_dir: str | Path | None = None) -&gt; Settings</code>","text":"<p>Get the Settings singleton instance.</p> <p>This is the primary way to access Settings throughout the application. If a <code>config_dir</code> is provided that differs from the existing instance, a new instance will be created and returned.</p> <p>Parameters:</p> Name Type Description Default <code>config_dir</code> <code>str | Path | None</code> <p>Optional path to a user-provided configuration directory.</p> <code>None</code> <p>Returns:</p> Type Description <code>Settings</code> <p>The Settings instance.</p> Source code in <code>culicidaelab\\core\\settings.py</code> <pre><code>def get_settings(config_dir: str | Path | None = None) -&gt; Settings:\n    \"\"\"\n    Get the Settings singleton instance.\n\n    This is the primary way to access Settings throughout the application.\n    If a `config_dir` is provided that differs from the existing instance,\n    a new instance will be created and returned.\n\n    Args:\n        config_dir: Optional path to a user-provided configuration directory.\n\n    Returns:\n        The Settings instance.\n    \"\"\"\n    global _SETTINGS_INSTANCE\n    with _SETTINGS_LOCK:\n        resolved_path = Path(config_dir).resolve() if config_dir else None\n\n        # Create a new instance if one doesn't exist, or if the config path has changed.\n        if _SETTINGS_INSTANCE is None or _SETTINGS_INSTANCE._current_config_dir != resolved_path:\n            _SETTINGS_INSTANCE = Settings(config_dir=config_dir)\n\n        return _SETTINGS_INSTANCE\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.download_file","title":"<code>download_file(url: str, destination: str | Path | None = None, downloads_dir: str | Path | None = None, progress_callback: Callable | None = None, chunk_size: int = 8192, timeout: int = 30, desc: str | None = None) -&gt; Path</code>","text":"<p>Downloads a file from the specified URL showing a progress bar and optionally calling a progress callback function. Supports both direct destination paths and default download directories.</p> <p>Parameters:</p> Name Type Description Default <code>url</code> <code>str</code> <p>The URL of the file to download. Must start with 'http://' or 'https://'.</p> required <code>destination</code> <code>Union[str, Path, None]</code> <p>The complete file path where the downloaded file should be saved. If None, the file will be saved in downloads_dir with its original filename. Defaults to None.</p> <code>None</code> <code>downloads_dir</code> <code>Union[str, Path, None]</code> <p>The directory to save the file in when no specific destination is provided. If None, uses current working directory. Defaults to None.</p> <code>None</code> <code>progress_callback</code> <code>Optional[Callable[[int, int], None]]</code> <p>A function to call with progress updates. Takes two parameters: bytes downloaded and total bytes. Defaults to None.</p> <code>None</code> <code>chunk_size</code> <code>int</code> <p>Size of chunks to download in bytes. Larger chunks use more memory but may download faster. Defaults to 8192.</p> <code>8192</code> <code>timeout</code> <code>int</code> <p>Number of seconds to wait for server response before timing out. Defaults to 30.</p> <code>30</code> <code>desc</code> <code>Optional[str]</code> <p>Custom description for the progress bar. If None, uses the filename. Defaults to None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>Path object pointing to the downloaded file.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the URL is invalid or doesn't start with http(s).</p> <code>RuntimeError</code> <p>If the download fails due to network issues or if writing the file fails due to permission or disk space issues.</p> Example <p>from pathlib import Path</p> Source code in <code>culicidaelab\\core\\utils.py</code> <pre><code>def download_file(\n    url: str,\n    destination: str | Path | None = None,\n    downloads_dir: str | Path | None = None,\n    progress_callback: Callable | None = None,\n    chunk_size: int = 8192,\n    timeout: int = 30,\n    desc: str | None = None,\n) -&gt; Path:\n    \"\"\"\n    Downloads a file from the specified URL showing a progress bar and optionally calling\n    a progress callback function. Supports both direct destination paths and default\n    download directories.\n\n    Args:\n        url (str): The URL of the file to download. Must start with 'http://' or 'https://'.\n        destination (Union[str, Path, None], optional): The complete file path where the\n            downloaded file should be saved. If None, the file will be saved in downloads_dir\n            with its original filename. Defaults to None.\n        downloads_dir (Union[str, Path, None], optional): The directory to save the file in\n            when no specific destination is provided. If None, uses current working directory.\n            Defaults to None.\n        progress_callback (Optional[Callable[[int, int], None]], optional): A function to call\n            with progress updates. Takes two parameters: bytes downloaded and total bytes.\n            Defaults to None.\n        chunk_size (int, optional): Size of chunks to download in bytes. Larger chunks use\n            more memory but may download faster. Defaults to 8192.\n        timeout (int, optional): Number of seconds to wait for server response before timing\n            out. Defaults to 30.\n        desc (Optional[str], optional): Custom description for the progress bar. If None,\n            uses the filename. Defaults to None.\n\n    Returns:\n        Path: Path object pointing to the downloaded file.\n\n    Raises:\n        ValueError: If the URL is invalid or doesn't start with http(s).\n        RuntimeError: If the download fails due to network issues or if writing the file\n            fails due to permission or disk space issues.\n\n    Example:\n        &gt;&gt;&gt; from pathlib import Path\n        &gt;&gt;&gt; # Basic download to current directory\n        &gt;&gt;&gt; path = download_file('https://example.com/data.csv')\n        &gt;&gt;&gt; print(path)\n        PosixPath('data.csv')\n\n        &gt;&gt;&gt; # Download with custom progress tracking\n        &gt;&gt;&gt; def progress(current, total):\n        ...     print(f'Downloaded {current}/{total} bytes')\n        &gt;&gt;&gt; path = download_file(\n        ...     'https://example.com/large_file.zip',\n        ...     destination='downloads/myfile.zip',\n        ...     progress_callback=progress\n        ... )\n    \"\"\"\n    if not url or not url.startswith((\"http://\", \"https://\")):\n        raise ValueError(f\"Invalid URL: {url}\")\n\n    dest_path = Path(destination) if destination else None\n    if dest_path is None:\n        base_dir = Path(downloads_dir) if downloads_dir else Path.cwd()\n        base_dir.mkdir(parents=True, exist_ok=True)\n        filename = url.split(\"/\")[-1]\n        dest_path = base_dir / filename\n\n    dest_path.parent.mkdir(parents=True, exist_ok=True)\n\n    try:\n        with requests.get(url, stream=True, timeout=timeout) as response:\n            response.raise_for_status()\n            total_size = int(response.headers.get(\"content-length\", 0))\n            progress_desc = desc or f\"Downloading {dest_path.name}\"\n\n            with tqdm.tqdm(\n                total=total_size,\n                unit=\"iB\",\n                unit_scale=True,\n                desc=progress_desc,\n            ) as pbar:\n                with open(dest_path, \"wb\") as file:\n                    for chunk in response.iter_content(chunk_size=chunk_size):\n                        written_size = file.write(chunk)\n                        pbar.update(written_size)\n                        if progress_callback:\n                            try:\n                                progress_callback(pbar.n, total_size)\n                            except Exception as cb_err:\n                                logging.warning(f\"Progress callback error: {cb_err}\")\n        return dest_path\n    except requests.RequestException as e:\n        logging.error(f\"Download failed for {url}: {e}\")\n        raise RuntimeError(f\"Failed to download file from {url}: {e}\") from e\n    except OSError as e:\n        logging.error(f\"File write error for {dest_path}: {e}\")\n        raise RuntimeError(f\"Failed to write file to {dest_path}: {e}\") from e\n</code></pre>"},{"location":"api_docs/core/#culicidaelab.core.download_file--basic-download-to-current-directory","title":"Basic download to current directory","text":"<p>path = download_file('https://example.com/data.csv') print(path) PosixPath('data.csv')</p>"},{"location":"api_docs/core/#culicidaelab.core.download_file--download-with-custom-progress-tracking","title":"Download with custom progress tracking","text":"<p>def progress(current, total): ...     print(f'Downloaded {current}/{total} bytes') path = download_file( ...     'https://example.com/large_file.zip', ...     destination='downloads/myfile.zip', ...     progress_callback=progress ... )</p>"},{"location":"api_docs/datasets/","title":"Datasets API","text":"<p>handler: python selection: members: true</p>"},{"location":"api_docs/datasets/#culicidaelab.datasets","title":"<code>culicidaelab.datasets</code>","text":"<p>Dataset management components for the CulicidaeLab library.</p> <p>This module provides the DatasetsManager, a high-level interface for accessing, loading, and managing datasets as defined in the application's configuration. It simplifies interactions with different data sources and providers.</p>"},{"location":"api_docs/datasets/#culicidaelab.datasets.__all__","title":"<code>__all__ = ['DatasetsManager']</code>  <code>module-attribute</code>","text":""},{"location":"api_docs/datasets/#culicidaelab.datasets.DatasetsManager","title":"<code>DatasetsManager</code>","text":"<p>Manages access, loading, and caching of configured datasets.</p> <p>This manager provides a high-level interface that uses the global settings for configuration and a dedicated provider service for the actual data loading. This decouples the logic of what datasets are available from how they are loaded and sourced.</p> <p>Attributes:</p> Name Type Description <code>settings</code> <p>The main settings object for the library.</p> <code>provider_service</code> <p>The service for resolving and using data providers.</p> <code>loaded_datasets</code> <code>dict[str, str | Path]</code> <p>A cache for storing the paths of downloaded datasets.</p> Source code in <code>culicidaelab\\datasets\\datasets_manager.py</code> <pre><code>class DatasetsManager:\n    \"\"\"Manages access, loading, and caching of configured datasets.\n\n    This manager provides a high-level interface that uses the global settings\n    for configuration and a dedicated provider service for the actual data\n    loading. This decouples the logic of what datasets are available from how\n    they are loaded and sourced.\n\n    Attributes:\n        settings: The main settings object for the library.\n        provider_service: The service for resolving and using data providers.\n        loaded_datasets: A cache for storing the paths of downloaded datasets.\n    \"\"\"\n\n    def __init__(self, settings: Settings):\n        \"\"\"Initializes the DatasetsManager with its dependencies.\n\n        Args:\n            settings: The main Settings object for the library.\n        \"\"\"\n        self.settings = settings\n        self.provider_service = ProviderService(settings)\n        self.loaded_datasets: dict[str, str | Path] = {}\n\n    def get_dataset_info(self, dataset_name: str) -&gt; DatasetConfig:\n        \"\"\"Retrieves the configuration for a specific dataset.\n\n        Example:\n            &gt;&gt;&gt; from culicidaelab.settings import Settings\n            &gt;&gt;&gt; from culicidaelab.datasets import DatasetsManager\n            &gt;&gt;&gt; settings = Settings()\n            &gt;&gt;&gt; manager = DatasetsManager(settings)\n            &gt;&gt;&gt; try:\n            ...     info = manager.get_dataset_info('classification')\n            ...     print(info.provider_name)\n            ... except KeyError as e:\n            ...     print(e)\n\n        Args:\n            dataset_name: The name of the dataset (e.g., 'classification').\n\n        Returns:\n            A Pydantic model instance containing the dataset's\n            validated configuration.\n\n        Raises:\n            KeyError: If the specified dataset is not found in the configuration.\n        \"\"\"\n        dataset_config = self.settings.get_config(f\"datasets.{dataset_name}\")\n        if not dataset_config:\n            raise KeyError(f\"Dataset '{dataset_name}' not found in configuration.\")\n        return dataset_config\n\n    def list_datasets(self) -&gt; list[str]:\n        \"\"\"Lists all available dataset names from the configuration.\n\n        Example:\n            &gt;&gt;&gt; from culicidaelab.settings import Settings\n            &gt;&gt;&gt; from culicidaelab.datasets import DatasetsManager\n            &gt;&gt;&gt; settings = Settings()\n            &gt;&gt;&gt; manager = DatasetsManager(settings)\n            &gt;&gt;&gt; available_datasets = manager.list_datasets()\n            &gt;&gt;&gt; print(available_datasets)\n\n        Returns:\n            A list of configured dataset names.\n        \"\"\"\n        return self.settings.list_datasets()\n\n    def list_loaded_datasets(self) -&gt; list[str]:\n        \"\"\"Lists all datasets that have been loaded during the session.\n\n        Example:\n            &gt;&gt;&gt; from culicidaelab.settings import Settings\n            &gt;&gt;&gt; from culicidaelab.datasets import DatasetsManager\n            &gt;&gt;&gt; settings = Settings()\n            &gt;&gt;&gt; manager = DatasetsManager(settings)\n            &gt;&gt;&gt; _ = manager.load_dataset('classification', split='train')\n            &gt;&gt;&gt; loaded = manager.list_loaded_datasets()\n            &gt;&gt;&gt; print(loaded)\n            ['classification']\n\n        Returns:\n            A list of names for datasets that are currently cached.\n        \"\"\"\n        return list(self.loaded_datasets.keys())\n\n    def load_dataset(\n        self,\n        name: str,\n        split: str | list[str] | None = None,\n        config_name: str | None = \"default\",\n    ) -&gt; Any:\n        \"\"\"Loads a dataset, handling complex splits and caching automatically.\n\n        Example:\n            &gt;&gt;&gt; from culicidaelab.settings import Settings\n            &gt;&gt;&gt; from culicidaelab.datasets import DatasetsManager\n            &gt;&gt;&gt; # This example assumes you have a configured settings object\n            &gt;&gt;&gt; settings = Settings()\n            &gt;&gt;&gt; manager = DatasetsManager(settings)\n            &gt;&gt;&gt; # Load the training split of the classification dataset\n            &gt;&gt;&gt; train_dataset = manager.load_dataset('classification', split='train')\n            &gt;&gt;&gt; # Load all splits\n            &gt;&gt;&gt; all_splits = manager.load_dataset('classification')\n\n        Args:\n            name: The name of the dataset to load.\n            split: The split(s) to load.\n                - str: A single split name (e.g., \"train\", \"test\").\n                - None: Loads ALL available splits into a `DatasetDict`.\n                - Advanced: Can be a slice (\"train[:100]\") or a list for\n                  cross-validation.\n            config_name: The name of the dataset configuration to use.\n                Defaults to \"default\".\n\n        Returns:\n            The loaded dataset object, which could be a `Dataset` or `DatasetDict`\n            depending on the provider and splits requested.\n        \"\"\"\n        # 1. Get config and provider\n        config = self.get_dataset_info(name)\n        provider = self.provider_service.get_provider(config.provider_name)\n\n        split_path = self.settings.get_dataset_path(\n            dataset_type=name,\n            split=split,\n        )\n\n        # Check cache, otherwise download\n        downloaded_path = None\n        if not split_path.exists():\n            # Instruct the provider to download and save to the precise cache path\n            downloaded_path = provider.download_dataset(\n                dataset_name=name,\n                config_name=config_name,\n                save_dir=split_path,\n                split=split,\n            )\n        else:\n            print(f\"Cache hit for split config: {split} {split_path}\")\n\n        # Instruct the provider to load from the appropriate path\n        load_from = downloaded_path or split_path\n\n        dataset = provider.load_dataset(load_from)\n\n        # Update the session cache\n        self.loaded_datasets[name] = load_from\n\n        return dataset\n</code></pre>"},{"location":"api_docs/datasets/#culicidaelab.datasets.DatasetsManager.settings","title":"<code>settings = settings</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/datasets/#culicidaelab.datasets.DatasetsManager.provider_service","title":"<code>provider_service = ProviderService(settings)</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/datasets/#culicidaelab.datasets.DatasetsManager.loaded_datasets","title":"<code>loaded_datasets: dict[str, str | Path] = {}</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/datasets/#culicidaelab.datasets.DatasetsManager.__init__","title":"<code>__init__(settings: Settings)</code>","text":"<p>Initializes the DatasetsManager with its dependencies.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>Settings</code> <p>The main Settings object for the library.</p> required Source code in <code>culicidaelab\\datasets\\datasets_manager.py</code> <pre><code>def __init__(self, settings: Settings):\n    \"\"\"Initializes the DatasetsManager with its dependencies.\n\n    Args:\n        settings: The main Settings object for the library.\n    \"\"\"\n    self.settings = settings\n    self.provider_service = ProviderService(settings)\n    self.loaded_datasets: dict[str, str | Path] = {}\n</code></pre>"},{"location":"api_docs/datasets/#culicidaelab.datasets.DatasetsManager.get_dataset_info","title":"<code>get_dataset_info(dataset_name: str) -&gt; DatasetConfig</code>","text":"<p>Retrieves the configuration for a specific dataset.</p> Example <p>from culicidaelab.settings import Settings from culicidaelab.datasets import DatasetsManager settings = Settings() manager = DatasetsManager(settings) try: ...     info = manager.get_dataset_info('classification') ...     print(info.provider_name) ... except KeyError as e: ...     print(e)</p> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>The name of the dataset (e.g., 'classification').</p> required <p>Returns:</p> Type Description <code>DatasetConfig</code> <p>A Pydantic model instance containing the dataset's</p> <code>DatasetConfig</code> <p>validated configuration.</p> <p>Raises:</p> Type Description <code>KeyError</code> <p>If the specified dataset is not found in the configuration.</p> Source code in <code>culicidaelab\\datasets\\datasets_manager.py</code> <pre><code>def get_dataset_info(self, dataset_name: str) -&gt; DatasetConfig:\n    \"\"\"Retrieves the configuration for a specific dataset.\n\n    Example:\n        &gt;&gt;&gt; from culicidaelab.settings import Settings\n        &gt;&gt;&gt; from culicidaelab.datasets import DatasetsManager\n        &gt;&gt;&gt; settings = Settings()\n        &gt;&gt;&gt; manager = DatasetsManager(settings)\n        &gt;&gt;&gt; try:\n        ...     info = manager.get_dataset_info('classification')\n        ...     print(info.provider_name)\n        ... except KeyError as e:\n        ...     print(e)\n\n    Args:\n        dataset_name: The name of the dataset (e.g., 'classification').\n\n    Returns:\n        A Pydantic model instance containing the dataset's\n        validated configuration.\n\n    Raises:\n        KeyError: If the specified dataset is not found in the configuration.\n    \"\"\"\n    dataset_config = self.settings.get_config(f\"datasets.{dataset_name}\")\n    if not dataset_config:\n        raise KeyError(f\"Dataset '{dataset_name}' not found in configuration.\")\n    return dataset_config\n</code></pre>"},{"location":"api_docs/datasets/#culicidaelab.datasets.DatasetsManager.list_datasets","title":"<code>list_datasets() -&gt; list[str]</code>","text":"<p>Lists all available dataset names from the configuration.</p> Example <p>from culicidaelab.settings import Settings from culicidaelab.datasets import DatasetsManager settings = Settings() manager = DatasetsManager(settings) available_datasets = manager.list_datasets() print(available_datasets)</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of configured dataset names.</p> Source code in <code>culicidaelab\\datasets\\datasets_manager.py</code> <pre><code>def list_datasets(self) -&gt; list[str]:\n    \"\"\"Lists all available dataset names from the configuration.\n\n    Example:\n        &gt;&gt;&gt; from culicidaelab.settings import Settings\n        &gt;&gt;&gt; from culicidaelab.datasets import DatasetsManager\n        &gt;&gt;&gt; settings = Settings()\n        &gt;&gt;&gt; manager = DatasetsManager(settings)\n        &gt;&gt;&gt; available_datasets = manager.list_datasets()\n        &gt;&gt;&gt; print(available_datasets)\n\n    Returns:\n        A list of configured dataset names.\n    \"\"\"\n    return self.settings.list_datasets()\n</code></pre>"},{"location":"api_docs/datasets/#culicidaelab.datasets.DatasetsManager.list_loaded_datasets","title":"<code>list_loaded_datasets() -&gt; list[str]</code>","text":"<p>Lists all datasets that have been loaded during the session.</p> Example <p>from culicidaelab.settings import Settings from culicidaelab.datasets import DatasetsManager settings = Settings() manager = DatasetsManager(settings) _ = manager.load_dataset('classification', split='train') loaded = manager.list_loaded_datasets() print(loaded) ['classification']</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of names for datasets that are currently cached.</p> Source code in <code>culicidaelab\\datasets\\datasets_manager.py</code> <pre><code>def list_loaded_datasets(self) -&gt; list[str]:\n    \"\"\"Lists all datasets that have been loaded during the session.\n\n    Example:\n        &gt;&gt;&gt; from culicidaelab.settings import Settings\n        &gt;&gt;&gt; from culicidaelab.datasets import DatasetsManager\n        &gt;&gt;&gt; settings = Settings()\n        &gt;&gt;&gt; manager = DatasetsManager(settings)\n        &gt;&gt;&gt; _ = manager.load_dataset('classification', split='train')\n        &gt;&gt;&gt; loaded = manager.list_loaded_datasets()\n        &gt;&gt;&gt; print(loaded)\n        ['classification']\n\n    Returns:\n        A list of names for datasets that are currently cached.\n    \"\"\"\n    return list(self.loaded_datasets.keys())\n</code></pre>"},{"location":"api_docs/datasets/#culicidaelab.datasets.DatasetsManager.load_dataset","title":"<code>load_dataset(name: str, split: str | list[str] | None = None, config_name: str | None = 'default') -&gt; Any</code>","text":"<p>Loads a dataset, handling complex splits and caching automatically.</p> Example <p>from culicidaelab.settings import Settings from culicidaelab.datasets import DatasetsManager</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>The name of the dataset to load.</p> required <code>split</code> <code>str | list[str] | None</code> <p>The split(s) to load. - str: A single split name (e.g., \"train\", \"test\"). - None: Loads ALL available splits into a <code>DatasetDict</code>. - Advanced: Can be a slice (\"train[:100]\") or a list for   cross-validation.</p> <code>None</code> <code>config_name</code> <code>str | None</code> <p>The name of the dataset configuration to use. Defaults to \"default\".</p> <code>'default'</code> <p>Returns:</p> Type Description <code>Any</code> <p>The loaded dataset object, which could be a <code>Dataset</code> or <code>DatasetDict</code></p> <code>Any</code> <p>depending on the provider and splits requested.</p> Source code in <code>culicidaelab\\datasets\\datasets_manager.py</code> <pre><code>def load_dataset(\n    self,\n    name: str,\n    split: str | list[str] | None = None,\n    config_name: str | None = \"default\",\n) -&gt; Any:\n    \"\"\"Loads a dataset, handling complex splits and caching automatically.\n\n    Example:\n        &gt;&gt;&gt; from culicidaelab.settings import Settings\n        &gt;&gt;&gt; from culicidaelab.datasets import DatasetsManager\n        &gt;&gt;&gt; # This example assumes you have a configured settings object\n        &gt;&gt;&gt; settings = Settings()\n        &gt;&gt;&gt; manager = DatasetsManager(settings)\n        &gt;&gt;&gt; # Load the training split of the classification dataset\n        &gt;&gt;&gt; train_dataset = manager.load_dataset('classification', split='train')\n        &gt;&gt;&gt; # Load all splits\n        &gt;&gt;&gt; all_splits = manager.load_dataset('classification')\n\n    Args:\n        name: The name of the dataset to load.\n        split: The split(s) to load.\n            - str: A single split name (e.g., \"train\", \"test\").\n            - None: Loads ALL available splits into a `DatasetDict`.\n            - Advanced: Can be a slice (\"train[:100]\") or a list for\n              cross-validation.\n        config_name: The name of the dataset configuration to use.\n            Defaults to \"default\".\n\n    Returns:\n        The loaded dataset object, which could be a `Dataset` or `DatasetDict`\n        depending on the provider and splits requested.\n    \"\"\"\n    # 1. Get config and provider\n    config = self.get_dataset_info(name)\n    provider = self.provider_service.get_provider(config.provider_name)\n\n    split_path = self.settings.get_dataset_path(\n        dataset_type=name,\n        split=split,\n    )\n\n    # Check cache, otherwise download\n    downloaded_path = None\n    if not split_path.exists():\n        # Instruct the provider to download and save to the precise cache path\n        downloaded_path = provider.download_dataset(\n            dataset_name=name,\n            config_name=config_name,\n            save_dir=split_path,\n            split=split,\n        )\n    else:\n        print(f\"Cache hit for split config: {split} {split_path}\")\n\n    # Instruct the provider to load from the appropriate path\n    load_from = downloaded_path or split_path\n\n    dataset = provider.load_dataset(load_from)\n\n    # Update the session cache\n    self.loaded_datasets[name] = load_from\n\n    return dataset\n</code></pre>"},{"location":"api_docs/datasets/#culicidaelab.datasets.DatasetsManager.load_dataset--this-example-assumes-you-have-a-configured-settings-object","title":"This example assumes you have a configured settings object","text":"<p>settings = Settings() manager = DatasetsManager(settings)</p>"},{"location":"api_docs/datasets/#culicidaelab.datasets.DatasetsManager.load_dataset--load-the-training-split-of-the-classification-dataset","title":"Load the training split of the classification dataset","text":"<p>train_dataset = manager.load_dataset('classification', split='train')</p>"},{"location":"api_docs/datasets/#culicidaelab.datasets.DatasetsManager.load_dataset--load-all-splits","title":"Load all splits","text":"<p>all_splits = manager.load_dataset('classification')</p>"},{"location":"api_docs/predictors/","title":"Predictors API","text":"<pre><code>selection:\n\nmembers: true\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors","title":"<code>culicidaelab.predictors</code>","text":"<p>This package contains the predictor classes for the culicidaelab library.</p>"},{"location":"api_docs/predictors/#culicidaelab.predictors.__all__","title":"<code>__all__ = ['MosquitoClassifier', 'MosquitoDetector', 'MosquitoSegmenter', 'ModelWeightsManager']</code>  <code>module-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier","title":"<code>MosquitoClassifier</code>","text":"<p>Classifies mosquito species from an image.</p> <p>This class provides methods to load a pre-trained model, predict species from single or batches of images, evaluate model performance, and visualize the classification results.</p> <p>Attributes:</p> Name Type Description <code>arch</code> <code>str</code> <p>The model architecture (e.g., 'convnext_tiny').</p> <code>data_dir</code> <code>Path</code> <p>The directory where datasets are stored.</p> <code>species_map</code> <code>dict[int, str]</code> <p>A mapping from class indices to species names.</p> <code>num_classes</code> <code>int</code> <p>The total number of species classes.</p> Source code in <code>culicidaelab\\predictors\\classifier.py</code> <pre><code>class MosquitoClassifier(\n    BasePredictor[ImageInput, ClassificationPrediction, ClassificationGroundTruthType],\n):\n    \"\"\"Classifies mosquito species from an image.\n\n    This class provides methods to load a pre-trained model, predict species\n    from single or batches of images, evaluate model performance, and visualize\n    the classification results.\n\n    Attributes:\n        arch (str): The model architecture (e.g., 'convnext_tiny').\n        data_dir (Path): The directory where datasets are stored.\n        species_map (dict[int, str]): A mapping from class indices to species names.\n        num_classes (int): The total number of species classes.\n    \"\"\"\n\n    def __init__(\n        self,\n        settings: Settings,\n        predictor_type=\"classifier\",\n        mode: Literal[\"torch\", \"serve\"] | None = None,\n        load_model: bool = False,\n        backend: BaseInferenceBackend | None = None,\n    ) -&gt; None:\n        \"\"\"Initializes the MosquitoClassifier.\n\n        Args:\n            settings: The main settings object for the library.\n            predictor_type: The type of predictor. Defaults to \"classifier\".\n            mode: The mode to run the predictor in, 'torch' or 'serve'.\n                If None, it's determined by the environment.\n            load_model: If True, load the model upon initialization.\n            backend: An optional backend instance. If not provided, one will be\n                created based on the mode and settings.\n        \"\"\"\n\n        backend_instance = backend or create_backend(\n            predictor_type=predictor_type,\n            settings=settings,\n            mode=mode,\n        )\n\n        super().__init__(\n            settings=settings,\n            predictor_type=predictor_type,\n            backend=backend_instance,\n            load_model=load_model,\n        )\n        self.arch: str | None = self.config.model_arch\n\n        self.data_dir: Path = self.settings.dataset_dir\n        self.species_map: dict[int, str] = self.settings.species_config.species_map\n        self.labels_map: dict[\n            str,\n            str,\n        ] = self.settings.species_config.class_to_full_name_map\n        self.num_classes: int = len(self.species_map)\n\n    # --------------------------------------------------------------------------\n    # Public Methods\n    # --------------------------------------------------------------------------\n\n    def get_class_index(self, species_name: str) -&gt; int | None:\n        \"\"\"Retrieves the class index for a given species name.\n\n        Args:\n            species_name: The name of the species.\n\n        Returns:\n            The corresponding class index if found, otherwise None.\n        \"\"\"\n        return self.settings.species_config.get_index_by_species(species_name)\n\n    def get_species_names(self) -&gt; list[str]:\n        \"\"\"Gets a sorted list of all species names known to the classifier.\n\n        The list is ordered by the class index.\n\n        Returns:\n            A list of species names.\n        \"\"\"\n        return [self.species_map[i] for i in sorted(self.species_map.keys())]\n\n    def visualize(\n        self,\n        input_data: ImageInput,\n        predictions: ClassificationPrediction,\n        save_path: str | Path | None = None,\n    ) -&gt; np.ndarray:\n        \"\"\"Creates a composite image with results and the input image.\n\n        This method generates a visualization by placing the top-k predictions\n        in a separate panel to the left of the image.\n\n        Example:\n            &gt;&gt;&gt; from culicidaelab.settings import Settings\n            &gt;&gt;&gt; from culicidaelab.predictors import MosquitoClassifier\n            &gt;&gt;&gt; # This example assumes you have a configured settings object\n            &gt;&gt;&gt; settings = Settings()\n            &gt;&gt;&gt; classifier = MosquitoClassifier(settings, load_model=True)\n            &gt;&gt;&gt; image = \"path/to/your/image.jpg\"\n            &gt;&gt;&gt; prediction = classifier.predict(image)\n            &gt;&gt;&gt; viz_image = classifier.visualize(image, prediction, save_path=\"viz.jpg\")\n\n        Args:\n            input_data: The input image (NumPy array, path, or PIL Image).\n            predictions: The prediction output from the `predict` method.\n            save_path: If provided, the image is saved to this path.\n\n        Returns:\n            A new image array containing the text panel and original image.\n\n        Raises:\n            ValueError: If the input data is invalid or predictions are empty.\n            FileNotFoundError: If the image file path doesn't exist.\n        \"\"\"\n        image_pil = self._load_and_validate_image(input_data)\n        image_np_rgb = np.array(image_pil)\n\n        if not predictions.predictions:\n            raise ValueError(\"Predictions list cannot be empty\")\n\n        vis_config = self.config.visualization\n        font_scale = vis_config.font_scale\n        top_k = self.config.params.get(\"top_k\", 5)\n\n        img_h, img_w, _ = image_np_rgb.shape\n        text_panel_width = 250\n        padding = 20\n        canvas_h = img_h\n        canvas_w = text_panel_width + img_w\n        canvas = Image.new(\"RGB\", (canvas_w, canvas_h), color=\"white\")\n        draw = ImageDraw.Draw(canvas)\n\n        y_offset = 40\n        line_height = int(font_scale * 20)\n        for classification in predictions.predictions[:top_k]:\n            species, conf = classification.species_name, classification.confidence\n            display_name = self.labels_map.get(species, species)\n            text = f\"{display_name}: {conf:.3f}\"\n            # Load a font (you might want to make this configurable or load once)\n            try:\n                font_pil = ImageFont.truetype(\"arial.ttf\", int(font_scale * 15))\n            except OSError:\n                font_pil = ImageFont.load_default()\n            draw.text((padding, y_offset), text, fill=vis_config.text_color, font=font_pil)\n            y_offset += line_height\n\n        canvas.paste(image_pil, (text_panel_width, 0))\n\n        if save_path:\n            save_path = Path(save_path)\n            save_path.parent.mkdir(parents=True, exist_ok=True)\n            canvas.save(str(save_path))\n\n        return np.array(canvas)\n\n    def visualize_report(\n        self,\n        report_data: dict[str, Any],\n        save_path: str | Path | None = None,\n    ) -&gt; None:\n        \"\"\"Generates a visualization of the evaluation report.\n\n        This function creates a figure with a text summary of key performance\n        metrics and a heatmap of the confusion matrix.\n\n        Args:\n            report_data: The evaluation report from the `evaluate` method.\n            save_path: If provided, the figure is saved to this path.\n\n        Raises:\n            ValueError: If `report_data` is missing required keys.\n        \"\"\"\n        required_keys = [\n            \"accuracy_mean\",\n            \"confidence_mean\",\n            \"top_5_correct_mean\",\n            \"count\",\n            \"confusion_matrix\",\n        ]\n        if not all(key in report_data for key in required_keys):\n            raise ValueError(\"report_data is missing one or more required keys.\")\n\n        conf_matrix = np.array(report_data[\"confusion_matrix\"])\n        class_labels = self.get_species_names()\n\n        fig, (ax_text, ax_matrix) = plt.subplots(\n            1,\n            2,\n            figsize=(15, 10),\n            gridspec_kw={\"width_ratios\": [1, 2.5]},\n        )\n        fig.suptitle(\"Model Evaluation Report\", fontsize=20, y=1.02)\n\n        ax_text.axis(\"off\")\n        text_content = (\n            f\"Summary (on {report_data['count']} samples):\\n\\n\"\n            f\"Mean Accuracy (Top-1): {report_data['accuracy_mean']:.3f}\\n\"\n            f\"Mean Top-5 Accuracy:   {report_data['top_5_correct_mean']:.3f}\\n\\n\"\n            f\"Mean Confidence:         {report_data['confidence_mean']:.3f}\\n\"\n        )\n        if \"roc_auc\" in report_data:\n            text_content += f\"ROC-AUC Score:           {report_data['roc_auc']:.3f}\\n\"\n        ax_text.text(\n            0.0,\n            0.7,\n            text_content,\n            ha=\"left\",\n            va=\"top\",\n            transform=ax_text.transAxes,\n            fontsize=16,\n            family=\"monospace\",\n        )\n\n        im = ax_matrix.imshow(conf_matrix, cmap=\"BuGn\", interpolation=\"nearest\")\n        tick_marks = np.arange(len(class_labels))\n        ax_matrix.set_xticks(tick_marks)\n        ax_matrix.set_yticks(tick_marks)\n        ax_matrix.set_xticklabels(\n            class_labels,\n            rotation=30,\n            ha=\"right\",\n            rotation_mode=\"anchor\",\n        )\n        ax_matrix.set_yticklabels(class_labels, rotation=0)\n        fig.colorbar(im, ax=ax_matrix, fraction=0.046, pad=0.04)\n\n        threshold = conf_matrix.max() / 2.0\n        for i in range(len(class_labels)):\n            for j in range(len(class_labels)):\n                text_color = \"white\" if conf_matrix[i, j] &gt; threshold else \"black\"\n                ax_matrix.text(\n                    j,\n                    i,\n                    f\"{conf_matrix[i, j]}\",\n                    ha=\"center\",\n                    va=\"center\",\n                    color=text_color,\n                )\n        ax_matrix.set_title(\"Confusion Matrix\", fontsize=16)\n        ax_matrix.set_xlabel(\"Predicted Label\", fontsize=12)\n        ax_matrix.set_ylabel(\"True Label\", fontsize=12)\n\n        plt.tight_layout(rect=(0, 0, 1, 0.96))\n        if save_path:\n            save_path = Path(save_path)\n            save_path.parent.mkdir(parents=True, exist_ok=True)\n            plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n            print(f\"Report visualization saved to: {save_path}\")\n        plt.show()\n\n    # --------------------------------------------------------------------------\n    # Private Methods\n    # --------------------------------------------------------------------------\n    def _convert_raw_to_prediction(self, raw_prediction: np.ndarray) -&gt; ClassificationPrediction:\n        \"\"\"Converts raw model output to a structured classification prediction.\"\"\"\n        species_probs = []\n\n        for idx, prob in enumerate(raw_prediction):\n            species_name = self.species_map.get(idx, f\"unknown_{idx}\")\n            species_probs.append(Classification(species_name=species_name, confidence=float(prob)))\n\n        species_probs.sort(key=lambda x: x.confidence, reverse=True)\n        return ClassificationPrediction(predictions=species_probs)\n\n    def _evaluate_from_prediction(\n        self,\n        prediction: ClassificationPrediction,\n        ground_truth: ClassificationGroundTruthType,\n    ) -&gt; dict[str, float]:\n        \"\"\"Calculates core evaluation metrics for a single prediction.\"\"\"\n        if not prediction.predictions:\n            return {\n                \"accuracy\": 0.0,\n                \"confidence\": 0.0,\n                \"top_1_correct\": 0.0,\n                \"top_5_correct\": 0.0,\n            }\n        ground_truth_species = self.labels_map.get(ground_truth, ground_truth)\n        top_pred = prediction.top_prediction()\n        pred_species = top_pred.species_name if top_pred else \"\"\n        confidence = top_pred.confidence if top_pred else 0.0\n        top_1_correct = float(pred_species == ground_truth_species)\n        top_5_species = [p.species_name for p in prediction.predictions[:5]]\n        top_5_correct = float(ground_truth_species in top_5_species)\n        return {\n            \"accuracy\": top_1_correct,\n            \"confidence\": confidence,\n            \"top_1_correct\": top_1_correct,\n            \"top_5_correct\": top_5_correct,\n        }\n\n    def _finalize_evaluation_report(\n        self,\n        aggregated_metrics: dict[str, float],\n        predictions: Sequence[ClassificationPrediction],\n        ground_truths: Sequence[ClassificationGroundTruthType],\n    ) -&gt; dict[str, Any]:\n        \"\"\"Calculates and adds confusion matrix and ROC-AUC to the final report.\"\"\"\n        species_to_idx = {v: k for k, v in self.species_map.items()}\n        class_labels = list(range(self.num_classes))\n        y_true_indices, y_pred_indices, y_scores = [], [], []\n\n        for gt, pred_list in zip(ground_truths, predictions):\n            gt_str = self.labels_map.get(gt, gt)\n            if gt_str in species_to_idx and pred_list.predictions:\n                true_idx = species_to_idx[gt_str]\n                top_pred = pred_list.top_prediction()\n                pred_str = top_pred.species_name if top_pred else \"\"\n                pred_idx = species_to_idx.get(pred_str, -1)\n                y_true_indices.append(true_idx)\n                y_pred_indices.append(pred_idx)\n                prob_vector = [0.0] * self.num_classes\n                for classification in pred_list.predictions:\n                    class_idx = species_to_idx.get(classification.species_name)\n                    if class_idx is not None:\n                        prob_vector[class_idx] = classification.confidence\n                y_scores.append(prob_vector)\n\n        if y_true_indices and y_pred_indices:\n            valid_indices = [i for i, p_idx in enumerate(y_pred_indices) if p_idx != -1]\n            if valid_indices:\n                cm_y_true = [y_true_indices[i] for i in valid_indices]\n                cm_y_pred = [y_pred_indices[i] for i in valid_indices]\n                conf_matrix = confusion_matrix(\n                    cm_y_true,\n                    cm_y_pred,\n                    labels=class_labels,\n                )\n                aggregated_metrics[\"confusion_matrix\"] = conf_matrix.tolist()\n\n        if y_scores and y_true_indices and len(np.unique(y_true_indices)) &gt; 1:\n            y_true_binarized = label_binarize(y_true_indices, classes=class_labels)\n            try:\n                roc_auc = roc_auc_score(\n                    y_true_binarized,\n                    np.array(y_scores),\n                    multi_class=\"ovr\",\n                )\n                aggregated_metrics[\"roc_auc\"] = roc_auc  # type: ignore\n            except ValueError as e:\n                self._logger.warning(f\"Could not compute ROC AUC score: {e}\")\n                aggregated_metrics[\"roc_auc\"] = 0.0\n        return aggregated_metrics\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.settings","title":"<code>settings = settings</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.predictor_type","title":"<code>predictor_type = predictor_type</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.backend","title":"<code>backend = backend</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.config","title":"<code>config: PredictorConfig</code>  <code>property</code>","text":"<p>Get the predictor configuration Pydantic model.</p> <p>Returns:</p> Name Type Description <code>PredictorConfig</code> <code>PredictorConfig</code> <p>The configuration object for this predictor.</p>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.model_loaded","title":"<code>model_loaded: bool</code>  <code>property</code>","text":"<p>Check if the model is loaded.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the model is loaded, False otherwise.</p>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.arch","title":"<code>arch: str | None = self.config.model_arch</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.data_dir","title":"<code>data_dir: Path = self.settings.dataset_dir</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.species_map","title":"<code>species_map: dict[int, str] = self.settings.species_config.species_map</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.labels_map","title":"<code>labels_map: dict[str, str] = self.settings.species_config.class_to_full_name_map</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.num_classes","title":"<code>num_classes: int = len(self.species_map)</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.__call__","title":"<code>__call__(input_data: InputDataType, **kwargs: Any) -&gt; Any</code>","text":"<p>Convenience method that calls <code>predict()</code>.</p> <p>This allows the predictor instance to be called as a function.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>InputDataType</code> <p>The input data for the prediction.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments to pass to the <code>predict</code> method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The result of the prediction.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def __call__(self, input_data: InputDataType, **kwargs: Any) -&gt; Any:\n    \"\"\"Convenience method that calls `predict()`.\n\n    This allows the predictor instance to be called as a function.\n\n    Args:\n        input_data (InputDataType): The input data for the prediction.\n        **kwargs (Any): Additional arguments to pass to the `predict` method.\n\n    Returns:\n        Any: The result of the prediction.\n    \"\"\"\n    if not self.backend.is_loaded:\n        self.load_model()\n    return self.predict(input_data, **kwargs)\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.__enter__","title":"<code>__enter__()</code>","text":"<p>Context manager entry.</p> <p>Loads the model if it is not already loaded.</p> <p>Returns:</p> Name Type Description <code>BasePredictor</code> <p>The predictor instance.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def __enter__(self):\n    \"\"\"Context manager entry.\n\n    Loads the model if it is not already loaded.\n\n    Returns:\n        BasePredictor: The predictor instance.\n    \"\"\"\n    if not self.backend.is_loaded:\n        self.load_model()\n    return self\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Context manager exit.</p> <p>This default implementation does nothing, but can be overridden to handle resource cleanup.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Context manager exit.\n\n    This default implementation does nothing, but can be overridden to handle\n    resource cleanup.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.model_context","title":"<code>model_context()</code>","text":"<p>A context manager for temporary model loading.</p> <p>Ensures the model is loaded upon entering the context and unloaded upon exiting if it was not loaded before. This is useful for managing memory in pipelines.</p> <p>Yields:</p> Name Type Description <code>BasePredictor</code> <p>The predictor instance itself.</p> Example <p>with predictor.model_context(): ...     predictions = predictor.predict(data)</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>@contextmanager\ndef model_context(self):\n    \"\"\"A context manager for temporary model loading.\n\n    Ensures the model is loaded upon entering the context and unloaded\n    upon exiting if it was not loaded before. This is useful for managing\n    memory in pipelines.\n\n    Yields:\n        BasePredictor: The predictor instance itself.\n\n    Example:\n        &gt;&gt;&gt; with predictor.model_context():\n        ...     predictions = predictor.predict(data)\n    \"\"\"\n    was_loaded = self.backend.is_loaded\n    try:\n        if not was_loaded:\n            self.load_model()\n        yield self\n    finally:\n        if not was_loaded and self.backend.is_loaded:\n            self.unload_model()\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.evaluate","title":"<code>evaluate(ground_truth: GroundTruthType, prediction: PredictionType | None = None, input_data: InputDataType | None = None, **predict_kwargs: Any) -&gt; dict[str, float]</code>","text":"<p>Evaluate a prediction against a ground truth.</p> <p>Either <code>prediction</code> or <code>input_data</code> must be provided. If <code>prediction</code> is provided, it is used directly. If <code>prediction</code> is None, <code>input_data</code> is used to generate a new prediction.</p> <p>Parameters:</p> Name Type Description Default <code>ground_truth</code> <code>GroundTruthType</code> <p>The ground truth annotation.</p> required <code>prediction</code> <code>PredictionType</code> <p>A pre-computed prediction.</p> <code>None</code> <code>input_data</code> <code>InputDataType</code> <p>Input data to generate a prediction from, if one isn't provided.</p> <code>None</code> <code>**predict_kwargs</code> <code>Any</code> <p>Additional arguments passed to the <code>predict</code> method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>dict[str, float]: Dictionary containing evaluation metrics for a</p> <code>dict[str, float]</code> <p>single item.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither <code>prediction</code> nor <code>input_data</code> is provided.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def evaluate(\n    self,\n    ground_truth: GroundTruthType,\n    prediction: PredictionType | None = None,\n    input_data: InputDataType | None = None,\n    **predict_kwargs: Any,\n) -&gt; dict[str, float]:\n    \"\"\"Evaluate a prediction against a ground truth.\n\n    Either `prediction` or `input_data` must be provided. If `prediction`\n    is provided, it is used directly. If `prediction` is None, `input_data`\n    is used to generate a new prediction.\n\n    Args:\n        ground_truth (GroundTruthType): The ground truth annotation.\n        prediction (PredictionType, optional): A pre-computed prediction.\n        input_data (InputDataType, optional): Input data to generate a\n            prediction from, if one isn't provided.\n        **predict_kwargs (Any): Additional arguments passed to the `predict`\n            method.\n\n    Returns:\n        dict[str, float]: Dictionary containing evaluation metrics for a\n        single item.\n\n    Raises:\n        ValueError: If neither `prediction` nor `input_data` is provided.\n    \"\"\"\n    if prediction is None:\n        if input_data is not None:\n            prediction = self.predict(input_data, **predict_kwargs)\n        else:\n            raise ValueError(\n                \"Either 'prediction' or 'input_data' must be provided.\",\n            )\n    return self._evaluate_from_prediction(\n        prediction=prediction,\n        ground_truth=ground_truth,\n    )\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.evaluate_batch","title":"<code>evaluate_batch(ground_truth_batch: Sequence[GroundTruthType], predictions_batch: Sequence[PredictionType] | None = None, input_data_batch: Sequence[InputDataType] | None = None, num_workers: int = 1, show_progress: bool = False, **predict_kwargs: Any) -&gt; dict[str, Any]</code>","text":"<p>Evaluate on a batch of items using parallel processing.</p> <p>Either <code>predictions_batch</code> or <code>input_data_batch</code> must be provided.</p> <p>Parameters:</p> Name Type Description Default <code>ground_truth_batch</code> <code>Sequence[GroundTruthType]</code> <p>List of corresponding ground truth annotations.</p> required <code>predictions_batch</code> <code>Sequence[PredictionType]</code> <p>A pre-computed list of predictions.</p> <code>None</code> <code>input_data_batch</code> <code>Sequence[InputDataType]</code> <p>List of input data to generate predictions from.</p> <code>None</code> <code>num_workers</code> <code>int</code> <p>Number of parallel workers for calculating metrics.</p> <code>1</code> <code>show_progress</code> <code>bool</code> <p>Whether to show a progress bar.</p> <code>False</code> <code>**predict_kwargs</code> <code>Any</code> <p>Additional arguments passed to <code>predict_batch</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Dictionary containing aggregated evaluation metrics.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the number of predictions does not match the number of ground truths, or if required inputs are missing.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def evaluate_batch(\n    self,\n    ground_truth_batch: Sequence[GroundTruthType],\n    predictions_batch: Sequence[PredictionType] | None = None,\n    input_data_batch: Sequence[InputDataType] | None = None,\n    num_workers: int = 1,\n    show_progress: bool = False,\n    **predict_kwargs: Any,\n) -&gt; dict[str, Any]:\n    \"\"\"Evaluate on a batch of items using parallel processing.\n\n    Either `predictions_batch` or `input_data_batch` must be provided.\n\n    Args:\n        ground_truth_batch (Sequence[GroundTruthType]): List of corresponding\n            ground truth annotations.\n        predictions_batch (Sequence[PredictionType], optional): A pre-computed\n            list of predictions.\n        input_data_batch (Sequence[InputDataType], optional): List of input data\n            to generate predictions from.\n        num_workers (int): Number of parallel workers for calculating metrics.\n        show_progress (bool): Whether to show a progress bar.\n        **predict_kwargs (Any): Additional arguments passed to `predict_batch`.\n\n    Returns:\n        dict[str, Any]: Dictionary containing aggregated evaluation metrics.\n\n    Raises:\n        ValueError: If the number of predictions does not match the number\n            of ground truths, or if required inputs are missing.\n    \"\"\"\n    if predictions_batch is None:\n        if input_data_batch is not None:\n            predictions_batch = self.predict_batch(\n                input_data_batch,\n                show_progress=show_progress,\n                **predict_kwargs,\n            )\n        else:\n            raise ValueError(\n                \"Either 'predictions_batch' or 'input_data_batch' must be provided.\",\n            )\n\n    if len(predictions_batch) != len(ground_truth_batch):\n        raise ValueError(\n            f\"Number of predictions ({len(predictions_batch)}) must match \"\n            f\"number of ground truths ({len(ground_truth_batch)}).\",\n        )\n\n    per_item_metrics = self._calculate_metrics_parallel(\n        predictions_batch,\n        ground_truth_batch,\n        num_workers,\n        show_progress,\n    )\n    aggregated_metrics = self._aggregate_metrics(per_item_metrics)\n    final_report = self._finalize_evaluation_report(\n        aggregated_metrics,\n        predictions_batch,\n        ground_truth_batch,\n    )\n    return final_report\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.get_model_info","title":"<code>get_model_info() -&gt; dict[str, Any]</code>","text":"<p>Gets information about the loaded model.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing details about the model, such</p> <code>dict[str, Any]</code> <p>as architecture, path, etc.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def get_model_info(self) -&gt; dict[str, Any]:\n    \"\"\"Gets information about the loaded model.\n\n    Returns:\n        dict[str, Any]: A dictionary containing details about the model, such\n        as architecture, path, etc.\n    \"\"\"\n    return {\n        \"predictor_type\": self.predictor_type,\n        \"model_loaded\": self.backend.is_loaded,\n        \"config\": self.config.model_dump(),\n    }\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.load_model","title":"<code>load_model() -&gt; None</code>","text":"<p>Delegates model loading to the configured backend.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def load_model(self) -&gt; None:\n    \"\"\"Delegates model loading to the configured backend.\"\"\"\n    if not self.backend.is_loaded:\n        self._logger.info(\n            f\"Loading model for {self.predictor_type} using {self.backend.__class__.__name__}\",\n        )\n        try:\n            self.backend.load_model()\n            self._logger.info(f\"Successfully loaded model for {self.predictor_type}\")\n        except Exception as e:\n            self._logger.error(f\"Failed to load model for {self.predictor_type}: {e}\")\n            raise RuntimeError(f\"Failed to load model for {self.predictor_type}: {e}\") from e\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.predict","title":"<code>predict(input_data: InputDataType, **kwargs: Any) -&gt; PredictionType</code>","text":"<p>Makes a prediction on a single input data sample.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>InputDataType</code> <p>The input data (e.g., an image as a NumPy array) to make a prediction on.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional predictor-specific arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>PredictionType</code> <code>PredictionType</code> <p>The prediction result, with a format specific to the</p> <code>PredictionType</code> <p>predictor type.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the model is not loaded before calling this method.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def predict(\n    self,\n    input_data: InputDataType,\n    **kwargs: Any,\n) -&gt; PredictionType:\n    \"\"\"Makes a prediction on a single input data sample.\n\n    Args:\n        input_data (InputDataType): The input data (e.g., an image as a NumPy\n            array) to make a prediction on.\n        **kwargs (Any): Additional predictor-specific arguments.\n\n    Returns:\n        PredictionType: The prediction result, with a format specific to the\n        predictor type.\n\n    Raises:\n        RuntimeError: If the model is not loaded before calling this method.\n    \"\"\"\n    if not self.backend.is_loaded:\n        try:\n            self.load_model()\n        except Exception as e:\n            raise RuntimeError(f\"Failed to load model: {e}\") from e\n\n    image = self._load_and_validate_image(input_data)\n\n    raw_output = self.backend.predict(image, **kwargs)\n\n    return self._convert_raw_to_prediction(raw_output)\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.predict_batch","title":"<code>predict_batch(input_data_batch: Sequence[InputDataType], show_progress: bool = False, **kwargs: Any) -&gt; list[PredictionType]</code>","text":"<p>Makes predictions on a batch of inputs by delegating to the backend.</p> <p>Parameters:</p> Name Type Description Default <code>input_data_batch</code> <code>Sequence[InputDataType]</code> <p>A sequence of inputs.</p> required <code>show_progress</code> <code>bool</code> <p>If True, displays a progress bar.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments for the backend's <code>predict_batch</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[PredictionType]</code> <p>list[PredictionType]: A list of prediction results.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def predict_batch(\n    self,\n    input_data_batch: Sequence[InputDataType],\n    show_progress: bool = False,\n    **kwargs: Any,\n) -&gt; list[PredictionType]:\n    \"\"\"Makes predictions on a batch of inputs by delegating to the backend.\n\n    Args:\n        input_data_batch (Sequence[InputDataType]): A sequence of inputs.\n        show_progress (bool): If True, displays a progress bar.\n        **kwargs (Any): Additional arguments for the backend's `predict_batch`.\n\n    Returns:\n        list[PredictionType]: A list of prediction results.\n    \"\"\"\n    if not input_data_batch:\n        return []\n\n    if not self.backend.is_loaded:\n        self.load_model()\n\n    raw_predictions = self.backend.predict_batch(list(input_data_batch), **kwargs)\n    final_predictions = [self._convert_raw_to_prediction(raw_pred) for raw_pred in raw_predictions]\n    return final_predictions\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.unload_model","title":"<code>unload_model() -&gt; None</code>","text":"<p>Unloads the model to free memory.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def unload_model(self) -&gt; None:\n    \"\"\"Unloads the model to free memory.\"\"\"\n    if self.backend.is_loaded:\n        self.backend.unload_model()\n        self._logger.info(f\"Unloaded model for {self.predictor_type}\")\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.__init__","title":"<code>__init__(settings: Settings, predictor_type='classifier', mode: Literal['torch', 'serve'] | None = None, load_model: bool = False, backend: BaseInferenceBackend | None = None) -&gt; None</code>","text":"<p>Initializes the MosquitoClassifier.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>Settings</code> <p>The main settings object for the library.</p> required <code>predictor_type</code> <p>The type of predictor. Defaults to \"classifier\".</p> <code>'classifier'</code> <code>mode</code> <code>Literal['torch', 'serve'] | None</code> <p>The mode to run the predictor in, 'torch' or 'serve'. If None, it's determined by the environment.</p> <code>None</code> <code>load_model</code> <code>bool</code> <p>If True, load the model upon initialization.</p> <code>False</code> <code>backend</code> <code>BaseInferenceBackend | None</code> <p>An optional backend instance. If not provided, one will be created based on the mode and settings.</p> <code>None</code> Source code in <code>culicidaelab\\predictors\\classifier.py</code> <pre><code>def __init__(\n    self,\n    settings: Settings,\n    predictor_type=\"classifier\",\n    mode: Literal[\"torch\", \"serve\"] | None = None,\n    load_model: bool = False,\n    backend: BaseInferenceBackend | None = None,\n) -&gt; None:\n    \"\"\"Initializes the MosquitoClassifier.\n\n    Args:\n        settings: The main settings object for the library.\n        predictor_type: The type of predictor. Defaults to \"classifier\".\n        mode: The mode to run the predictor in, 'torch' or 'serve'.\n            If None, it's determined by the environment.\n        load_model: If True, load the model upon initialization.\n        backend: An optional backend instance. If not provided, one will be\n            created based on the mode and settings.\n    \"\"\"\n\n    backend_instance = backend or create_backend(\n        predictor_type=predictor_type,\n        settings=settings,\n        mode=mode,\n    )\n\n    super().__init__(\n        settings=settings,\n        predictor_type=predictor_type,\n        backend=backend_instance,\n        load_model=load_model,\n    )\n    self.arch: str | None = self.config.model_arch\n\n    self.data_dir: Path = self.settings.dataset_dir\n    self.species_map: dict[int, str] = self.settings.species_config.species_map\n    self.labels_map: dict[\n        str,\n        str,\n    ] = self.settings.species_config.class_to_full_name_map\n    self.num_classes: int = len(self.species_map)\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.get_class_index","title":"<code>get_class_index(species_name: str) -&gt; int | None</code>","text":"<p>Retrieves the class index for a given species name.</p> <p>Parameters:</p> Name Type Description Default <code>species_name</code> <code>str</code> <p>The name of the species.</p> required <p>Returns:</p> Type Description <code>int | None</code> <p>The corresponding class index if found, otherwise None.</p> Source code in <code>culicidaelab\\predictors\\classifier.py</code> <pre><code>def get_class_index(self, species_name: str) -&gt; int | None:\n    \"\"\"Retrieves the class index for a given species name.\n\n    Args:\n        species_name: The name of the species.\n\n    Returns:\n        The corresponding class index if found, otherwise None.\n    \"\"\"\n    return self.settings.species_config.get_index_by_species(species_name)\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.get_species_names","title":"<code>get_species_names() -&gt; list[str]</code>","text":"<p>Gets a sorted list of all species names known to the classifier.</p> <p>The list is ordered by the class index.</p> <p>Returns:</p> Type Description <code>list[str]</code> <p>A list of species names.</p> Source code in <code>culicidaelab\\predictors\\classifier.py</code> <pre><code>def get_species_names(self) -&gt; list[str]:\n    \"\"\"Gets a sorted list of all species names known to the classifier.\n\n    The list is ordered by the class index.\n\n    Returns:\n        A list of species names.\n    \"\"\"\n    return [self.species_map[i] for i in sorted(self.species_map.keys())]\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.visualize","title":"<code>visualize(input_data: ImageInput, predictions: ClassificationPrediction, save_path: str | Path | None = None) -&gt; np.ndarray</code>","text":"<p>Creates a composite image with results and the input image.</p> <p>This method generates a visualization by placing the top-k predictions in a separate panel to the left of the image.</p> Example <p>from culicidaelab.settings import Settings from culicidaelab.predictors import MosquitoClassifier</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>ImageInput</code> <p>The input image (NumPy array, path, or PIL Image).</p> required <code>predictions</code> <code>ClassificationPrediction</code> <p>The prediction output from the <code>predict</code> method.</p> required <code>save_path</code> <code>str | Path | None</code> <p>If provided, the image is saved to this path.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A new image array containing the text panel and original image.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the input data is invalid or predictions are empty.</p> <code>FileNotFoundError</code> <p>If the image file path doesn't exist.</p> Source code in <code>culicidaelab\\predictors\\classifier.py</code> <pre><code>def visualize(\n    self,\n    input_data: ImageInput,\n    predictions: ClassificationPrediction,\n    save_path: str | Path | None = None,\n) -&gt; np.ndarray:\n    \"\"\"Creates a composite image with results and the input image.\n\n    This method generates a visualization by placing the top-k predictions\n    in a separate panel to the left of the image.\n\n    Example:\n        &gt;&gt;&gt; from culicidaelab.settings import Settings\n        &gt;&gt;&gt; from culicidaelab.predictors import MosquitoClassifier\n        &gt;&gt;&gt; # This example assumes you have a configured settings object\n        &gt;&gt;&gt; settings = Settings()\n        &gt;&gt;&gt; classifier = MosquitoClassifier(settings, load_model=True)\n        &gt;&gt;&gt; image = \"path/to/your/image.jpg\"\n        &gt;&gt;&gt; prediction = classifier.predict(image)\n        &gt;&gt;&gt; viz_image = classifier.visualize(image, prediction, save_path=\"viz.jpg\")\n\n    Args:\n        input_data: The input image (NumPy array, path, or PIL Image).\n        predictions: The prediction output from the `predict` method.\n        save_path: If provided, the image is saved to this path.\n\n    Returns:\n        A new image array containing the text panel and original image.\n\n    Raises:\n        ValueError: If the input data is invalid or predictions are empty.\n        FileNotFoundError: If the image file path doesn't exist.\n    \"\"\"\n    image_pil = self._load_and_validate_image(input_data)\n    image_np_rgb = np.array(image_pil)\n\n    if not predictions.predictions:\n        raise ValueError(\"Predictions list cannot be empty\")\n\n    vis_config = self.config.visualization\n    font_scale = vis_config.font_scale\n    top_k = self.config.params.get(\"top_k\", 5)\n\n    img_h, img_w, _ = image_np_rgb.shape\n    text_panel_width = 250\n    padding = 20\n    canvas_h = img_h\n    canvas_w = text_panel_width + img_w\n    canvas = Image.new(\"RGB\", (canvas_w, canvas_h), color=\"white\")\n    draw = ImageDraw.Draw(canvas)\n\n    y_offset = 40\n    line_height = int(font_scale * 20)\n    for classification in predictions.predictions[:top_k]:\n        species, conf = classification.species_name, classification.confidence\n        display_name = self.labels_map.get(species, species)\n        text = f\"{display_name}: {conf:.3f}\"\n        # Load a font (you might want to make this configurable or load once)\n        try:\n            font_pil = ImageFont.truetype(\"arial.ttf\", int(font_scale * 15))\n        except OSError:\n            font_pil = ImageFont.load_default()\n        draw.text((padding, y_offset), text, fill=vis_config.text_color, font=font_pil)\n        y_offset += line_height\n\n    canvas.paste(image_pil, (text_panel_width, 0))\n\n    if save_path:\n        save_path = Path(save_path)\n        save_path.parent.mkdir(parents=True, exist_ok=True)\n        canvas.save(str(save_path))\n\n    return np.array(canvas)\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.visualize--this-example-assumes-you-have-a-configured-settings-object","title":"This example assumes you have a configured settings object","text":"<p>settings = Settings() classifier = MosquitoClassifier(settings, load_model=True) image = \"path/to/your/image.jpg\" prediction = classifier.predict(image) viz_image = classifier.visualize(image, prediction, save_path=\"viz.jpg\")</p>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoClassifier.visualize_report","title":"<code>visualize_report(report_data: dict[str, Any], save_path: str | Path | None = None) -&gt; None</code>","text":"<p>Generates a visualization of the evaluation report.</p> <p>This function creates a figure with a text summary of key performance metrics and a heatmap of the confusion matrix.</p> <p>Parameters:</p> Name Type Description Default <code>report_data</code> <code>dict[str, Any]</code> <p>The evaluation report from the <code>evaluate</code> method.</p> required <code>save_path</code> <code>str | Path | None</code> <p>If provided, the figure is saved to this path.</p> <code>None</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>report_data</code> is missing required keys.</p> Source code in <code>culicidaelab\\predictors\\classifier.py</code> <pre><code>def visualize_report(\n    self,\n    report_data: dict[str, Any],\n    save_path: str | Path | None = None,\n) -&gt; None:\n    \"\"\"Generates a visualization of the evaluation report.\n\n    This function creates a figure with a text summary of key performance\n    metrics and a heatmap of the confusion matrix.\n\n    Args:\n        report_data: The evaluation report from the `evaluate` method.\n        save_path: If provided, the figure is saved to this path.\n\n    Raises:\n        ValueError: If `report_data` is missing required keys.\n    \"\"\"\n    required_keys = [\n        \"accuracy_mean\",\n        \"confidence_mean\",\n        \"top_5_correct_mean\",\n        \"count\",\n        \"confusion_matrix\",\n    ]\n    if not all(key in report_data for key in required_keys):\n        raise ValueError(\"report_data is missing one or more required keys.\")\n\n    conf_matrix = np.array(report_data[\"confusion_matrix\"])\n    class_labels = self.get_species_names()\n\n    fig, (ax_text, ax_matrix) = plt.subplots(\n        1,\n        2,\n        figsize=(15, 10),\n        gridspec_kw={\"width_ratios\": [1, 2.5]},\n    )\n    fig.suptitle(\"Model Evaluation Report\", fontsize=20, y=1.02)\n\n    ax_text.axis(\"off\")\n    text_content = (\n        f\"Summary (on {report_data['count']} samples):\\n\\n\"\n        f\"Mean Accuracy (Top-1): {report_data['accuracy_mean']:.3f}\\n\"\n        f\"Mean Top-5 Accuracy:   {report_data['top_5_correct_mean']:.3f}\\n\\n\"\n        f\"Mean Confidence:         {report_data['confidence_mean']:.3f}\\n\"\n    )\n    if \"roc_auc\" in report_data:\n        text_content += f\"ROC-AUC Score:           {report_data['roc_auc']:.3f}\\n\"\n    ax_text.text(\n        0.0,\n        0.7,\n        text_content,\n        ha=\"left\",\n        va=\"top\",\n        transform=ax_text.transAxes,\n        fontsize=16,\n        family=\"monospace\",\n    )\n\n    im = ax_matrix.imshow(conf_matrix, cmap=\"BuGn\", interpolation=\"nearest\")\n    tick_marks = np.arange(len(class_labels))\n    ax_matrix.set_xticks(tick_marks)\n    ax_matrix.set_yticks(tick_marks)\n    ax_matrix.set_xticklabels(\n        class_labels,\n        rotation=30,\n        ha=\"right\",\n        rotation_mode=\"anchor\",\n    )\n    ax_matrix.set_yticklabels(class_labels, rotation=0)\n    fig.colorbar(im, ax=ax_matrix, fraction=0.046, pad=0.04)\n\n    threshold = conf_matrix.max() / 2.0\n    for i in range(len(class_labels)):\n        for j in range(len(class_labels)):\n            text_color = \"white\" if conf_matrix[i, j] &gt; threshold else \"black\"\n            ax_matrix.text(\n                j,\n                i,\n                f\"{conf_matrix[i, j]}\",\n                ha=\"center\",\n                va=\"center\",\n                color=text_color,\n            )\n    ax_matrix.set_title(\"Confusion Matrix\", fontsize=16)\n    ax_matrix.set_xlabel(\"Predicted Label\", fontsize=12)\n    ax_matrix.set_ylabel(\"True Label\", fontsize=12)\n\n    plt.tight_layout(rect=(0, 0, 1, 0.96))\n    if save_path:\n        save_path = Path(save_path)\n        save_path.parent.mkdir(parents=True, exist_ok=True)\n        plt.savefig(save_path, dpi=300, bbox_inches=\"tight\")\n        print(f\"Report visualization saved to: {save_path}\")\n    plt.show()\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector","title":"<code>MosquitoDetector</code>","text":"<p>Detects mosquitos in images using a YOLO model.</p> <p>This class loads a model and provides methods for predicting bounding boxes on single or batches of images, visualizing results, and evaluating detection performance against ground truth data.</p> <p>Attributes:</p> Name Type Description <code>confidence_threshold</code> <code>float</code> <p>The minimum confidence score for a detection to be considered valid.</p> <code>iou_threshold</code> <code>float</code> <p>The IoU threshold for non-maximum suppression.</p> <code>max_detections</code> <code>int</code> <p>The maximum number of detections to return per image.</p> Source code in <code>culicidaelab\\predictors\\detector.py</code> <pre><code>class MosquitoDetector(\n    BasePredictor[ImageInput, DetectionPrediction, DetectionGroundTruthType],\n):\n    \"\"\"Detects mosquitos in images using a YOLO model.\n\n    This class loads a model and provides methods for predicting bounding\n    boxes on single or batches of images, visualizing results, and evaluating\n    detection performance against ground truth data.\n\n    Attributes:\n        confidence_threshold (float): The minimum confidence score for a\n            detection to be considered valid.\n        iou_threshold (float): The IoU threshold for non-maximum suppression.\n        max_detections (int): The maximum number of detections to return per image.\n    \"\"\"\n\n    def __init__(\n        self,\n        settings: Settings,\n        predictor_type=\"detector\",\n        mode: Literal[\"torch\", \"serve\"] | None = None,\n        load_model: bool = False,\n        backend: BaseInferenceBackend | None = None,\n    ) -&gt; None:\n        \"\"\"Initializes the MosquitoDetector.\n\n        Args:\n            settings: The main settings object for the library.\n            predictor_type: The type of predictor. Defaults to \"detector\".\n            mode: The mode to run the predictor in, 'torch' or 'serve'.\n                If None, it's determined by the environment.\n            load_model: If True, load the model upon initialization.\n            backend: An optional backend instance. If not provided, one will be\n                created based on the mode and settings.\n        \"\"\"\n\n        backend_instance = backend or create_backend(\n            predictor_type=predictor_type,\n            settings=settings,\n            mode=mode,\n        )\n\n        super().__init__(\n            settings=settings,\n            predictor_type=predictor_type,\n            backend=backend_instance,\n            load_model=load_model,\n        )\n        self.confidence_threshold: float = self.config.confidence or 0.5\n        self.iou_threshold: float = self.config.params.get(\"iou_threshold\", 0.45)\n        self.max_detections: int = self.config.params.get(\"max_detections\", 300)\n\n    def predict(self, input_data: ImageInput, **kwargs: Any) -&gt; DetectionPrediction:\n        \"\"\"Detects mosquitos in a single image.\n\n        Example:\n            &gt;&gt;&gt; from culicidaelab.settings import Settings\n            &gt;&gt;&gt; from culicidaelab.predictors import MosquitoDetector\n            &gt;&gt;&gt; # This example assumes you have a configured settings object\n            &gt;&gt;&gt; settings = Settings()\n            &gt;&gt;&gt; detector = MosquitoDetector(settings, load_model=True)\n            &gt;&gt;&gt; image = \"path/to/your/image.jpg\"\n            &gt;&gt;&gt; detections = detector.predict(image)\n            &gt;&gt;&gt; for detection in detections.detections:\n            ...     print(detection.box, detection.confidence)\n\n        Args:\n            input_data: The input image as a NumPy array or other supported format.\n            **kwargs: Optional keyword arguments, including:\n                confidence_threshold (float): Override the default confidence\n                    threshold for this prediction.\n\n        Returns:\n            A `DetectionPrediction` object containing a list of\n            `Detection` instances. Returns an empty list if no mosquitos are found.\n\n        Raises:\n            RuntimeError: If the model fails to load or if prediction fails.\n        \"\"\"\n        if not self.backend.is_loaded:\n            self.load_model()\n\n        confidence_threshold = kwargs.get(\n            \"confidence_threshold\",\n            self.confidence_threshold,\n        )\n\n        try:\n            input_image = self._load_and_validate_image(input_data)\n            # The backend now returns a standardized NumPy array (N, 5) -&gt; [x1, y1, x2, y2, conf]\n            results_array = self.backend.predict(\n                input_data=input_image,\n                conf=confidence_threshold,\n                iou=self.iou_threshold,\n                max_det=self.max_detections,\n                verbose=False,\n            )\n        except Exception as e:\n            logger.error(f\"Prediction failed: {e}\", exc_info=True)\n            raise RuntimeError(f\"Prediction failed: {e}\") from e\n\n        return self._convert_raw_to_prediction(results_array)\n\n    def _convert_raw_to_prediction(self, raw_prediction: np.ndarray) -&gt; DetectionPrediction:\n        \"\"\"Converts raw model output to a structured detection prediction.\n\n        Args:\n            raw_prediction: A numpy array with shape (N, 5) where each row is\n                [x1, y1, x2, y2, confidence].\n\n        Returns:\n            A DetectionPrediction object containing a list of Detection objects.\n        \"\"\"\n        detections: list[Detection] = []\n        if raw_prediction.ndim == 2 and raw_prediction.shape[1] == 5:\n            for row in raw_prediction:\n                x1, y1, x2, y2, conf = row\n                detections.append(\n                    Detection(box=BoundingBox(x1=x1, y1=y1, x2=x2, y2=y2), confidence=conf),\n                )\n        return DetectionPrediction(detections=detections)\n\n    def visualize(\n        self,\n        input_data: ImageInput,\n        predictions: DetectionPrediction,\n        save_path: str | Path | None = None,\n    ) -&gt; np.ndarray:\n        \"\"\"Draws predicted bounding boxes on an image.\n\n        Example:\n            &gt;&gt;&gt; from culicidaelab.settings import Settings\n            &gt;&gt;&gt; from culicidaelab.predictors import MosquitoDetector\n            &gt;&gt;&gt; # This example assumes you have a configured settings object\n            &gt;&gt;&gt; settings = Settings()\n            &gt;&gt;&gt; detector = MosquitoDetector(settings, load_model=True)\n            &gt;&gt;&gt; image = \"path/to/your/image.jpg\"\n            &gt;&gt;&gt; detections = detector.predict(image)\n            &gt;&gt;&gt; viz_image = detector.visualize(image, detections, save_path=\"viz.jpg\")\n\n        Args:\n            input_data: The original image.\n            predictions: The `DetectionPrediction` from `predict`.\n            save_path: If provided, the output image is saved to this path.\n\n        Returns:\n            A new image array with bounding boxes and confidence scores drawn on it.\n        \"\"\"\n        vis_img = self._load_and_validate_image(input_data).copy()\n        draw = ImageDraw.Draw(vis_img)\n        vis_config = self.config.visualization\n        font_scale = vis_config.font_scale\n        thickness = vis_config.box_thickness\n\n        for detection in predictions.detections:\n            box = detection.box\n            conf = detection.confidence\n            draw.rectangle(\n                [(int(box.x1), int(box.y1)), (int(box.x2), int(box.y2))],\n                outline=vis_config.box_color,\n                width=thickness,\n            )\n            text = f\"{conf:.2f}\"\n            try:\n                font = ImageFont.truetype(\"arial.ttf\", int(font_scale * 20))\n            except OSError:\n                font = ImageFont.load_default()\n            draw.text((int(box.x1), int(box.y1 - 10)), text, fill=vis_config.text_color, font=font)\n\n        if save_path:\n            save_path = Path(save_path)\n            save_path.parent.mkdir(parents=True, exist_ok=True)\n            vis_img.save(str(save_path))\n\n        return np.array(vis_img)\n\n    def _calculate_iou(self, box1_xyxy: tuple, box2_xyxy: tuple) -&gt; float:\n        \"\"\"Calculates Intersection over Union (IoU) for two boxes.\n\n        Args:\n            box1_xyxy: The first box in (x1, y1, x2, y2) format.\n            box2_xyxy: The second box in (x1, y1, x2, y2) format.\n\n        Returns:\n            The IoU score between 0.0 and 1.0.\n        \"\"\"\n        b1_x1, b1_y1, b1_x2, b1_y2 = box1_xyxy\n        b2_x1, b2_y1, b2_x2, b2_y2 = box2_xyxy\n\n        inter_x1, inter_y1 = max(b1_x1, b2_x1), max(b1_y1, b2_y1)\n        inter_x2, inter_y2 = min(b1_x2, b2_x2), min(b1_y2, b2_y2)\n        intersection = max(0, inter_x2 - inter_x1) * max(0, inter_y2 - inter_y1)\n\n        area1 = (b1_x2 - b1_x1) * (b1_y2 - b1_y1)\n        area2 = (b2_x2 - b2_x1) * (b2_y2 - b2_y1)\n        union = area1 + area2 - intersection\n        return float(intersection / union) if union &gt; 0 else 0.0\n\n    def _evaluate_from_prediction(\n        self,\n        prediction: DetectionPrediction,\n        ground_truth: DetectionGroundTruthType,\n    ) -&gt; dict[str, float]:\n        \"\"\"Calculates detection metrics for a single image's predictions.\n\n        This computes precision, recall, F1-score, Average Precision (AP),\n        and mean IoU for a set of predicted boxes against ground truth boxes.\n\n        Args:\n            prediction: A `DetectionPrediction` object.\n            ground_truth: A list of ground truth boxes: `[(x, y, w, h), ...]`.\n\n        Returns:\n            A dictionary containing the calculated metrics.\n        \"\"\"\n        if not ground_truth and not prediction.detections:\n            return {\n                \"precision\": 1.0,\n                \"recall\": 1.0,\n                \"f1\": 1.0,\n                \"ap\": 1.0,\n                \"mean_iou\": 0.0,\n            }\n        if not ground_truth:  # False positives exist\n            return {\n                \"precision\": 0.0,\n                \"recall\": 0.0,\n                \"f1\": 0.0,\n                \"ap\": 0.0,\n                \"mean_iou\": 0.0,\n            }\n        if not prediction.detections:  # False negatives exist\n            return {\n                \"precision\": 0.0,\n                \"recall\": 0.0,\n                \"f1\": 0.0,\n                \"ap\": 0.0,\n                \"mean_iou\": 0.0,\n            }\n\n        predictions_sorted = sorted(prediction.detections, key=lambda x: x.confidence, reverse=True)\n        tp = np.zeros(len(predictions_sorted))\n        fp = np.zeros(len(predictions_sorted))\n        gt_matched = [False] * len(ground_truth)\n        all_ious_for_mean = []\n        iou_threshold = self.iou_threshold\n\n        for i, pred in enumerate(predictions_sorted):\n            pred_box = (pred.box.x1, pred.box.y1, pred.box.x2, pred.box.y2)\n            best_iou, best_gt_idx = 0.0, -1\n\n            for j, gt_box in enumerate(ground_truth):\n                if not gt_matched[j]:\n                    iou = self._calculate_iou(pred_box, gt_box)\n                    if iou &gt; best_iou:\n                        best_iou = iou\n                        best_gt_idx = j\n\n            if best_gt_idx != -1:\n                all_ious_for_mean.append(best_iou)\n\n            if best_iou &gt;= iou_threshold:\n                if not gt_matched[best_gt_idx]:\n                    tp[i] = 1\n                    gt_matched[best_gt_idx] = True\n                else:  # Matched a GT box that was already matched\n                    fp[i] = 1\n            else:\n                fp[i] = 1\n\n        mean_iou_val = float(np.mean(all_ious_for_mean)) if all_ious_for_mean else 0.0\n        fp_cumsum, tp_cumsum = np.cumsum(fp), np.cumsum(tp)\n        recall_curve = tp_cumsum / len(ground_truth)\n        precision_curve = tp_cumsum / (tp_cumsum + fp_cumsum + 1e-9)\n\n        ap = 0.0\n        for t in np.linspace(0, 1, 11):  # 11-point interpolation\n            precisions_at_recall_t = precision_curve[recall_curve &gt;= t]\n            ap += np.max(precisions_at_recall_t) if len(precisions_at_recall_t) &gt; 0 else 0.0\n        ap /= 11.0\n\n        final_precision = precision_curve[-1] if len(precision_curve) &gt; 0 else 0.0\n        final_recall = recall_curve[-1] if len(recall_curve) &gt; 0 else 0.0\n        f1 = (\n            2 * (final_precision * final_recall) / (final_precision + final_recall + 1e-9)\n            if (final_precision + final_recall) &gt; 0\n            else 0.0\n        )\n\n        return {\n            \"precision\": float(final_precision),\n            \"recall\": float(final_recall),\n            \"f1\": float(f1),\n            \"ap\": float(ap),\n            \"mean_iou\": mean_iou_val,\n        }\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.settings","title":"<code>settings = settings</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.predictor_type","title":"<code>predictor_type = predictor_type</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.backend","title":"<code>backend = backend</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.config","title":"<code>config: PredictorConfig</code>  <code>property</code>","text":"<p>Get the predictor configuration Pydantic model.</p> <p>Returns:</p> Name Type Description <code>PredictorConfig</code> <code>PredictorConfig</code> <p>The configuration object for this predictor.</p>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.model_loaded","title":"<code>model_loaded: bool</code>  <code>property</code>","text":"<p>Check if the model is loaded.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the model is loaded, False otherwise.</p>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.confidence_threshold","title":"<code>confidence_threshold: float = self.config.confidence or 0.5</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.iou_threshold","title":"<code>iou_threshold: float = self.config.params.get('iou_threshold', 0.45)</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.max_detections","title":"<code>max_detections: int = self.config.params.get('max_detections', 300)</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.__call__","title":"<code>__call__(input_data: InputDataType, **kwargs: Any) -&gt; Any</code>","text":"<p>Convenience method that calls <code>predict()</code>.</p> <p>This allows the predictor instance to be called as a function.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>InputDataType</code> <p>The input data for the prediction.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments to pass to the <code>predict</code> method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The result of the prediction.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def __call__(self, input_data: InputDataType, **kwargs: Any) -&gt; Any:\n    \"\"\"Convenience method that calls `predict()`.\n\n    This allows the predictor instance to be called as a function.\n\n    Args:\n        input_data (InputDataType): The input data for the prediction.\n        **kwargs (Any): Additional arguments to pass to the `predict` method.\n\n    Returns:\n        Any: The result of the prediction.\n    \"\"\"\n    if not self.backend.is_loaded:\n        self.load_model()\n    return self.predict(input_data, **kwargs)\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.__enter__","title":"<code>__enter__()</code>","text":"<p>Context manager entry.</p> <p>Loads the model if it is not already loaded.</p> <p>Returns:</p> Name Type Description <code>BasePredictor</code> <p>The predictor instance.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def __enter__(self):\n    \"\"\"Context manager entry.\n\n    Loads the model if it is not already loaded.\n\n    Returns:\n        BasePredictor: The predictor instance.\n    \"\"\"\n    if not self.backend.is_loaded:\n        self.load_model()\n    return self\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Context manager exit.</p> <p>This default implementation does nothing, but can be overridden to handle resource cleanup.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Context manager exit.\n\n    This default implementation does nothing, but can be overridden to handle\n    resource cleanup.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.model_context","title":"<code>model_context()</code>","text":"<p>A context manager for temporary model loading.</p> <p>Ensures the model is loaded upon entering the context and unloaded upon exiting if it was not loaded before. This is useful for managing memory in pipelines.</p> <p>Yields:</p> Name Type Description <code>BasePredictor</code> <p>The predictor instance itself.</p> Example <p>with predictor.model_context(): ...     predictions = predictor.predict(data)</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>@contextmanager\ndef model_context(self):\n    \"\"\"A context manager for temporary model loading.\n\n    Ensures the model is loaded upon entering the context and unloaded\n    upon exiting if it was not loaded before. This is useful for managing\n    memory in pipelines.\n\n    Yields:\n        BasePredictor: The predictor instance itself.\n\n    Example:\n        &gt;&gt;&gt; with predictor.model_context():\n        ...     predictions = predictor.predict(data)\n    \"\"\"\n    was_loaded = self.backend.is_loaded\n    try:\n        if not was_loaded:\n            self.load_model()\n        yield self\n    finally:\n        if not was_loaded and self.backend.is_loaded:\n            self.unload_model()\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.evaluate","title":"<code>evaluate(ground_truth: GroundTruthType, prediction: PredictionType | None = None, input_data: InputDataType | None = None, **predict_kwargs: Any) -&gt; dict[str, float]</code>","text":"<p>Evaluate a prediction against a ground truth.</p> <p>Either <code>prediction</code> or <code>input_data</code> must be provided. If <code>prediction</code> is provided, it is used directly. If <code>prediction</code> is None, <code>input_data</code> is used to generate a new prediction.</p> <p>Parameters:</p> Name Type Description Default <code>ground_truth</code> <code>GroundTruthType</code> <p>The ground truth annotation.</p> required <code>prediction</code> <code>PredictionType</code> <p>A pre-computed prediction.</p> <code>None</code> <code>input_data</code> <code>InputDataType</code> <p>Input data to generate a prediction from, if one isn't provided.</p> <code>None</code> <code>**predict_kwargs</code> <code>Any</code> <p>Additional arguments passed to the <code>predict</code> method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>dict[str, float]: Dictionary containing evaluation metrics for a</p> <code>dict[str, float]</code> <p>single item.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither <code>prediction</code> nor <code>input_data</code> is provided.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def evaluate(\n    self,\n    ground_truth: GroundTruthType,\n    prediction: PredictionType | None = None,\n    input_data: InputDataType | None = None,\n    **predict_kwargs: Any,\n) -&gt; dict[str, float]:\n    \"\"\"Evaluate a prediction against a ground truth.\n\n    Either `prediction` or `input_data` must be provided. If `prediction`\n    is provided, it is used directly. If `prediction` is None, `input_data`\n    is used to generate a new prediction.\n\n    Args:\n        ground_truth (GroundTruthType): The ground truth annotation.\n        prediction (PredictionType, optional): A pre-computed prediction.\n        input_data (InputDataType, optional): Input data to generate a\n            prediction from, if one isn't provided.\n        **predict_kwargs (Any): Additional arguments passed to the `predict`\n            method.\n\n    Returns:\n        dict[str, float]: Dictionary containing evaluation metrics for a\n        single item.\n\n    Raises:\n        ValueError: If neither `prediction` nor `input_data` is provided.\n    \"\"\"\n    if prediction is None:\n        if input_data is not None:\n            prediction = self.predict(input_data, **predict_kwargs)\n        else:\n            raise ValueError(\n                \"Either 'prediction' or 'input_data' must be provided.\",\n            )\n    return self._evaluate_from_prediction(\n        prediction=prediction,\n        ground_truth=ground_truth,\n    )\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.evaluate_batch","title":"<code>evaluate_batch(ground_truth_batch: Sequence[GroundTruthType], predictions_batch: Sequence[PredictionType] | None = None, input_data_batch: Sequence[InputDataType] | None = None, num_workers: int = 1, show_progress: bool = False, **predict_kwargs: Any) -&gt; dict[str, Any]</code>","text":"<p>Evaluate on a batch of items using parallel processing.</p> <p>Either <code>predictions_batch</code> or <code>input_data_batch</code> must be provided.</p> <p>Parameters:</p> Name Type Description Default <code>ground_truth_batch</code> <code>Sequence[GroundTruthType]</code> <p>List of corresponding ground truth annotations.</p> required <code>predictions_batch</code> <code>Sequence[PredictionType]</code> <p>A pre-computed list of predictions.</p> <code>None</code> <code>input_data_batch</code> <code>Sequence[InputDataType]</code> <p>List of input data to generate predictions from.</p> <code>None</code> <code>num_workers</code> <code>int</code> <p>Number of parallel workers for calculating metrics.</p> <code>1</code> <code>show_progress</code> <code>bool</code> <p>Whether to show a progress bar.</p> <code>False</code> <code>**predict_kwargs</code> <code>Any</code> <p>Additional arguments passed to <code>predict_batch</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Dictionary containing aggregated evaluation metrics.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the number of predictions does not match the number of ground truths, or if required inputs are missing.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def evaluate_batch(\n    self,\n    ground_truth_batch: Sequence[GroundTruthType],\n    predictions_batch: Sequence[PredictionType] | None = None,\n    input_data_batch: Sequence[InputDataType] | None = None,\n    num_workers: int = 1,\n    show_progress: bool = False,\n    **predict_kwargs: Any,\n) -&gt; dict[str, Any]:\n    \"\"\"Evaluate on a batch of items using parallel processing.\n\n    Either `predictions_batch` or `input_data_batch` must be provided.\n\n    Args:\n        ground_truth_batch (Sequence[GroundTruthType]): List of corresponding\n            ground truth annotations.\n        predictions_batch (Sequence[PredictionType], optional): A pre-computed\n            list of predictions.\n        input_data_batch (Sequence[InputDataType], optional): List of input data\n            to generate predictions from.\n        num_workers (int): Number of parallel workers for calculating metrics.\n        show_progress (bool): Whether to show a progress bar.\n        **predict_kwargs (Any): Additional arguments passed to `predict_batch`.\n\n    Returns:\n        dict[str, Any]: Dictionary containing aggregated evaluation metrics.\n\n    Raises:\n        ValueError: If the number of predictions does not match the number\n            of ground truths, or if required inputs are missing.\n    \"\"\"\n    if predictions_batch is None:\n        if input_data_batch is not None:\n            predictions_batch = self.predict_batch(\n                input_data_batch,\n                show_progress=show_progress,\n                **predict_kwargs,\n            )\n        else:\n            raise ValueError(\n                \"Either 'predictions_batch' or 'input_data_batch' must be provided.\",\n            )\n\n    if len(predictions_batch) != len(ground_truth_batch):\n        raise ValueError(\n            f\"Number of predictions ({len(predictions_batch)}) must match \"\n            f\"number of ground truths ({len(ground_truth_batch)}).\",\n        )\n\n    per_item_metrics = self._calculate_metrics_parallel(\n        predictions_batch,\n        ground_truth_batch,\n        num_workers,\n        show_progress,\n    )\n    aggregated_metrics = self._aggregate_metrics(per_item_metrics)\n    final_report = self._finalize_evaluation_report(\n        aggregated_metrics,\n        predictions_batch,\n        ground_truth_batch,\n    )\n    return final_report\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.get_model_info","title":"<code>get_model_info() -&gt; dict[str, Any]</code>","text":"<p>Gets information about the loaded model.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing details about the model, such</p> <code>dict[str, Any]</code> <p>as architecture, path, etc.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def get_model_info(self) -&gt; dict[str, Any]:\n    \"\"\"Gets information about the loaded model.\n\n    Returns:\n        dict[str, Any]: A dictionary containing details about the model, such\n        as architecture, path, etc.\n    \"\"\"\n    return {\n        \"predictor_type\": self.predictor_type,\n        \"model_loaded\": self.backend.is_loaded,\n        \"config\": self.config.model_dump(),\n    }\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.load_model","title":"<code>load_model() -&gt; None</code>","text":"<p>Delegates model loading to the configured backend.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def load_model(self) -&gt; None:\n    \"\"\"Delegates model loading to the configured backend.\"\"\"\n    if not self.backend.is_loaded:\n        self._logger.info(\n            f\"Loading model for {self.predictor_type} using {self.backend.__class__.__name__}\",\n        )\n        try:\n            self.backend.load_model()\n            self._logger.info(f\"Successfully loaded model for {self.predictor_type}\")\n        except Exception as e:\n            self._logger.error(f\"Failed to load model for {self.predictor_type}: {e}\")\n            raise RuntimeError(f\"Failed to load model for {self.predictor_type}: {e}\") from e\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.predict_batch","title":"<code>predict_batch(input_data_batch: Sequence[InputDataType], show_progress: bool = False, **kwargs: Any) -&gt; list[PredictionType]</code>","text":"<p>Makes predictions on a batch of inputs by delegating to the backend.</p> <p>Parameters:</p> Name Type Description Default <code>input_data_batch</code> <code>Sequence[InputDataType]</code> <p>A sequence of inputs.</p> required <code>show_progress</code> <code>bool</code> <p>If True, displays a progress bar.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments for the backend's <code>predict_batch</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[PredictionType]</code> <p>list[PredictionType]: A list of prediction results.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def predict_batch(\n    self,\n    input_data_batch: Sequence[InputDataType],\n    show_progress: bool = False,\n    **kwargs: Any,\n) -&gt; list[PredictionType]:\n    \"\"\"Makes predictions on a batch of inputs by delegating to the backend.\n\n    Args:\n        input_data_batch (Sequence[InputDataType]): A sequence of inputs.\n        show_progress (bool): If True, displays a progress bar.\n        **kwargs (Any): Additional arguments for the backend's `predict_batch`.\n\n    Returns:\n        list[PredictionType]: A list of prediction results.\n    \"\"\"\n    if not input_data_batch:\n        return []\n\n    if not self.backend.is_loaded:\n        self.load_model()\n\n    raw_predictions = self.backend.predict_batch(list(input_data_batch), **kwargs)\n    final_predictions = [self._convert_raw_to_prediction(raw_pred) for raw_pred in raw_predictions]\n    return final_predictions\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.unload_model","title":"<code>unload_model() -&gt; None</code>","text":"<p>Unloads the model to free memory.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def unload_model(self) -&gt; None:\n    \"\"\"Unloads the model to free memory.\"\"\"\n    if self.backend.is_loaded:\n        self.backend.unload_model()\n        self._logger.info(f\"Unloaded model for {self.predictor_type}\")\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.__init__","title":"<code>__init__(settings: Settings, predictor_type='detector', mode: Literal['torch', 'serve'] | None = None, load_model: bool = False, backend: BaseInferenceBackend | None = None) -&gt; None</code>","text":"<p>Initializes the MosquitoDetector.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>Settings</code> <p>The main settings object for the library.</p> required <code>predictor_type</code> <p>The type of predictor. Defaults to \"detector\".</p> <code>'detector'</code> <code>mode</code> <code>Literal['torch', 'serve'] | None</code> <p>The mode to run the predictor in, 'torch' or 'serve'. If None, it's determined by the environment.</p> <code>None</code> <code>load_model</code> <code>bool</code> <p>If True, load the model upon initialization.</p> <code>False</code> <code>backend</code> <code>BaseInferenceBackend | None</code> <p>An optional backend instance. If not provided, one will be created based on the mode and settings.</p> <code>None</code> Source code in <code>culicidaelab\\predictors\\detector.py</code> <pre><code>def __init__(\n    self,\n    settings: Settings,\n    predictor_type=\"detector\",\n    mode: Literal[\"torch\", \"serve\"] | None = None,\n    load_model: bool = False,\n    backend: BaseInferenceBackend | None = None,\n) -&gt; None:\n    \"\"\"Initializes the MosquitoDetector.\n\n    Args:\n        settings: The main settings object for the library.\n        predictor_type: The type of predictor. Defaults to \"detector\".\n        mode: The mode to run the predictor in, 'torch' or 'serve'.\n            If None, it's determined by the environment.\n        load_model: If True, load the model upon initialization.\n        backend: An optional backend instance. If not provided, one will be\n            created based on the mode and settings.\n    \"\"\"\n\n    backend_instance = backend or create_backend(\n        predictor_type=predictor_type,\n        settings=settings,\n        mode=mode,\n    )\n\n    super().__init__(\n        settings=settings,\n        predictor_type=predictor_type,\n        backend=backend_instance,\n        load_model=load_model,\n    )\n    self.confidence_threshold: float = self.config.confidence or 0.5\n    self.iou_threshold: float = self.config.params.get(\"iou_threshold\", 0.45)\n    self.max_detections: int = self.config.params.get(\"max_detections\", 300)\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.predict","title":"<code>predict(input_data: ImageInput, **kwargs: Any) -&gt; DetectionPrediction</code>","text":"<p>Detects mosquitos in a single image.</p> Example <p>from culicidaelab.settings import Settings from culicidaelab.predictors import MosquitoDetector</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>ImageInput</code> <p>The input image as a NumPy array or other supported format.</p> required <code>**kwargs</code> <code>Any</code> <p>Optional keyword arguments, including: confidence_threshold (float): Override the default confidence     threshold for this prediction.</p> <code>{}</code> <p>Returns:</p> Type Description <code>DetectionPrediction</code> <p>A <code>DetectionPrediction</code> object containing a list of</p> <code>DetectionPrediction</code> <p><code>Detection</code> instances. Returns an empty list if no mosquitos are found.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the model fails to load or if prediction fails.</p> Source code in <code>culicidaelab\\predictors\\detector.py</code> <pre><code>def predict(self, input_data: ImageInput, **kwargs: Any) -&gt; DetectionPrediction:\n    \"\"\"Detects mosquitos in a single image.\n\n    Example:\n        &gt;&gt;&gt; from culicidaelab.settings import Settings\n        &gt;&gt;&gt; from culicidaelab.predictors import MosquitoDetector\n        &gt;&gt;&gt; # This example assumes you have a configured settings object\n        &gt;&gt;&gt; settings = Settings()\n        &gt;&gt;&gt; detector = MosquitoDetector(settings, load_model=True)\n        &gt;&gt;&gt; image = \"path/to/your/image.jpg\"\n        &gt;&gt;&gt; detections = detector.predict(image)\n        &gt;&gt;&gt; for detection in detections.detections:\n        ...     print(detection.box, detection.confidence)\n\n    Args:\n        input_data: The input image as a NumPy array or other supported format.\n        **kwargs: Optional keyword arguments, including:\n            confidence_threshold (float): Override the default confidence\n                threshold for this prediction.\n\n    Returns:\n        A `DetectionPrediction` object containing a list of\n        `Detection` instances. Returns an empty list if no mosquitos are found.\n\n    Raises:\n        RuntimeError: If the model fails to load or if prediction fails.\n    \"\"\"\n    if not self.backend.is_loaded:\n        self.load_model()\n\n    confidence_threshold = kwargs.get(\n        \"confidence_threshold\",\n        self.confidence_threshold,\n    )\n\n    try:\n        input_image = self._load_and_validate_image(input_data)\n        # The backend now returns a standardized NumPy array (N, 5) -&gt; [x1, y1, x2, y2, conf]\n        results_array = self.backend.predict(\n            input_data=input_image,\n            conf=confidence_threshold,\n            iou=self.iou_threshold,\n            max_det=self.max_detections,\n            verbose=False,\n        )\n    except Exception as e:\n        logger.error(f\"Prediction failed: {e}\", exc_info=True)\n        raise RuntimeError(f\"Prediction failed: {e}\") from e\n\n    return self._convert_raw_to_prediction(results_array)\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.predict--this-example-assumes-you-have-a-configured-settings-object","title":"This example assumes you have a configured settings object","text":"<p>settings = Settings() detector = MosquitoDetector(settings, load_model=True) image = \"path/to/your/image.jpg\" detections = detector.predict(image) for detection in detections.detections: ...     print(detection.box, detection.confidence)</p>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.visualize","title":"<code>visualize(input_data: ImageInput, predictions: DetectionPrediction, save_path: str | Path | None = None) -&gt; np.ndarray</code>","text":"<p>Draws predicted bounding boxes on an image.</p> Example <p>from culicidaelab.settings import Settings from culicidaelab.predictors import MosquitoDetector</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>ImageInput</code> <p>The original image.</p> required <code>predictions</code> <code>DetectionPrediction</code> <p>The <code>DetectionPrediction</code> from <code>predict</code>.</p> required <code>save_path</code> <code>str | Path | None</code> <p>If provided, the output image is saved to this path.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A new image array with bounding boxes and confidence scores drawn on it.</p> Source code in <code>culicidaelab\\predictors\\detector.py</code> <pre><code>def visualize(\n    self,\n    input_data: ImageInput,\n    predictions: DetectionPrediction,\n    save_path: str | Path | None = None,\n) -&gt; np.ndarray:\n    \"\"\"Draws predicted bounding boxes on an image.\n\n    Example:\n        &gt;&gt;&gt; from culicidaelab.settings import Settings\n        &gt;&gt;&gt; from culicidaelab.predictors import MosquitoDetector\n        &gt;&gt;&gt; # This example assumes you have a configured settings object\n        &gt;&gt;&gt; settings = Settings()\n        &gt;&gt;&gt; detector = MosquitoDetector(settings, load_model=True)\n        &gt;&gt;&gt; image = \"path/to/your/image.jpg\"\n        &gt;&gt;&gt; detections = detector.predict(image)\n        &gt;&gt;&gt; viz_image = detector.visualize(image, detections, save_path=\"viz.jpg\")\n\n    Args:\n        input_data: The original image.\n        predictions: The `DetectionPrediction` from `predict`.\n        save_path: If provided, the output image is saved to this path.\n\n    Returns:\n        A new image array with bounding boxes and confidence scores drawn on it.\n    \"\"\"\n    vis_img = self._load_and_validate_image(input_data).copy()\n    draw = ImageDraw.Draw(vis_img)\n    vis_config = self.config.visualization\n    font_scale = vis_config.font_scale\n    thickness = vis_config.box_thickness\n\n    for detection in predictions.detections:\n        box = detection.box\n        conf = detection.confidence\n        draw.rectangle(\n            [(int(box.x1), int(box.y1)), (int(box.x2), int(box.y2))],\n            outline=vis_config.box_color,\n            width=thickness,\n        )\n        text = f\"{conf:.2f}\"\n        try:\n            font = ImageFont.truetype(\"arial.ttf\", int(font_scale * 20))\n        except OSError:\n            font = ImageFont.load_default()\n        draw.text((int(box.x1), int(box.y1 - 10)), text, fill=vis_config.text_color, font=font)\n\n    if save_path:\n        save_path = Path(save_path)\n        save_path.parent.mkdir(parents=True, exist_ok=True)\n        vis_img.save(str(save_path))\n\n    return np.array(vis_img)\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoDetector.visualize--this-example-assumes-you-have-a-configured-settings-object","title":"This example assumes you have a configured settings object","text":"<p>settings = Settings() detector = MosquitoDetector(settings, load_model=True) image = \"path/to/your/image.jpg\" detections = detector.predict(image) viz_image = detector.visualize(image, detections, save_path=\"viz.jpg\")</p>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter","title":"<code>MosquitoSegmenter</code>","text":"<p>Segments mosquitos in images using a SAM model.</p> <p>This class provides methods to load a SAM model, generate segmentation masks for entire images or specific regions defined by bounding boxes, and visualize the resulting masks.</p> Example <p>from culicidaelab.core.settings import Settings from culicidaelab.predictors import MosquitoSegmenter import numpy as np</p> Source code in <code>culicidaelab\\predictors\\segmenter.py</code> <pre><code>class MosquitoSegmenter(\n    BasePredictor[ImageInput, SegmentationPrediction, SegmentationGroundTruthType],\n):\n    \"\"\"Segments mosquitos in images using a SAM model.\n\n    This class provides methods to load a SAM model, generate segmentation\n    masks for entire images or specific regions defined by bounding boxes,\n    and visualize the resulting masks.\n\n    Example:\n        &gt;&gt;&gt; from culicidaelab.core.settings import Settings\n        &gt;&gt;&gt; from culicidaelab.predictors import MosquitoSegmenter\n        &gt;&gt;&gt; import numpy as np\n        &gt;&gt;&gt; # This example assumes you have a configured settings object\n        &gt;&gt;&gt; settings = Settings()\n        &gt;&gt;&gt; segmenter = MosquitoSegmenter(settings, load_model=True)\n        &gt;&gt;&gt; image = np.random.randint(0, 256, (1024, 1024, 3), dtype=np.uint8)\n        &gt;&gt;&gt; # Predict without prompts (might not be effective for all backends)\n        &gt;&gt;&gt; prediction = segmenter.predict(image)\n        &gt;&gt;&gt; print(f\"Generated mask with {prediction.pixel_count} pixels.\")\n\n    \"\"\"\n\n    def __init__(\n        self,\n        settings: Settings,\n        predictor_type=\"segmenter\",\n        mode: Literal[\"torch\", \"serve\"] | None = None,\n        load_model: bool = False,\n        backend: BaseInferenceBackend | None = None,\n    ) -&gt; None:\n        \"\"\"Initializes the MosquitoSegmenter.\n\n        Args:\n            settings: The main settings object for the library.\n            predictor_type: The type of predictor. Defaults to \"segmenter\".\n            mode: The mode to run the predictor in, 'torch' or 'serve'.\n                If None, it's determined by the environment.\n            load_model: If True, load the model upon initialization.\n            backend: An optional backend instance. If not provided, one will be\n                created based on the mode and settings.\n        \"\"\"\n\n        backend_instance = backend or create_backend(\n            predictor_type=predictor_type,\n            settings=settings,\n            mode=mode,\n        )\n\n        super().__init__(\n            settings=settings,\n            predictor_type=predictor_type,\n            backend=backend_instance,\n            load_model=load_model,\n        )\n\n    def _convert_raw_to_prediction(self, raw_prediction: np.ndarray) -&gt; SegmentationPrediction:\n        \"\"\"Converts a raw numpy mask to a structured segmentation prediction.\n\n        Args:\n            raw_prediction: A 2D numpy array representing the segmentation mask.\n\n        Returns:\n            A SegmentationPrediction object containing the mask and pixel count.\n        \"\"\"\n        return SegmentationPrediction(mask=raw_prediction, pixel_count=int(np.sum(raw_prediction)))\n\n    def visualize(\n        self,\n        input_data: ImageInput,\n        predictions: SegmentationPrediction,\n        save_path: str | Path | None = None,\n    ) -&gt; np.ndarray:\n        \"\"\"Overlays a segmentation mask on the original image.\n\n        Example:\n            &gt;&gt;&gt; from culicidaelab.settings import Settings\n            &gt;&gt;&gt; from culicidaelab.predictors import MosquitoSegmenter\n            &gt;&gt;&gt; # This example assumes you have a configured settings object\n            &gt;&gt;&gt; settings = Settings()\n            &gt;&gt;&gt; segmenter = MosquitoSegmenter(settings, load_model=True)\n            &gt;&gt;&gt; image = \"path/to/your/image.jpg\"\n            &gt;&gt;&gt; # Assuming you have a prediction from segmenter.predict()\n            &gt;&gt;&gt; prediction = segmenter.predict(image)\n            &gt;&gt;&gt; viz_image = segmenter.visualize(image, prediction, save_path=\"viz.jpg\")\n\n        Args:\n            input_data: The original image.\n            predictions: The `SegmentationPrediction` from `predict`.\n            save_path: If provided, the output image is saved to this path.\n\n        Returns:\n            A numpy array of the image with the segmentation mask overlaid.\n        \"\"\"\n\n        image_pil = self._load_and_validate_image(input_data)\n\n        colored_mask = Image.new(\"RGB\", image_pil.size, self.config.visualization.overlay_color)\n\n        # Create an alpha mask where the segmentation is transparent\n        alpha_mask = Image.fromarray((predictions.mask * 255).astype(np.uint8))\n\n        # Composite the images\n        overlay = Image.composite(colored_mask, image_pil, alpha_mask)\n\n        if save_path:\n            save_path = Path(save_path)\n            save_path.parent.mkdir(parents=True, exist_ok=True)\n            overlay.save(str(save_path))\n\n        return np.array(overlay)\n\n    def _evaluate_from_prediction(\n        self,\n        prediction: SegmentationPrediction,\n        ground_truth: SegmentationGroundTruthType,\n    ) -&gt; dict[str, float]:\n        \"\"\"Calculates segmentation metrics for a single predicted mask.\n\n        Computes Intersection over Union (IoU), precision, recall, and F1-score.\n\n        Args:\n            prediction: The `SegmentationPrediction` object.\n            ground_truth: A 2D numpy array of the ground truth mask.\n\n        Returns:\n            A dictionary containing the calculated metrics.\n\n        Raises:\n            ValueError: If prediction and ground truth masks have different shapes.\n        \"\"\"\n        pred_mask = prediction.mask.astype(bool)\n        ground_truth = ground_truth.astype(bool)\n\n        if pred_mask.shape != ground_truth.shape:\n            raise ValueError(\"Prediction and ground truth must have the same shape.\")\n\n        intersection = np.logical_and(pred_mask, ground_truth).sum()\n        union = np.logical_or(pred_mask, ground_truth).sum()\n        prediction_sum = pred_mask.sum()\n        ground_truth_sum = ground_truth.sum()\n\n        iou = intersection / union if union &gt; 0 else 0.0\n        precision = intersection / prediction_sum if prediction_sum &gt; 0 else 0.0\n        recall = intersection / ground_truth_sum if ground_truth_sum &gt; 0 else 0.0\n        f1 = (2 * (precision * recall) / (precision + recall)) if (precision + recall) &gt; 0 else 0.0\n\n        return {\"iou\": float(iou), \"precision\": float(precision), \"recall\": float(recall), \"f1\": float(f1)}\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter--this-example-assumes-you-have-a-configured-settings-object","title":"This example assumes you have a configured settings object","text":"<p>settings = Settings() segmenter = MosquitoSegmenter(settings, load_model=True) image = np.random.randint(0, 256, (1024, 1024, 3), dtype=np.uint8)</p>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter--predict-without-prompts-might-not-be-effective-for-all-backends","title":"Predict without prompts (might not be effective for all backends)","text":"<p>prediction = segmenter.predict(image) print(f\"Generated mask with {prediction.pixel_count} pixels.\")</p>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.settings","title":"<code>settings = settings</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.predictor_type","title":"<code>predictor_type = predictor_type</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.backend","title":"<code>backend = backend</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.config","title":"<code>config: PredictorConfig</code>  <code>property</code>","text":"<p>Get the predictor configuration Pydantic model.</p> <p>Returns:</p> Name Type Description <code>PredictorConfig</code> <code>PredictorConfig</code> <p>The configuration object for this predictor.</p>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.model_loaded","title":"<code>model_loaded: bool</code>  <code>property</code>","text":"<p>Check if the model is loaded.</p> <p>Returns:</p> Name Type Description <code>bool</code> <code>bool</code> <p>True if the model is loaded, False otherwise.</p>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.__call__","title":"<code>__call__(input_data: InputDataType, **kwargs: Any) -&gt; Any</code>","text":"<p>Convenience method that calls <code>predict()</code>.</p> <p>This allows the predictor instance to be called as a function.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>InputDataType</code> <p>The input data for the prediction.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional arguments to pass to the <code>predict</code> method.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The result of the prediction.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def __call__(self, input_data: InputDataType, **kwargs: Any) -&gt; Any:\n    \"\"\"Convenience method that calls `predict()`.\n\n    This allows the predictor instance to be called as a function.\n\n    Args:\n        input_data (InputDataType): The input data for the prediction.\n        **kwargs (Any): Additional arguments to pass to the `predict` method.\n\n    Returns:\n        Any: The result of the prediction.\n    \"\"\"\n    if not self.backend.is_loaded:\n        self.load_model()\n    return self.predict(input_data, **kwargs)\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.__enter__","title":"<code>__enter__()</code>","text":"<p>Context manager entry.</p> <p>Loads the model if it is not already loaded.</p> <p>Returns:</p> Name Type Description <code>BasePredictor</code> <p>The predictor instance.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def __enter__(self):\n    \"\"\"Context manager entry.\n\n    Loads the model if it is not already loaded.\n\n    Returns:\n        BasePredictor: The predictor instance.\n    \"\"\"\n    if not self.backend.is_loaded:\n        self.load_model()\n    return self\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.__exit__","title":"<code>__exit__(exc_type, exc_val, exc_tb)</code>","text":"<p>Context manager exit.</p> <p>This default implementation does nothing, but can be overridden to handle resource cleanup.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def __exit__(self, exc_type, exc_val, exc_tb):\n    \"\"\"Context manager exit.\n\n    This default implementation does nothing, but can be overridden to handle\n    resource cleanup.\n    \"\"\"\n    pass\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.model_context","title":"<code>model_context()</code>","text":"<p>A context manager for temporary model loading.</p> <p>Ensures the model is loaded upon entering the context and unloaded upon exiting if it was not loaded before. This is useful for managing memory in pipelines.</p> <p>Yields:</p> Name Type Description <code>BasePredictor</code> <p>The predictor instance itself.</p> Example <p>with predictor.model_context(): ...     predictions = predictor.predict(data)</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>@contextmanager\ndef model_context(self):\n    \"\"\"A context manager for temporary model loading.\n\n    Ensures the model is loaded upon entering the context and unloaded\n    upon exiting if it was not loaded before. This is useful for managing\n    memory in pipelines.\n\n    Yields:\n        BasePredictor: The predictor instance itself.\n\n    Example:\n        &gt;&gt;&gt; with predictor.model_context():\n        ...     predictions = predictor.predict(data)\n    \"\"\"\n    was_loaded = self.backend.is_loaded\n    try:\n        if not was_loaded:\n            self.load_model()\n        yield self\n    finally:\n        if not was_loaded and self.backend.is_loaded:\n            self.unload_model()\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.evaluate","title":"<code>evaluate(ground_truth: GroundTruthType, prediction: PredictionType | None = None, input_data: InputDataType | None = None, **predict_kwargs: Any) -&gt; dict[str, float]</code>","text":"<p>Evaluate a prediction against a ground truth.</p> <p>Either <code>prediction</code> or <code>input_data</code> must be provided. If <code>prediction</code> is provided, it is used directly. If <code>prediction</code> is None, <code>input_data</code> is used to generate a new prediction.</p> <p>Parameters:</p> Name Type Description Default <code>ground_truth</code> <code>GroundTruthType</code> <p>The ground truth annotation.</p> required <code>prediction</code> <code>PredictionType</code> <p>A pre-computed prediction.</p> <code>None</code> <code>input_data</code> <code>InputDataType</code> <p>Input data to generate a prediction from, if one isn't provided.</p> <code>None</code> <code>**predict_kwargs</code> <code>Any</code> <p>Additional arguments passed to the <code>predict</code> method.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, float]</code> <p>dict[str, float]: Dictionary containing evaluation metrics for a</p> <code>dict[str, float]</code> <p>single item.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If neither <code>prediction</code> nor <code>input_data</code> is provided.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def evaluate(\n    self,\n    ground_truth: GroundTruthType,\n    prediction: PredictionType | None = None,\n    input_data: InputDataType | None = None,\n    **predict_kwargs: Any,\n) -&gt; dict[str, float]:\n    \"\"\"Evaluate a prediction against a ground truth.\n\n    Either `prediction` or `input_data` must be provided. If `prediction`\n    is provided, it is used directly. If `prediction` is None, `input_data`\n    is used to generate a new prediction.\n\n    Args:\n        ground_truth (GroundTruthType): The ground truth annotation.\n        prediction (PredictionType, optional): A pre-computed prediction.\n        input_data (InputDataType, optional): Input data to generate a\n            prediction from, if one isn't provided.\n        **predict_kwargs (Any): Additional arguments passed to the `predict`\n            method.\n\n    Returns:\n        dict[str, float]: Dictionary containing evaluation metrics for a\n        single item.\n\n    Raises:\n        ValueError: If neither `prediction` nor `input_data` is provided.\n    \"\"\"\n    if prediction is None:\n        if input_data is not None:\n            prediction = self.predict(input_data, **predict_kwargs)\n        else:\n            raise ValueError(\n                \"Either 'prediction' or 'input_data' must be provided.\",\n            )\n    return self._evaluate_from_prediction(\n        prediction=prediction,\n        ground_truth=ground_truth,\n    )\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.evaluate_batch","title":"<code>evaluate_batch(ground_truth_batch: Sequence[GroundTruthType], predictions_batch: Sequence[PredictionType] | None = None, input_data_batch: Sequence[InputDataType] | None = None, num_workers: int = 1, show_progress: bool = False, **predict_kwargs: Any) -&gt; dict[str, Any]</code>","text":"<p>Evaluate on a batch of items using parallel processing.</p> <p>Either <code>predictions_batch</code> or <code>input_data_batch</code> must be provided.</p> <p>Parameters:</p> Name Type Description Default <code>ground_truth_batch</code> <code>Sequence[GroundTruthType]</code> <p>List of corresponding ground truth annotations.</p> required <code>predictions_batch</code> <code>Sequence[PredictionType]</code> <p>A pre-computed list of predictions.</p> <code>None</code> <code>input_data_batch</code> <code>Sequence[InputDataType]</code> <p>List of input data to generate predictions from.</p> <code>None</code> <code>num_workers</code> <code>int</code> <p>Number of parallel workers for calculating metrics.</p> <code>1</code> <code>show_progress</code> <code>bool</code> <p>Whether to show a progress bar.</p> <code>False</code> <code>**predict_kwargs</code> <code>Any</code> <p>Additional arguments passed to <code>predict_batch</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: Dictionary containing aggregated evaluation metrics.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the number of predictions does not match the number of ground truths, or if required inputs are missing.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def evaluate_batch(\n    self,\n    ground_truth_batch: Sequence[GroundTruthType],\n    predictions_batch: Sequence[PredictionType] | None = None,\n    input_data_batch: Sequence[InputDataType] | None = None,\n    num_workers: int = 1,\n    show_progress: bool = False,\n    **predict_kwargs: Any,\n) -&gt; dict[str, Any]:\n    \"\"\"Evaluate on a batch of items using parallel processing.\n\n    Either `predictions_batch` or `input_data_batch` must be provided.\n\n    Args:\n        ground_truth_batch (Sequence[GroundTruthType]): List of corresponding\n            ground truth annotations.\n        predictions_batch (Sequence[PredictionType], optional): A pre-computed\n            list of predictions.\n        input_data_batch (Sequence[InputDataType], optional): List of input data\n            to generate predictions from.\n        num_workers (int): Number of parallel workers for calculating metrics.\n        show_progress (bool): Whether to show a progress bar.\n        **predict_kwargs (Any): Additional arguments passed to `predict_batch`.\n\n    Returns:\n        dict[str, Any]: Dictionary containing aggregated evaluation metrics.\n\n    Raises:\n        ValueError: If the number of predictions does not match the number\n            of ground truths, or if required inputs are missing.\n    \"\"\"\n    if predictions_batch is None:\n        if input_data_batch is not None:\n            predictions_batch = self.predict_batch(\n                input_data_batch,\n                show_progress=show_progress,\n                **predict_kwargs,\n            )\n        else:\n            raise ValueError(\n                \"Either 'predictions_batch' or 'input_data_batch' must be provided.\",\n            )\n\n    if len(predictions_batch) != len(ground_truth_batch):\n        raise ValueError(\n            f\"Number of predictions ({len(predictions_batch)}) must match \"\n            f\"number of ground truths ({len(ground_truth_batch)}).\",\n        )\n\n    per_item_metrics = self._calculate_metrics_parallel(\n        predictions_batch,\n        ground_truth_batch,\n        num_workers,\n        show_progress,\n    )\n    aggregated_metrics = self._aggregate_metrics(per_item_metrics)\n    final_report = self._finalize_evaluation_report(\n        aggregated_metrics,\n        predictions_batch,\n        ground_truth_batch,\n    )\n    return final_report\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.get_model_info","title":"<code>get_model_info() -&gt; dict[str, Any]</code>","text":"<p>Gets information about the loaded model.</p> <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: A dictionary containing details about the model, such</p> <code>dict[str, Any]</code> <p>as architecture, path, etc.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def get_model_info(self) -&gt; dict[str, Any]:\n    \"\"\"Gets information about the loaded model.\n\n    Returns:\n        dict[str, Any]: A dictionary containing details about the model, such\n        as architecture, path, etc.\n    \"\"\"\n    return {\n        \"predictor_type\": self.predictor_type,\n        \"model_loaded\": self.backend.is_loaded,\n        \"config\": self.config.model_dump(),\n    }\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.load_model","title":"<code>load_model() -&gt; None</code>","text":"<p>Delegates model loading to the configured backend.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def load_model(self) -&gt; None:\n    \"\"\"Delegates model loading to the configured backend.\"\"\"\n    if not self.backend.is_loaded:\n        self._logger.info(\n            f\"Loading model for {self.predictor_type} using {self.backend.__class__.__name__}\",\n        )\n        try:\n            self.backend.load_model()\n            self._logger.info(f\"Successfully loaded model for {self.predictor_type}\")\n        except Exception as e:\n            self._logger.error(f\"Failed to load model for {self.predictor_type}: {e}\")\n            raise RuntimeError(f\"Failed to load model for {self.predictor_type}: {e}\") from e\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.predict","title":"<code>predict(input_data: InputDataType, **kwargs: Any) -&gt; PredictionType</code>","text":"<p>Makes a prediction on a single input data sample.</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>InputDataType</code> <p>The input data (e.g., an image as a NumPy array) to make a prediction on.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional predictor-specific arguments.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>PredictionType</code> <code>PredictionType</code> <p>The prediction result, with a format specific to the</p> <code>PredictionType</code> <p>predictor type.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the model is not loaded before calling this method.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def predict(\n    self,\n    input_data: InputDataType,\n    **kwargs: Any,\n) -&gt; PredictionType:\n    \"\"\"Makes a prediction on a single input data sample.\n\n    Args:\n        input_data (InputDataType): The input data (e.g., an image as a NumPy\n            array) to make a prediction on.\n        **kwargs (Any): Additional predictor-specific arguments.\n\n    Returns:\n        PredictionType: The prediction result, with a format specific to the\n        predictor type.\n\n    Raises:\n        RuntimeError: If the model is not loaded before calling this method.\n    \"\"\"\n    if not self.backend.is_loaded:\n        try:\n            self.load_model()\n        except Exception as e:\n            raise RuntimeError(f\"Failed to load model: {e}\") from e\n\n    image = self._load_and_validate_image(input_data)\n\n    raw_output = self.backend.predict(image, **kwargs)\n\n    return self._convert_raw_to_prediction(raw_output)\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.predict_batch","title":"<code>predict_batch(input_data_batch: Sequence[InputDataType], show_progress: bool = False, **kwargs: Any) -&gt; list[PredictionType]</code>","text":"<p>Makes predictions on a batch of inputs by delegating to the backend.</p> <p>Parameters:</p> Name Type Description Default <code>input_data_batch</code> <code>Sequence[InputDataType]</code> <p>A sequence of inputs.</p> required <code>show_progress</code> <code>bool</code> <p>If True, displays a progress bar.</p> <code>False</code> <code>**kwargs</code> <code>Any</code> <p>Additional arguments for the backend's <code>predict_batch</code>.</p> <code>{}</code> <p>Returns:</p> Type Description <code>list[PredictionType]</code> <p>list[PredictionType]: A list of prediction results.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def predict_batch(\n    self,\n    input_data_batch: Sequence[InputDataType],\n    show_progress: bool = False,\n    **kwargs: Any,\n) -&gt; list[PredictionType]:\n    \"\"\"Makes predictions on a batch of inputs by delegating to the backend.\n\n    Args:\n        input_data_batch (Sequence[InputDataType]): A sequence of inputs.\n        show_progress (bool): If True, displays a progress bar.\n        **kwargs (Any): Additional arguments for the backend's `predict_batch`.\n\n    Returns:\n        list[PredictionType]: A list of prediction results.\n    \"\"\"\n    if not input_data_batch:\n        return []\n\n    if not self.backend.is_loaded:\n        self.load_model()\n\n    raw_predictions = self.backend.predict_batch(list(input_data_batch), **kwargs)\n    final_predictions = [self._convert_raw_to_prediction(raw_pred) for raw_pred in raw_predictions]\n    return final_predictions\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.unload_model","title":"<code>unload_model() -&gt; None</code>","text":"<p>Unloads the model to free memory.</p> Source code in <code>culicidaelab\\core\\base_predictor.py</code> <pre><code>def unload_model(self) -&gt; None:\n    \"\"\"Unloads the model to free memory.\"\"\"\n    if self.backend.is_loaded:\n        self.backend.unload_model()\n        self._logger.info(f\"Unloaded model for {self.predictor_type}\")\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.__init__","title":"<code>__init__(settings: Settings, predictor_type='segmenter', mode: Literal['torch', 'serve'] | None = None, load_model: bool = False, backend: BaseInferenceBackend | None = None) -&gt; None</code>","text":"<p>Initializes the MosquitoSegmenter.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>Settings</code> <p>The main settings object for the library.</p> required <code>predictor_type</code> <p>The type of predictor. Defaults to \"segmenter\".</p> <code>'segmenter'</code> <code>mode</code> <code>Literal['torch', 'serve'] | None</code> <p>The mode to run the predictor in, 'torch' or 'serve'. If None, it's determined by the environment.</p> <code>None</code> <code>load_model</code> <code>bool</code> <p>If True, load the model upon initialization.</p> <code>False</code> <code>backend</code> <code>BaseInferenceBackend | None</code> <p>An optional backend instance. If not provided, one will be created based on the mode and settings.</p> <code>None</code> Source code in <code>culicidaelab\\predictors\\segmenter.py</code> <pre><code>def __init__(\n    self,\n    settings: Settings,\n    predictor_type=\"segmenter\",\n    mode: Literal[\"torch\", \"serve\"] | None = None,\n    load_model: bool = False,\n    backend: BaseInferenceBackend | None = None,\n) -&gt; None:\n    \"\"\"Initializes the MosquitoSegmenter.\n\n    Args:\n        settings: The main settings object for the library.\n        predictor_type: The type of predictor. Defaults to \"segmenter\".\n        mode: The mode to run the predictor in, 'torch' or 'serve'.\n            If None, it's determined by the environment.\n        load_model: If True, load the model upon initialization.\n        backend: An optional backend instance. If not provided, one will be\n            created based on the mode and settings.\n    \"\"\"\n\n    backend_instance = backend or create_backend(\n        predictor_type=predictor_type,\n        settings=settings,\n        mode=mode,\n    )\n\n    super().__init__(\n        settings=settings,\n        predictor_type=predictor_type,\n        backend=backend_instance,\n        load_model=load_model,\n    )\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.visualize","title":"<code>visualize(input_data: ImageInput, predictions: SegmentationPrediction, save_path: str | Path | None = None) -&gt; np.ndarray</code>","text":"<p>Overlays a segmentation mask on the original image.</p> Example <p>from culicidaelab.settings import Settings from culicidaelab.predictors import MosquitoSegmenter</p> <p>Parameters:</p> Name Type Description Default <code>input_data</code> <code>ImageInput</code> <p>The original image.</p> required <code>predictions</code> <code>SegmentationPrediction</code> <p>The <code>SegmentationPrediction</code> from <code>predict</code>.</p> required <code>save_path</code> <code>str | Path | None</code> <p>If provided, the output image is saved to this path.</p> <code>None</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>A numpy array of the image with the segmentation mask overlaid.</p> Source code in <code>culicidaelab\\predictors\\segmenter.py</code> <pre><code>def visualize(\n    self,\n    input_data: ImageInput,\n    predictions: SegmentationPrediction,\n    save_path: str | Path | None = None,\n) -&gt; np.ndarray:\n    \"\"\"Overlays a segmentation mask on the original image.\n\n    Example:\n        &gt;&gt;&gt; from culicidaelab.settings import Settings\n        &gt;&gt;&gt; from culicidaelab.predictors import MosquitoSegmenter\n        &gt;&gt;&gt; # This example assumes you have a configured settings object\n        &gt;&gt;&gt; settings = Settings()\n        &gt;&gt;&gt; segmenter = MosquitoSegmenter(settings, load_model=True)\n        &gt;&gt;&gt; image = \"path/to/your/image.jpg\"\n        &gt;&gt;&gt; # Assuming you have a prediction from segmenter.predict()\n        &gt;&gt;&gt; prediction = segmenter.predict(image)\n        &gt;&gt;&gt; viz_image = segmenter.visualize(image, prediction, save_path=\"viz.jpg\")\n\n    Args:\n        input_data: The original image.\n        predictions: The `SegmentationPrediction` from `predict`.\n        save_path: If provided, the output image is saved to this path.\n\n    Returns:\n        A numpy array of the image with the segmentation mask overlaid.\n    \"\"\"\n\n    image_pil = self._load_and_validate_image(input_data)\n\n    colored_mask = Image.new(\"RGB\", image_pil.size, self.config.visualization.overlay_color)\n\n    # Create an alpha mask where the segmentation is transparent\n    alpha_mask = Image.fromarray((predictions.mask * 255).astype(np.uint8))\n\n    # Composite the images\n    overlay = Image.composite(colored_mask, image_pil, alpha_mask)\n\n    if save_path:\n        save_path = Path(save_path)\n        save_path.parent.mkdir(parents=True, exist_ok=True)\n        overlay.save(str(save_path))\n\n    return np.array(overlay)\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.visualize--this-example-assumes-you-have-a-configured-settings-object","title":"This example assumes you have a configured settings object","text":"<p>settings = Settings() segmenter = MosquitoSegmenter(settings, load_model=True) image = \"path/to/your/image.jpg\"</p>"},{"location":"api_docs/predictors/#culicidaelab.predictors.MosquitoSegmenter.visualize--assuming-you-have-a-prediction-from-segmenterpredict","title":"Assuming you have a prediction from segmenter.predict()","text":"<p>prediction = segmenter.predict(image) viz_image = segmenter.visualize(image, prediction, save_path=\"viz.jpg\")</p>"},{"location":"api_docs/predictors/#culicidaelab.predictors.ModelWeightsManager","title":"<code>ModelWeightsManager</code>","text":"<p>Manages the download and local availability of model weights.</p> <p>This class implements the WeightsManagerProtocol and serves as the bridge between a predictor and the provider service that can download model files.</p> <p>Attributes:</p> Name Type Description <code>settings</code> <code>Settings</code> <p>The application's global settings object.</p> <code>provider_service</code> <code>ProviderService</code> <p>The service used to access and download model weights from various providers.</p> Source code in <code>culicidaelab\\predictors\\model_weights_manager.py</code> <pre><code>class ModelWeightsManager(WeightsManagerProtocol):\n    \"\"\"Manages the download and local availability of model weights.\n\n    This class implements the WeightsManagerProtocol and serves as the bridge\n    between a predictor and the provider service that can download model files.\n\n    Attributes:\n        settings (Settings): The application's global settings object.\n        provider_service (ProviderService): The service used to access and\n            download model weights from various providers.\n    \"\"\"\n\n    def __init__(self, settings: Settings):\n        \"\"\"Initializes the ModelWeightsManager.\n\n        Args:\n            settings: The application's global settings object.\n        \"\"\"\n        self.settings = settings\n        self.provider_service = ProviderService(settings)\n\n    def ensure_weights(self, predictor_type: str, backend_type: str) -&gt; Path:\n        \"\"\"Ensures weights for a given predictor and backend are available.\n\n        This method checks if the model weights for the specified predictor and\n        backend type exist locally. If they don't, it downloads them using the\n        provider service.\n\n        Example:\n            &gt;&gt;&gt; from culicidaelab.settings import Settings\n            &gt;&gt;&gt; from culicidaelab.predictors import ModelWeightsManager\n            &gt;&gt;&gt; # This example assumes you have a configured settings object\n            &gt;&gt;&gt; settings = Settings()\n            &gt;&gt;&gt; manager = ModelWeightsManager(settings)\n            &gt;&gt;&gt; weights_path = manager.ensure_weights(\"classifier\", \"torch\")\n            &gt;&gt;&gt; print(weights_path.exists())\n            True\n\n        Args:\n            predictor_type: The type of predictor (e.g., 'classifier').\n            backend_type: The type of backend (e.g., 'torch', 'onnx').\n\n        Returns:\n            The absolute path to the local model weights file.\n\n        Raises:\n            RuntimeError: If the weights cannot be resolved or downloaded.\n            ValueError: If the configuration for the weights is missing\n                'repository_id' or 'filename'.\n        \"\"\"\n\n        try:\n            local_path = self.settings.construct_weights_path(\n                predictor_type=predictor_type,\n                backend=backend_type,\n            )\n\n            if local_path.exists():\n                return local_path\n\n            predictor_config = self.settings.get_config(f\"predictors.{predictor_type}\")\n            # Construct the config key to get the specific weights info\n            weights_config_key = f\"predictors.{predictor_type}.weights.{backend_type}\"\n            weights_config = self.settings.get_config(weights_config_key)\n\n            # The repository can be overridden at the weights level\n            repo_id = predictor_config.repository_id\n            filename = weights_config.filename\n\n            if not all([repo_id, filename]):\n                raise ValueError(f\"Missing 'repository_id' or 'filename' for {weights_config_key}\")\n\n            provider_name = predictor_config.provider_name or \"huggingface\"  # Default provider\n            provider = self.provider_service.get_provider(provider_name)\n\n            # Assuming provider has a method to download a specific file\n            return provider.download_model_weights(\n                repo_id=repo_id,\n                filename=filename,\n                local_dir=local_path.parent,\n            )\n\n        except Exception as e:\n            error_msg = f\"Failed to resolve weights for '{predictor_type}' with backend '{backend_type}': {e}\"\n            raise RuntimeError(error_msg) from e\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.ModelWeightsManager.settings","title":"<code>settings = settings</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.ModelWeightsManager.provider_service","title":"<code>provider_service = ProviderService(settings)</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/predictors/#culicidaelab.predictors.ModelWeightsManager.__init__","title":"<code>__init__(settings: Settings)</code>","text":"<p>Initializes the ModelWeightsManager.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>Settings</code> <p>The application's global settings object.</p> required Source code in <code>culicidaelab\\predictors\\model_weights_manager.py</code> <pre><code>def __init__(self, settings: Settings):\n    \"\"\"Initializes the ModelWeightsManager.\n\n    Args:\n        settings: The application's global settings object.\n    \"\"\"\n    self.settings = settings\n    self.provider_service = ProviderService(settings)\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.ModelWeightsManager.ensure_weights","title":"<code>ensure_weights(predictor_type: str, backend_type: str) -&gt; Path</code>","text":"<p>Ensures weights for a given predictor and backend are available.</p> <p>This method checks if the model weights for the specified predictor and backend type exist locally. If they don't, it downloads them using the provider service.</p> Example <p>from culicidaelab.settings import Settings from culicidaelab.predictors import ModelWeightsManager</p> <p>Parameters:</p> Name Type Description Default <code>predictor_type</code> <code>str</code> <p>The type of predictor (e.g., 'classifier').</p> required <code>backend_type</code> <code>str</code> <p>The type of backend (e.g., 'torch', 'onnx').</p> required <p>Returns:</p> Type Description <code>Path</code> <p>The absolute path to the local model weights file.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If the weights cannot be resolved or downloaded.</p> <code>ValueError</code> <p>If the configuration for the weights is missing 'repository_id' or 'filename'.</p> Source code in <code>culicidaelab\\predictors\\model_weights_manager.py</code> <pre><code>def ensure_weights(self, predictor_type: str, backend_type: str) -&gt; Path:\n    \"\"\"Ensures weights for a given predictor and backend are available.\n\n    This method checks if the model weights for the specified predictor and\n    backend type exist locally. If they don't, it downloads them using the\n    provider service.\n\n    Example:\n        &gt;&gt;&gt; from culicidaelab.settings import Settings\n        &gt;&gt;&gt; from culicidaelab.predictors import ModelWeightsManager\n        &gt;&gt;&gt; # This example assumes you have a configured settings object\n        &gt;&gt;&gt; settings = Settings()\n        &gt;&gt;&gt; manager = ModelWeightsManager(settings)\n        &gt;&gt;&gt; weights_path = manager.ensure_weights(\"classifier\", \"torch\")\n        &gt;&gt;&gt; print(weights_path.exists())\n        True\n\n    Args:\n        predictor_type: The type of predictor (e.g., 'classifier').\n        backend_type: The type of backend (e.g., 'torch', 'onnx').\n\n    Returns:\n        The absolute path to the local model weights file.\n\n    Raises:\n        RuntimeError: If the weights cannot be resolved or downloaded.\n        ValueError: If the configuration for the weights is missing\n            'repository_id' or 'filename'.\n    \"\"\"\n\n    try:\n        local_path = self.settings.construct_weights_path(\n            predictor_type=predictor_type,\n            backend=backend_type,\n        )\n\n        if local_path.exists():\n            return local_path\n\n        predictor_config = self.settings.get_config(f\"predictors.{predictor_type}\")\n        # Construct the config key to get the specific weights info\n        weights_config_key = f\"predictors.{predictor_type}.weights.{backend_type}\"\n        weights_config = self.settings.get_config(weights_config_key)\n\n        # The repository can be overridden at the weights level\n        repo_id = predictor_config.repository_id\n        filename = weights_config.filename\n\n        if not all([repo_id, filename]):\n            raise ValueError(f\"Missing 'repository_id' or 'filename' for {weights_config_key}\")\n\n        provider_name = predictor_config.provider_name or \"huggingface\"  # Default provider\n        provider = self.provider_service.get_provider(provider_name)\n\n        # Assuming provider has a method to download a specific file\n        return provider.download_model_weights(\n            repo_id=repo_id,\n            filename=filename,\n            local_dir=local_path.parent,\n        )\n\n    except Exception as e:\n        error_msg = f\"Failed to resolve weights for '{predictor_type}' with backend '{backend_type}': {e}\"\n        raise RuntimeError(error_msg) from e\n</code></pre>"},{"location":"api_docs/predictors/#culicidaelab.predictors.ModelWeightsManager.ensure_weights--this-example-assumes-you-have-a-configured-settings-object","title":"This example assumes you have a configured settings object","text":"<p>settings = Settings() manager = ModelWeightsManager(settings) weights_path = manager.ensure_weights(\"classifier\", \"torch\") print(weights_path.exists()) True</p>"},{"location":"api_docs/providers/","title":"Providers API","text":"<pre><code>selection:\n\nmembers: true\n</code></pre>"},{"location":"api_docs/providers/#culicidaelab.providers","title":"<code>culicidaelab.providers</code>","text":"<p>Data provider implementations for accessing datasets and models.</p> <p>This package contains classes that implement the <code>BaseProvider</code> interface to interact with various data sources like Hugging Face, Kaggle, etc. Each provider module offers specific logic for downloading datasets and model weights.</p> Available Classes <ul> <li>HuggingFaceProvider: A provider for interacting with the Hugging Face Hub.</li> </ul>"},{"location":"api_docs/providers/#culicidaelab.providers.__all__","title":"<code>__all__ = ['HuggingFaceProvider']</code>  <code>module-attribute</code>","text":""},{"location":"api_docs/providers/#culicidaelab.providers.HuggingFaceProvider","title":"<code>HuggingFaceProvider</code>","text":"<p>Provider for downloading and managing HuggingFace datasets and models.</p> <p>This class interfaces with the Hugging Face Hub to fetch dataset metadata, download full datasets or specific splits, and download model weights. It uses the core settings object for path resolution and API key access.</p> <p>Attributes:</p> Name Type Description <code>provider_name</code> <code>str</code> <p>The name of the provider, \"huggingface\".</p> <code>settings</code> <code>Settings</code> <p>The main Settings object for the library.</p> <code>dataset_url</code> <code>str</code> <p>The base URL for fetching Hugging Face dataset metadata.</p> <code>api_key</code> <code>str | None</code> <p>The Hugging Face API key, if provided.</p> Source code in <code>culicidaelab\\providers\\huggingface_provider.py</code> <pre><code>class HuggingFaceProvider(BaseProvider):\n    \"\"\"Provider for downloading and managing HuggingFace datasets and models.\n\n    This class interfaces with the Hugging Face Hub to fetch dataset metadata,\n    download full datasets or specific splits, and download model weights. It uses\n    the core settings object for path resolution and API key access.\n\n    Attributes:\n        provider_name (str): The name of the provider, \"huggingface\".\n        settings (Settings): The main Settings object for the library.\n        dataset_url (str): The base URL for fetching Hugging Face dataset metadata.\n        api_key (str | None): The Hugging Face API key, if provided.\n    \"\"\"\n\n    def __init__(self, settings: Settings, dataset_url: str, **kwargs: Any) -&gt; None:\n        \"\"\"Initializes the HuggingFace provider.\n\n        This constructor is called by the `ProviderService`, which injects the\n        global `settings` object and unpacks the specific provider's configuration\n        (e.g., `dataset_url`) as keyword arguments.\n\n        Args:\n            settings (Settings): The main Settings object for the library.\n            dataset_url (str): The base URL for fetching Hugging Face dataset metadata.\n            **kwargs (Any): Catches other config parameters (e.g., `api_key`).\n        \"\"\"\n        super().__init__()\n        self.provider_name = \"huggingface\"\n        self.settings = settings\n        self.dataset_url = dataset_url\n        self.api_key: str | None = kwargs.get(\"api_key\") or self.settings.get_api_key(\n            self.provider_name,\n        )\n\n    def download_dataset(\n        self,\n        dataset_name: str,\n        save_dir: Path | None = None,\n        config_name: str | None = None,\n        split: str | None = None,\n        **kwargs: Any,\n    ) -&gt; Path:\n        \"\"\"Downloads a dataset from HuggingFace.\n\n        Args:\n            dataset_name (str): Name of the dataset to download (e.g., \"segmentation\").\n            save_dir (Path | None, optional): Directory to save the dataset.\n                Defaults to None, using the path from settings.\n            config_name (str | None, optional): Name of the dataset configuration.\n                Defaults to None.\n            split (str | None, optional): Dataset split to download (e.g., \"train\").\n                Defaults to None.\n            **kwargs (Any): Additional keyword arguments to pass to `load_dataset`.\n\n        Returns:\n            Path: The path to the downloaded dataset.\n\n        Raises:\n            ValueError: If the configuration is missing the `repository` ID.\n            RuntimeError: If the download fails.\n        \"\"\"\n        save_path = self.settings.get_dataset_path(dataset_name)\n        cache_path = str(self.settings.cache_dir / dataset_name)\n        if save_dir:\n            save_path = save_dir\n        dataset_config = self.settings.get_config(f\"datasets.{dataset_name}\")\n\n        repo_id = dataset_config.repository\n        if not repo_id:\n            raise ValueError(\n                f\"Configuration for dataset '{dataset_name}' is missing the 'repository' (repository ID).\",\n            )\n\n        try:\n            if self.api_key:\n                downloaded_object = load_dataset(\n                    repo_id,\n                    name=config_name,\n                    split=split,\n                    token=self.api_key,\n                    cache_dir=cache_path,\n                    **kwargs,\n                )\n            else:\n                downloaded_object = load_dataset(\n                    repo_id,\n                    name=config_name,\n                    split=split,\n                    cache_dir=cache_path,\n                    **kwargs,\n                )\n\n            saveable_dataset = None\n            if isinstance(downloaded_object, (IterableDataset, IterableDatasetDict)):\n                if isinstance(downloaded_object, IterableDataset):\n                    saveable_dataset = Dataset.from_list(list(downloaded_object))\n                else:\n                    materialized_splits = {s_name: list(s_data) for s_name, s_data in downloaded_object.items()}\n                    saveable_dataset = DatasetDict(\n                        {s_name: Dataset.from_list(data) for s_name, data in materialized_splits.items()},\n                    )\n            else:\n                saveable_dataset = downloaded_object\n\n            if Path(save_path).exists() and Path(save_path).is_dir():\n                shutil.rmtree(save_path)\n\n            save_path.mkdir(parents=True, exist_ok=True)\n\n            saveable_dataset.save_to_disk(str(save_path))\n\n            shutil.rmtree(cache_path, ignore_errors=True)\n\n            return save_path\n\n        except Exception as e:\n            if Path(save_path).exists() and Path(save_path).is_dir():\n                shutil.rmtree(save_path)\n            raise RuntimeError(f\"Failed to download dataset {repo_id}: {str(e)}\") from e\n\n    def download_model_weights(self, repo_id: str, filename: str, local_dir: Path) -&gt; Path:\n        \"\"\"Downloads and caches a specific model weights file from the HuggingFace Hub.\n\n        Checks if the file exists locally. If not, it downloads it from the specified\n        repository and saves it to the given local directory.\n\n        Args:\n            repo_id (str): The Hugging Face repository ID (e.g., 'user/repo-name').\n            filename (str): The specific weights file to download (e.g., 'model.onnx').\n            local_dir (Path): The local directory to save the file in.\n\n        Returns:\n            Path: The absolute path to the downloaded model weights file.\n\n        Raises:\n            ValueError: If `repo_id` or `filename` are not provided.\n            RuntimeError: If the download fails for any reason.\n        \"\"\"\n        if not repo_id or not filename:\n            raise ValueError(\"'repo_id' and 'filename' must be provided.\")\n\n        local_path = (local_dir / filename).resolve()\n        cache_dir = self.settings.cache_dir / f\"{repo_id.replace('/', '_')}_{filename}\"\n\n        if local_path.exists():\n            print(f\"Weights file found at: {local_path}\")\n            return local_path\n\n        print(f\"Model weights '{filename}' not found locally. Attempting to download from {repo_id}...\")\n\n        try:\n            local_dir.mkdir(parents=True, exist_ok=True)\n\n            downloaded_path_str = hf_hub_download(\n                repo_id=repo_id,\n                filename=filename,\n                cache_dir=str(cache_dir),\n                local_dir=str(local_dir),\n                # local_dir_use_symlinks=False,  # Use direct file placement\n            )\n\n            downloaded_path = Path(downloaded_path_str)\n\n            # hf_hub_download might place it in a subfolder structure, so we ensure it's moved to the final destination\n            if downloaded_path.resolve() != local_path.resolve():\n                shutil.move(str(downloaded_path), str(local_path))\n                print(f\"Moved weights to final destination: {local_path}\")\n            else:\n                print(f\"Downloaded weights directly to: {local_path}\")\n\n            # Clean up the cache directory if it was used\n            if cache_dir.exists():\n                shutil.rmtree(cache_dir, ignore_errors=True)\n\n            return local_path\n\n        except Exception as e:\n            # Clean up any partial download\n            if local_path.exists():\n                local_path.unlink()\n            raise RuntimeError(\n                f\"Failed to download weights file '{filename}' from repo '{repo_id}'. Error: {e}\",\n            ) from e\n\n    def get_dataset_metadata(self, dataset_name: str) -&gt; dict[str, Any]:\n        \"\"\"Gets metadata for a specific dataset from HuggingFace.\n\n        Args:\n            dataset_name (str): The name of the dataset to get metadata for.\n\n        Returns:\n            dict[str, Any]: The dataset metadata as a dictionary.\n\n        Raises:\n            requests.RequestException: If the HTTP request fails.\n        \"\"\"\n        url = self.dataset_url.format(dataset_name=dataset_name)\n        headers = {\"Authorization\": f\"Bearer {self.api_key}\"} if self.api_key else {}\n\n        try:\n            response = requests.get(url, headers=headers, timeout=10.0)\n            response.raise_for_status()\n            return cast(dict[str, Any], response.json())\n        except requests.RequestException as e:\n            raise requests.RequestException(\n                f\"Failed to fetch dataset metadata for {dataset_name}: {str(e)}\",\n            ) from e\n\n    def get_provider_name(self) -&gt; str:\n        \"\"\"Returns the provider's name.\n\n        Returns:\n            str: The name of the provider, \"huggingface\".\n        \"\"\"\n        return self.provider_name\n\n    def load_dataset(self, dataset_path: str | Path, **kwargs: Any) -&gt; Any:\n        \"\"\"Loads a dataset from disk.\n\n        This method attempts to load a dataset from the specified path. If a `split`\n        name is provided and a corresponding subdirectory exists, it will load\n        the split from that subdirectory. Otherwise, it loads the entire dataset\n        from the base path.\n\n        Args:\n            dataset_path (str | Path): The local path to the dataset,\n                typically returned by `download_dataset`.\n            **kwargs: Additional keyword arguments to pass to the\n                `datasets.load_from_disk` function.\n\n        Returns:\n            Any: The loaded dataset, typically a `datasets.Dataset` or\n                `datasets.DatasetDict` object.\n        \"\"\"\n        return load_from_disk(str(dataset_path), **kwargs)\n</code></pre>"},{"location":"api_docs/providers/#culicidaelab.providers.HuggingFaceProvider.provider_name","title":"<code>provider_name = 'huggingface'</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/providers/#culicidaelab.providers.HuggingFaceProvider.settings","title":"<code>settings = settings</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/providers/#culicidaelab.providers.HuggingFaceProvider.dataset_url","title":"<code>dataset_url = dataset_url</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/providers/#culicidaelab.providers.HuggingFaceProvider.api_key","title":"<code>api_key: str | None = kwargs.get('api_key') or self.settings.get_api_key(self.provider_name)</code>  <code>instance-attribute</code>","text":""},{"location":"api_docs/providers/#culicidaelab.providers.HuggingFaceProvider.__init__","title":"<code>__init__(settings: Settings, dataset_url: str, **kwargs: Any) -&gt; None</code>","text":"<p>Initializes the HuggingFace provider.</p> <p>This constructor is called by the <code>ProviderService</code>, which injects the global <code>settings</code> object and unpacks the specific provider's configuration (e.g., <code>dataset_url</code>) as keyword arguments.</p> <p>Parameters:</p> Name Type Description Default <code>settings</code> <code>Settings</code> <p>The main Settings object for the library.</p> required <code>dataset_url</code> <code>str</code> <p>The base URL for fetching Hugging Face dataset metadata.</p> required <code>**kwargs</code> <code>Any</code> <p>Catches other config parameters (e.g., <code>api_key</code>).</p> <code>{}</code> Source code in <code>culicidaelab\\providers\\huggingface_provider.py</code> <pre><code>def __init__(self, settings: Settings, dataset_url: str, **kwargs: Any) -&gt; None:\n    \"\"\"Initializes the HuggingFace provider.\n\n    This constructor is called by the `ProviderService`, which injects the\n    global `settings` object and unpacks the specific provider's configuration\n    (e.g., `dataset_url`) as keyword arguments.\n\n    Args:\n        settings (Settings): The main Settings object for the library.\n        dataset_url (str): The base URL for fetching Hugging Face dataset metadata.\n        **kwargs (Any): Catches other config parameters (e.g., `api_key`).\n    \"\"\"\n    super().__init__()\n    self.provider_name = \"huggingface\"\n    self.settings = settings\n    self.dataset_url = dataset_url\n    self.api_key: str | None = kwargs.get(\"api_key\") or self.settings.get_api_key(\n        self.provider_name,\n    )\n</code></pre>"},{"location":"api_docs/providers/#culicidaelab.providers.HuggingFaceProvider.download_dataset","title":"<code>download_dataset(dataset_name: str, save_dir: Path | None = None, config_name: str | None = None, split: str | None = None, **kwargs: Any) -&gt; Path</code>","text":"<p>Downloads a dataset from HuggingFace.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>Name of the dataset to download (e.g., \"segmentation\").</p> required <code>save_dir</code> <code>Path | None</code> <p>Directory to save the dataset. Defaults to None, using the path from settings.</p> <code>None</code> <code>config_name</code> <code>str | None</code> <p>Name of the dataset configuration. Defaults to None.</p> <code>None</code> <code>split</code> <code>str | None</code> <p>Dataset split to download (e.g., \"train\"). Defaults to None.</p> <code>None</code> <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to pass to <code>load_dataset</code>.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>The path to the downloaded dataset.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the configuration is missing the <code>repository</code> ID.</p> <code>RuntimeError</code> <p>If the download fails.</p> Source code in <code>culicidaelab\\providers\\huggingface_provider.py</code> <pre><code>def download_dataset(\n    self,\n    dataset_name: str,\n    save_dir: Path | None = None,\n    config_name: str | None = None,\n    split: str | None = None,\n    **kwargs: Any,\n) -&gt; Path:\n    \"\"\"Downloads a dataset from HuggingFace.\n\n    Args:\n        dataset_name (str): Name of the dataset to download (e.g., \"segmentation\").\n        save_dir (Path | None, optional): Directory to save the dataset.\n            Defaults to None, using the path from settings.\n        config_name (str | None, optional): Name of the dataset configuration.\n            Defaults to None.\n        split (str | None, optional): Dataset split to download (e.g., \"train\").\n            Defaults to None.\n        **kwargs (Any): Additional keyword arguments to pass to `load_dataset`.\n\n    Returns:\n        Path: The path to the downloaded dataset.\n\n    Raises:\n        ValueError: If the configuration is missing the `repository` ID.\n        RuntimeError: If the download fails.\n    \"\"\"\n    save_path = self.settings.get_dataset_path(dataset_name)\n    cache_path = str(self.settings.cache_dir / dataset_name)\n    if save_dir:\n        save_path = save_dir\n    dataset_config = self.settings.get_config(f\"datasets.{dataset_name}\")\n\n    repo_id = dataset_config.repository\n    if not repo_id:\n        raise ValueError(\n            f\"Configuration for dataset '{dataset_name}' is missing the 'repository' (repository ID).\",\n        )\n\n    try:\n        if self.api_key:\n            downloaded_object = load_dataset(\n                repo_id,\n                name=config_name,\n                split=split,\n                token=self.api_key,\n                cache_dir=cache_path,\n                **kwargs,\n            )\n        else:\n            downloaded_object = load_dataset(\n                repo_id,\n                name=config_name,\n                split=split,\n                cache_dir=cache_path,\n                **kwargs,\n            )\n\n        saveable_dataset = None\n        if isinstance(downloaded_object, (IterableDataset, IterableDatasetDict)):\n            if isinstance(downloaded_object, IterableDataset):\n                saveable_dataset = Dataset.from_list(list(downloaded_object))\n            else:\n                materialized_splits = {s_name: list(s_data) for s_name, s_data in downloaded_object.items()}\n                saveable_dataset = DatasetDict(\n                    {s_name: Dataset.from_list(data) for s_name, data in materialized_splits.items()},\n                )\n        else:\n            saveable_dataset = downloaded_object\n\n        if Path(save_path).exists() and Path(save_path).is_dir():\n            shutil.rmtree(save_path)\n\n        save_path.mkdir(parents=True, exist_ok=True)\n\n        saveable_dataset.save_to_disk(str(save_path))\n\n        shutil.rmtree(cache_path, ignore_errors=True)\n\n        return save_path\n\n    except Exception as e:\n        if Path(save_path).exists() and Path(save_path).is_dir():\n            shutil.rmtree(save_path)\n        raise RuntimeError(f\"Failed to download dataset {repo_id}: {str(e)}\") from e\n</code></pre>"},{"location":"api_docs/providers/#culicidaelab.providers.HuggingFaceProvider.download_model_weights","title":"<code>download_model_weights(repo_id: str, filename: str, local_dir: Path) -&gt; Path</code>","text":"<p>Downloads and caches a specific model weights file from the HuggingFace Hub.</p> <p>Checks if the file exists locally. If not, it downloads it from the specified repository and saves it to the given local directory.</p> <p>Parameters:</p> Name Type Description Default <code>repo_id</code> <code>str</code> <p>The Hugging Face repository ID (e.g., 'user/repo-name').</p> required <code>filename</code> <code>str</code> <p>The specific weights file to download (e.g., 'model.onnx').</p> required <code>local_dir</code> <code>Path</code> <p>The local directory to save the file in.</p> required <p>Returns:</p> Name Type Description <code>Path</code> <code>Path</code> <p>The absolute path to the downloaded model weights file.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>repo_id</code> or <code>filename</code> are not provided.</p> <code>RuntimeError</code> <p>If the download fails for any reason.</p> Source code in <code>culicidaelab\\providers\\huggingface_provider.py</code> <pre><code>def download_model_weights(self, repo_id: str, filename: str, local_dir: Path) -&gt; Path:\n    \"\"\"Downloads and caches a specific model weights file from the HuggingFace Hub.\n\n    Checks if the file exists locally. If not, it downloads it from the specified\n    repository and saves it to the given local directory.\n\n    Args:\n        repo_id (str): The Hugging Face repository ID (e.g., 'user/repo-name').\n        filename (str): The specific weights file to download (e.g., 'model.onnx').\n        local_dir (Path): The local directory to save the file in.\n\n    Returns:\n        Path: The absolute path to the downloaded model weights file.\n\n    Raises:\n        ValueError: If `repo_id` or `filename` are not provided.\n        RuntimeError: If the download fails for any reason.\n    \"\"\"\n    if not repo_id or not filename:\n        raise ValueError(\"'repo_id' and 'filename' must be provided.\")\n\n    local_path = (local_dir / filename).resolve()\n    cache_dir = self.settings.cache_dir / f\"{repo_id.replace('/', '_')}_{filename}\"\n\n    if local_path.exists():\n        print(f\"Weights file found at: {local_path}\")\n        return local_path\n\n    print(f\"Model weights '{filename}' not found locally. Attempting to download from {repo_id}...\")\n\n    try:\n        local_dir.mkdir(parents=True, exist_ok=True)\n\n        downloaded_path_str = hf_hub_download(\n            repo_id=repo_id,\n            filename=filename,\n            cache_dir=str(cache_dir),\n            local_dir=str(local_dir),\n            # local_dir_use_symlinks=False,  # Use direct file placement\n        )\n\n        downloaded_path = Path(downloaded_path_str)\n\n        # hf_hub_download might place it in a subfolder structure, so we ensure it's moved to the final destination\n        if downloaded_path.resolve() != local_path.resolve():\n            shutil.move(str(downloaded_path), str(local_path))\n            print(f\"Moved weights to final destination: {local_path}\")\n        else:\n            print(f\"Downloaded weights directly to: {local_path}\")\n\n        # Clean up the cache directory if it was used\n        if cache_dir.exists():\n            shutil.rmtree(cache_dir, ignore_errors=True)\n\n        return local_path\n\n    except Exception as e:\n        # Clean up any partial download\n        if local_path.exists():\n            local_path.unlink()\n        raise RuntimeError(\n            f\"Failed to download weights file '{filename}' from repo '{repo_id}'. Error: {e}\",\n        ) from e\n</code></pre>"},{"location":"api_docs/providers/#culicidaelab.providers.HuggingFaceProvider.get_dataset_metadata","title":"<code>get_dataset_metadata(dataset_name: str) -&gt; dict[str, Any]</code>","text":"<p>Gets metadata for a specific dataset from HuggingFace.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_name</code> <code>str</code> <p>The name of the dataset to get metadata for.</p> required <p>Returns:</p> Type Description <code>dict[str, Any]</code> <p>dict[str, Any]: The dataset metadata as a dictionary.</p> <p>Raises:</p> Type Description <code>RequestException</code> <p>If the HTTP request fails.</p> Source code in <code>culicidaelab\\providers\\huggingface_provider.py</code> <pre><code>def get_dataset_metadata(self, dataset_name: str) -&gt; dict[str, Any]:\n    \"\"\"Gets metadata for a specific dataset from HuggingFace.\n\n    Args:\n        dataset_name (str): The name of the dataset to get metadata for.\n\n    Returns:\n        dict[str, Any]: The dataset metadata as a dictionary.\n\n    Raises:\n        requests.RequestException: If the HTTP request fails.\n    \"\"\"\n    url = self.dataset_url.format(dataset_name=dataset_name)\n    headers = {\"Authorization\": f\"Bearer {self.api_key}\"} if self.api_key else {}\n\n    try:\n        response = requests.get(url, headers=headers, timeout=10.0)\n        response.raise_for_status()\n        return cast(dict[str, Any], response.json())\n    except requests.RequestException as e:\n        raise requests.RequestException(\n            f\"Failed to fetch dataset metadata for {dataset_name}: {str(e)}\",\n        ) from e\n</code></pre>"},{"location":"api_docs/providers/#culicidaelab.providers.HuggingFaceProvider.get_provider_name","title":"<code>get_provider_name() -&gt; str</code>","text":"<p>Returns the provider's name.</p> <p>Returns:</p> Name Type Description <code>str</code> <code>str</code> <p>The name of the provider, \"huggingface\".</p> Source code in <code>culicidaelab\\providers\\huggingface_provider.py</code> <pre><code>def get_provider_name(self) -&gt; str:\n    \"\"\"Returns the provider's name.\n\n    Returns:\n        str: The name of the provider, \"huggingface\".\n    \"\"\"\n    return self.provider_name\n</code></pre>"},{"location":"api_docs/providers/#culicidaelab.providers.HuggingFaceProvider.load_dataset","title":"<code>load_dataset(dataset_path: str | Path, **kwargs: Any) -&gt; Any</code>","text":"<p>Loads a dataset from disk.</p> <p>This method attempts to load a dataset from the specified path. If a <code>split</code> name is provided and a corresponding subdirectory exists, it will load the split from that subdirectory. Otherwise, it loads the entire dataset from the base path.</p> <p>Parameters:</p> Name Type Description Default <code>dataset_path</code> <code>str | Path</code> <p>The local path to the dataset, typically returned by <code>download_dataset</code>.</p> required <code>**kwargs</code> <code>Any</code> <p>Additional keyword arguments to pass to the <code>datasets.load_from_disk</code> function.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>Any</code> <code>Any</code> <p>The loaded dataset, typically a <code>datasets.Dataset</code> or <code>datasets.DatasetDict</code> object.</p> Source code in <code>culicidaelab\\providers\\huggingface_provider.py</code> <pre><code>def load_dataset(self, dataset_path: str | Path, **kwargs: Any) -&gt; Any:\n    \"\"\"Loads a dataset from disk.\n\n    This method attempts to load a dataset from the specified path. If a `split`\n    name is provided and a corresponding subdirectory exists, it will load\n    the split from that subdirectory. Otherwise, it loads the entire dataset\n    from the base path.\n\n    Args:\n        dataset_path (str | Path): The local path to the dataset,\n            typically returned by `download_dataset`.\n        **kwargs: Additional keyword arguments to pass to the\n            `datasets.load_from_disk` function.\n\n    Returns:\n        Any: The loaded dataset, typically a `datasets.Dataset` or\n            `datasets.DatasetDict` object.\n    \"\"\"\n    return load_from_disk(str(dataset_path), **kwargs)\n</code></pre>"},{"location":"api_docs/serve/","title":"Serve API","text":""},{"location":"api_docs/serve/#culicidaelab.serve","title":"<code>culicidaelab.serve</code>","text":"<p>High-level inference functions for production environments.</p> <p>This module provides a simplified, high-performance interface for running predictions. It is designed for production use cases where speed and reliability are critical. The <code>serve</code> function automatically utilizes the ONNX backend for inference, which is optimized for lightweight and fast execution. To avoid the overhead of repeated model loading, it caches predictor instances in memory.</p> Example <p>from culicidaelab.serve import serve, clear_serve_cache from PIL import Image</p>"},{"location":"api_docs/serve/#culicidaelab.serve--run-a-prediction","title":"Run a prediction","text":"<p>image_path = \"path/to/your/image.jpg\" prediction = serve(image_path, predictor_type=\"detector\", confidence_threshold=0.5) print(prediction)</p>"},{"location":"api_docs/serve/#culicidaelab.serve--clear-the-cache-when-done-or-to-free-up-resources","title":"Clear the cache when done or to free up resources","text":"<p>clear_serve_cache()</p>"},{"location":"api_docs/serve/#culicidaelab.serve.ImageInput","title":"<code>ImageInput: TypeAlias = Union[np.ndarray, str, Path, Image.Image, bytes]</code>  <code>module-attribute</code>","text":"<p>Type alias for acceptable image input formats.</p>"},{"location":"api_docs/serve/#culicidaelab.serve.PredictionResult","title":"<code>PredictionResult: TypeAlias = Union[ClassificationPrediction, DetectionPrediction, SegmentationPrediction]</code>  <code>module-attribute</code>","text":"<p>Type alias for the structured prediction output.</p>"},{"location":"api_docs/serve/#culicidaelab.serve.serve","title":"<code>serve(image: ImageInput, predictor_type: str = 'classifier', **kwargs) -&gt; PredictionResult</code>","text":"<p>Runs a prediction using a specified predictor type in high-performance mode.</p> <p>This function is optimized for production environments. It automatically selects the ONNX backend for fast inference and caches the initialized predictor in memory to minimize latency on subsequent calls. The first call for a given <code>predictor_type</code> will be slower as it includes model initialization.</p> <p>Parameters:</p> Name Type Description Default <code>image</code> <code>ImageInput</code> <p>The input image to process. Can be a file path (str or Path), a PIL Image, a NumPy array, or bytes.</p> required <code>predictor_type</code> <code>str</code> <p>The type of predictor to use. Valid options are 'classifier', 'detector', and 'segmenter'. Defaults to 'classifier'.</p> <code>'classifier'</code> <code>**kwargs</code> <p>Additional keyword arguments to pass to the predictor's <code>predict</code> method. For example, <code>confidence_threshold=0.5</code> for a detector.</p> <code>{}</code> <p>Returns:</p> Type Description <code>PredictionResult</code> <p>A Pydantic model (<code>ClassificationPrediction</code>, <code>DetectionPrediction</code>, or</p> <code>PredictionResult</code> <p><code>SegmentationPrediction</code>) containing the structured prediction results.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an unknown <code>predictor_type</code> is specified.</p> Example <p>from culicidaelab.serve import serve from PIL import Image</p> Source code in <code>culicidaelab\\serve.py</code> <pre><code>def serve(\n    image: ImageInput,\n    predictor_type: str = \"classifier\",\n    **kwargs,\n) -&gt; PredictionResult:\n    \"\"\"Runs a prediction using a specified predictor type in high-performance mode.\n\n    This function is optimized for production environments. It automatically selects\n    the ONNX backend for fast inference and caches the initialized predictor in\n    memory to minimize latency on subsequent calls. The first call for a given\n    `predictor_type` will be slower as it includes model initialization.\n\n    Args:\n        image: The input image to process. Can be a file path (str or Path),\n            a PIL Image, a NumPy array, or bytes.\n        predictor_type: The type of predictor to use. Valid options are\n            'classifier', 'detector', and 'segmenter'. Defaults to 'classifier'.\n        **kwargs: Additional keyword arguments to pass to the predictor's\n            `predict` method. For example, `confidence_threshold=0.5` for\n            a detector.\n\n    Returns:\n        A Pydantic model (`ClassificationPrediction`, `DetectionPrediction`, or\n        `SegmentationPrediction`) containing the structured prediction results.\n\n    Raises:\n        ValueError: If an unknown `predictor_type` is specified.\n\n    Example:\n        &gt;&gt;&gt; from culicidaelab.serve import serve\n        &gt;&gt;&gt; from PIL import Image\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Create a dummy image\n        &gt;&gt;&gt; dummy_image = Image.new('RGB', (100, 100), color = 'red')\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Run mosquito detection\n        &gt;&gt;&gt; detection_result = serve(dummy_image, predictor_type=\"detector\", confidence_threshold=0.5)\n        &gt;&gt;&gt; print(detection_result.model_dump_json(indent=2))\n        &gt;&gt;&gt;\n        &gt;&gt;&gt; # Run mosquito classification\n        &gt;&gt;&gt; classification_result = serve(dummy_image, predictor_type=\"classifier\")\n        &gt;&gt;&gt; print(classification_result.model_dump_json(indent=2))\n    \"\"\"\n    if predictor_type not in _PREDICTOR_CACHE:\n        settings = get_settings()\n        predictor_class_map: dict[str, type[BasePredictor]] = {\n            \"classifier\": MosquitoClassifier,\n            \"detector\": MosquitoDetector,\n            \"segmenter\": MosquitoSegmenter,\n        }\n\n        if predictor_type not in predictor_class_map:\n            raise ValueError(\n                f\"Unknown predictor_type: '{predictor_type}'. \"\n                f\"Available options are: {list(predictor_class_map.keys())}\",\n            )\n\n        predictor_class = predictor_class_map[predictor_type]\n\n        # Create the backend instance configured for serving (ONNX)\n        backend_instance = create_backend(\n            predictor_type=predictor_type,\n            settings=settings,\n            mode=\"serve\",\n        )\n        # Instantiate the predictor, forcing the 'serve' mode to guarantee ONNX is used.\n        # This overrides any local YAML configuration for maximum safety.\n        print(f\"Initializing '{predictor_type}' predictor for serving...\")\n        predictor = predictor_class(settings, predictor_type=predictor_type, backend=backend_instance)\n        _PREDICTOR_CACHE[predictor_type] = predictor\n\n    # Retrieve the cached predictor and run prediction\n    predictor_instance = _PREDICTOR_CACHE[predictor_type]\n    return predictor_instance.predict(image, **kwargs)\n</code></pre>"},{"location":"api_docs/serve/#culicidaelab.serve.serve--create-a-dummy-image","title":"Create a dummy image","text":"<p>dummy_image = Image.new('RGB', (100, 100), color = 'red')</p>"},{"location":"api_docs/serve/#culicidaelab.serve.serve--run-mosquito-detection","title":"Run mosquito detection","text":"<p>detection_result = serve(dummy_image, predictor_type=\"detector\", confidence_threshold=0.5) print(detection_result.model_dump_json(indent=2))</p>"},{"location":"api_docs/serve/#culicidaelab.serve.serve--run-mosquito-classification","title":"Run mosquito classification","text":"<p>classification_result = serve(dummy_image, predictor_type=\"classifier\") print(classification_result.model_dump_json(indent=2))</p>"},{"location":"api_docs/serve/#culicidaelab.serve.clear_serve_cache","title":"<code>clear_serve_cache()</code>","text":"<p>Clears the in-memory predictor cache and unloads models.</p> <p>This function should be called to release GPU memory and other resources when the <code>serve</code> function is no longer needed. It iterates through all cached predictors, unloads their models, and then clears the cache dictionary.</p> Source code in <code>culicidaelab\\serve.py</code> <pre><code>def clear_serve_cache():\n    \"\"\"Clears the in-memory predictor cache and unloads models.\n\n    This function should be called to release GPU memory and other resources\n    when the `serve` function is no longer needed. It iterates through all\n    cached predictors, unloads their models, and then clears the cache dictionary.\n    \"\"\"\n    global _PREDICTOR_CACHE\n    for predictor in _PREDICTOR_CACHE.values():\n        # Ensure the model and any associated resources are released\n        predictor.unload_model()\n    _PREDICTOR_CACHE = {}\n</code></pre>"},{"location":"dev_docs/architecture/","title":"DEVELOPER GUIDE","text":""},{"location":"dev_docs/architecture/#1-introduction","title":"1. Introduction","text":""},{"location":"dev_docs/architecture/#11-purpose","title":"1.1 Purpose","text":"<p>This document provides a detailed design description for the CulicidaeLab library. The library is a Python-based system designed to facilitate the management of datasets, configuration, and machine learning models (predictors) for tasks related to mosquito image analysis, including detection, segmentation, and classification.</p>"},{"location":"dev_docs/architecture/#12-scope","title":"1.2 Scope","text":"<p>The library provides:</p> <ul> <li>A type-safe, validated configuration system for model parameters, application settings, and species metadata.</li> <li>Cross-platform resource management for datasets, model weights, cache, and temporary files.</li> <li>A suite of predictors for classification, detection, and segmentation, built on a common base class.</li> <li>A provider-based architecture for integration with external data sources like Hugging Face.</li> <li>Utilities for dataset handling, file operations, and result visualization.</li> </ul>"},{"location":"dev_docs/architecture/#13-definitions-acronyms-and-abbreviations-daa","title":"1.3 Definitions, Acronyms, and Abbreviations (DAA)","text":"<ul> <li>YOLO: You Only Look Once (an object detection model architecture)</li> <li>SAM: Segment Anything Model (a segmentation model architecture)</li> <li>IoU: Intersection over Union (a metric for segmentation and detection)</li> <li>AP: Average Precision (a metric for detection)</li> <li>mAP: Mean Average Precision (detection metric)</li> <li>Pydantic: A data validation and settings management library for Python.</li> </ul>"},{"location":"dev_docs/architecture/#14-references","title":"1.4 References","text":"<ul> <li>IEEE Std 1016-1998, IEEE Recommended Practice for Software Design Descriptions.</li> <li>Python 3.x Language Reference.</li> <li>Pydantic Documentation.</li> <li>OmegaConf Documentation.</li> <li>FastAI Library Documentation.</li> <li>HuggingFace Hub and Datasets Documentation.</li> <li>YOLO (Ultralytics) Model Documentation.</li> <li>Segment Anything Model (SAM) Documentation.</li> <li>timm (PyTorch Image Models) Documentation.</li> </ul>"},{"location":"dev_docs/architecture/#15-overview-of-the-document","title":"1.5 Overview of the Document","text":"<p>This document is organized into four main sections:</p> <ul> <li>Section 1 (Introduction): Provides the purpose, scope, definitions, references, and an overview of this document.</li> <li>Section 2 (System Overview): Describes the system's context, objectives, and overall functions.</li> <li>Section 3 (System Architectural Design): Outlines the high-level architecture, including component decomposition, their interfaces, and data design.</li> <li>Section 4 (System Detailed Design): Provides a detailed description of each module and its constituent classes, including their purpose, functions, interfaces, and data.</li> <li>Section 5 (Traceability): Briefly discusses how the design addresses the implicit requirements of the library.</li> </ul>"},{"location":"dev_docs/architecture/#2-system-overview","title":"2. System Overview","text":""},{"location":"dev_docs/architecture/#21-system-context","title":"2.1 System Context","text":"<p>The CulicidaeLab library is intended to be used by researchers, developers, and data scientists working on projects involving mosquito image analysis. It can serve as a backend for more extensive applications or be used directly in scripts for batch processing, model evaluation, and dataset management. It operates within a Python environment and relies on several external libraries for its core functionalities (e.g., Pydantic, FastAI, Hugging Face libraries, PyTorch, Ultralytics).</p>"},{"location":"dev_docs/architecture/#22-system-objectives","title":"2.2 System Objectives","text":"<p>The primary objectives of this library are:</p> <ol> <li>To provide a centralized, type-safe, and validated way to manage configurations for datasets, models, and application settings using Pydantic.</li> <li>To offer a flexible, provider-based system for managing and accessing diverse datasets and model weights from various sources (e.g., Hugging Face).</li> <li>To define a common, predictable interface (<code>BasePredictor</code>) for different types of predictors (detector, segmenter, classifier) and provide concrete implementations.</li> <li>To facilitate efficient model inference, clear result visualization, and standardized evaluation.</li> <li>To ensure robust, cross-platform resource management for models, datasets, cache, and temporary files.</li> </ol>"},{"location":"dev_docs/architecture/#23-system-functions","title":"2.3 System Functions","text":"<p>The library provides the following key functions:</p> <ul> <li>Configuration Management: Loads, merges, and validates hierarchical configurations from YAML files into Pydantic models.</li> <li>Resource Management: Manages file system paths for models, datasets, cache, and temporary files in a cross-platform manner.</li> <li>Provider Abstraction: Downloads datasets and model weights from external providers (e.g., Hugging Face) through a standardized interface.</li> <li>Dataset Management: Lists and loads datasets as defined in the configuration, using the provider abstraction.</li> <li>Model Prediction: Performs inference using detector, segmenter, and classifier models on single images or batches.</li> <li>Result Visualization: Generates visual outputs of model predictions overlaid on input images.</li> <li>Model Evaluation: Evaluates model performance against ground truth data using standard metrics for each task.</li> <li>Model Weight Management: Ensures model weights are available locally, downloading them via providers when necessary.</li> </ul>"},{"location":"dev_docs/architecture/#3-system-architectural-design","title":"3. System Architectural Design","text":""},{"location":"dev_docs/architecture/#31-architectural-overview-and-design-principles","title":"3.1 Architectural Overview and Design Principles","text":"<p>The architecture of the <code>culicidaelab</code> library is built on the principles of Clean Code and SOLID to provide users with a powerful and flexible tool that remains simple to use. The architecture is clearly divided into logical layers, each with its own area of responsibility. This separation simplifies understanding, testing, and extending the code.</p> <p>The library features a revolutionary pluggable backend architecture that enables support for multiple ML frameworks (PyTorch, ONNX) and optimized deployment modes. This allows for flexible installation profiles ranging from lightweight serving-only deployments to full development environments.</p>"},{"location":"dev_docs/architecture/#311-architectural-layers-diagram","title":"3.1.1 Architectural Layers Diagram","text":"<pre><code>graph TD\n    %% -- Layers Definition --\n    classDef userLayer fill:#eaf4ff,stroke:#004085,stroke-width:2px,color:#004085\n    classDef productLayer fill:#e8f5e9,stroke:#155724,stroke-width:2px,color:#155724\n    classDef facadeLayer fill:#fff8e1,stroke:#856404,stroke-width:2px,color:#856404\n    classDef coreLayer fill:#fbe9e7,stroke:#721c24,stroke-width:2px,color:#721c24\n    classDef infraLayer fill:#eceff1,stroke:#383d41,stroke-width:2px,color:#383d41\n    classDef backendLayer fill:#e3f2fd,stroke:#0277bd,stroke-width:2px,color:#0277bd\n    classDef externalLayer fill:#f5f5f5,stroke:#6c757d,stroke-width:4px,stroke-dasharray: 5 5\n\n    %% -- User Layer --\n    subgraph \"User\"\n         LibraryUser[/\"\ud83d\udc64 Library User\"/]\n         ServeAPI[/\"\u26a1 Serve API&lt;br/&gt;(Production)\"/]\n    end\n\n    %% -- Products Layer --\n    subgraph \"Main Library Functionality\"\n        direction TB\n        Predictors[\"\ud83d\udd2c Predictors\"]\n        style Predictors fill:#fff,stroke:none\n        MosquitoClassifier(\"\ud83e\udd9f MosquitoClassifier\")\n        MosquitoDetector(\"\ud83c\udfaf MosquitoDetector\")\n        MosquitoSegmenter(\"\u2702\ufe0f MosquitoSegmenter\")\n        UtilityFunctions(\"\ud83d\udd27 Utility Functions&lt;br/&gt;list_models()&lt;br/&gt;list_datasets()\")\n    end\n\n    %% -- Facade Layer --\n    subgraph \"Facade (Configuration Center)\"\n        facade_spacer[\"&lt;br&gt;\"]; style facade_spacer fill:none,stroke:none\n        facade_spacer ~~~ Settings\n        Settings[\"\ud83c\udf9b\ufe0f Settings&lt;br/&gt;&lt;b&gt;(Facade)&lt;/b&gt;&lt;br/&gt;Provides unified access&lt;br/&gt;to services and parameters\"]\n    end\n\n    %% -- Core Abstraction &amp; Logic Layer --\n    subgraph \"Core (Abstractions &amp; Contracts)\"\n        core_spacer[\"&lt;br&gt;\"]; style core_spacer fill:none,stroke:none\n        core_spacer ~~~ BasePredictor\n        BasePredictor[\"\ud83e\udde9 BasePredictor&lt;br/&gt;Abstract class for&lt;br/&gt;all predictors\"]\n        BaseProvider[\"\ud83d\udd0c BaseProvider&lt;br/&gt;Abstract class for&lt;br/&gt;external providers\"]\n        BaseInferenceBackend[\"\ud83c\udfaf BaseInferenceBackend&lt;br/&gt;Abstract backend interface&lt;br/&gt;for ML frameworks\"]\n        PredictionModels[\"\ud83d\udcca Prediction Models&lt;br/&gt;Pydantic-based structured&lt;br/&gt;prediction outputs\"]\n        ProviderService[\"\ud83d\udd27 ProviderService&lt;br/&gt;Factory for creating&lt;br/&gt;provider objects\"]\n        ConfigManager[\"\u2699\ufe0f ConfigManager&lt;br/&gt;Manages configurations&lt;br/&gt;from YAML files\"]\n    end\n\n    %% -- Backend Layer --\n    subgraph \"Pluggable Backend System\"\n        BackendFactory[\"\ud83c\udfed Backend Factory&lt;br/&gt;Intelligent backend selection&lt;br/&gt;based on environment\"]\n        PyTorchBackends[\"\ud83d\udd25 PyTorch Backends&lt;br/&gt;FastAI, YOLO, SAM&lt;br/&gt;(Development)\"]\n        ONNXBackends[\"\u26a1 ONNX Backends&lt;br/&gt;Optimized inference&lt;br/&gt;(Production)\"]\n    end\n\n    %% -- Infrastructure &amp; Adapters Layer --\n    subgraph \"Infrastructure &amp; Adapters\"\n        infra_spacer[\"&lt;br&gt;\"]; style infra_spacer fill:none,stroke:none\n        infra_spacer ~~~ DatasetsManager\n        ResourceManager[\"\ud83d\udcc1 ResourceManager&lt;br/&gt;Manages files&lt;br/&gt;and directories\"]\n        HuggingFaceProvider[\"\ud83e\udd17 HuggingFaceProvider&lt;br/&gt;&lt;b&gt;(Adapter)&lt;/b&gt;&lt;br/&gt;Implementation for&lt;br/&gt;Hugging Face Hub\"]\n        DatasetsManager[\"\ud83d\udcca DatasetsManager&lt;br/&gt;Manages the lifecycle&lt;br/&gt;of datasets\"]\n    end\n\n    %% -- External Systems --\n    subgraph \"External Systems\"\n        direction LR\n        HuggingFaceHub[(\"\ud83c\udf10&lt;br/&gt;Hugging Face Hub\")]\n        FileSystem[(\"\ud83d\udcbe&lt;br/&gt;Local&lt;br/&gt;File System\")]\n    end\n\n    %% -- Relationships --\n    LibraryUser -- \"Uses\" --&gt; MosquitoClassifier\n    LibraryUser -- \"Uses\" --&gt; MosquitoDetector\n    LibraryUser -- \"Uses\" --&gt; MosquitoSegmenter\n    LibraryUser -- \"Uses\" --&gt; UtilityFunctions\n    LibraryUser -- \"High-performance API\" --&gt; ServeAPI\n    LibraryUser -- \"Or manages data via\" --&gt; DatasetsManager\n\n    ServeAPI -- \"Optimized inference\" --&gt; ONNXBackends\n    ServeAPI -- \"Caches predictors\" --&gt; MosquitoClassifier\n    ServeAPI -- \"Caches predictors\" --&gt; MosquitoDetector\n    ServeAPI -- \"Caches predictors\" --&gt; MosquitoSegmenter\n\n    MosquitoClassifier -- \"Receives on creation\" --&gt; Settings\n    MosquitoDetector -- \"Receives on creation\" --&gt; Settings\n    MosquitoSegmenter -- \"Receives on creation\" --&gt; Settings\n    UtilityFunctions -- \"Uses\" --&gt; Settings\n\n    Settings -- \"Manages\" --&gt; ProviderService\n    Settings -- \"Manages\" --&gt; ConfigManager\n    Settings -- \"Manages\" --&gt; ResourceManager\n\n    MosquitoClassifier -. \"Implements\" .-&gt; BasePredictor\n    MosquitoDetector -. \"Implements\" .-&gt; BasePredictor\n    MosquitoSegmenter -. \"Implements\" .-&gt; BasePredictor\n    Predictors --- MosquitoClassifier\n    Predictors --- MosquitoDetector\n    Predictors --- MosquitoSegmenter\n\n    BasePredictor -- \"Delegates to\" --&gt; BaseInferenceBackend\n    BasePredictor -- \"Outputs\" --&gt; PredictionModels\n    BackendFactory -- \"Creates\" --&gt; BaseInferenceBackend\n    BackendFactory -. \"Selects\" .-&gt; PyTorchBackends\n    BackendFactory -. \"Selects\" .-&gt; ONNXBackends\n    PyTorchBackends -. \"Implements\" .-&gt; BaseInferenceBackend\n    ONNXBackends -. \"Implements\" .-&gt; BaseInferenceBackend\n\n    DatasetsManager -- \"Uses\" --&gt; ProviderService\n    ProviderService -- \"Creates\" --&gt; HuggingFaceProvider\n    HuggingFaceProvider -. \"Implements\" .-&gt; BaseProvider\n\n    HuggingFaceProvider -- \"Downloads from\" --&gt; HuggingFaceHub\n    ResourceManager -- \"Works with\" --&gt; FileSystem\n    HuggingFaceProvider -- \"Saves to\" --&gt; ResourceManager\n    ConfigManager -- \"Reads from\" --&gt; ResourceManager\n\n    %% -- Styling --\n    class LibraryUser,ServeAPI userLayer\n    class MosquitoClassifier,MosquitoDetector,MosquitoSegmenter,Predictors,UtilityFunctions productLayer\n    class Settings facadeLayer\n    class BasePredictor,BaseProvider,BaseInferenceBackend,PredictionModels,ProviderService,ConfigManager coreLayer\n    class BackendFactory,PyTorchBackends,ONNXBackends backendLayer\n    class ResourceManager,HuggingFaceProvider,DatasetsManager infraLayer\n    class HuggingFaceHub,FileSystem externalLayer</code></pre>"},{"location":"dev_docs/architecture/#312-layer-descriptions","title":"3.1.2 Layer Descriptions","text":"<ol> <li> <p>Main Library Functionality: This is the highest level, representing the concrete, usable products of the library: <code>MosquitoClassifier</code>, <code>MosquitoDetector</code>, <code>MosquitoSegmenter</code>, and utility functions. Also includes the high-performance <code>serve()</code> API for production deployments.</p> </li> <li> <p>Facade (Configuration Center): The <code>Settings</code> class implements the Facade design pattern. It serves as a single, simplified entry point for configuring the entire library, hiding the internal complexity of managing configurations, resources, and services.</p> </li> <li> <p>Core (Abstractions and Contracts): This is the architectural core, defining the main abstract classes and interfaces (<code>BasePredictor</code>, <code>BaseProvider</code>, <code>BaseInferenceBackend</code>). This layer is completely decoupled from concrete implementations and includes structured prediction models built with Pydantic.</p> </li> <li> <p>Pluggable Backend System: A revolutionary layer that enables support for multiple ML frameworks. The <code>BackendFactory</code> intelligently selects between PyTorch backends (for development) and ONNX backends (for production) based on environment, configuration, and user preferences.</p> </li> <li> <p>Infrastructure and Adapters: This layer contains concrete implementations of the core abstractions. It acts as a bridge between the library's logic and the outside world.</p> </li> <li><code>DatasetsManager</code> manages high-level dataset resources.</li> <li><code>HuggingFaceProvider</code> implements the Adapter pattern, adapting the Hugging Face API to the internal <code>BaseProvider</code> interface.</li> <li> <p><code>ResourceManager</code> works directly with the file system.</p> </li> <li> <p>External Systems: Resources outside the library's direct control, such as the <code>Hugging Face Hub</code> and the local <code>File System</code>.</p> </li> </ol>"},{"location":"dev_docs/architecture/#313-guiding-design-principles","title":"3.1.3 Guiding Design Principles","text":"<ul> <li> <p>Extensibility: To add a new data source (e.g., AWS S3), a developer only needs to create a new <code>S3Provider</code> that implements the <code>BaseProvider</code> interface and register it in the configuration. To add a new ML framework backend, implement <code>BaseInferenceBackend</code> and register it with the <code>BackendFactory</code>. No changes are needed in the high-level predictor modules.</p> </li> <li> <p>Pluggable Architecture: The backend system enables seamless switching between ML frameworks (PyTorch, ONNX) and deployment modes (development, production) without changing user-facing APIs.</p> </li> <li> <p>Installation Flexibility: The architecture supports multiple installation profiles:</p> </li> <li>Lightweight serving (<code>[serve]</code>): ONNX-only for production deployments (~200MB)</li> <li> <p>Full development (<code>[full]</code>): PyTorch + ONNX for complete functionality (~2GB+)</p> </li> <li> <p>Maintainability &amp; Testability: The single responsibility of each component simplifies debugging. The use of dependency inversion allows infrastructure components to be replaced with mocks during testing.</p> </li> <li> <p>SOLID Principles:</p> </li> <li>Dependency Inversion Principle (DIP): High-level modules (<code>MosquitoClassifier</code>) do not depend on low-level modules (<code>HuggingFaceProvider</code>, specific backends). Both depend on abstractions (<code>BaseProvider</code>, <code>BaseInferenceBackend</code>).</li> <li>Factory Pattern (<code>ProviderService</code>, <code>BackendFactory</code>): Allows the system to dynamically decide which provider or backend object to create based on configuration and environment.</li> <li>Facade Pattern (<code>Settings</code>): Simplifies the user's interaction with the library by hiding the complexity of creating and wiring internal components.</li> <li>Strategy Pattern (Backends): Different inference strategies (PyTorch vs ONNX) can be swapped without changing the predictor interface.</li> </ul>"},{"location":"dev_docs/architecture/#32-component-decomposition","title":"3.2 Component Decomposition","text":"<p>The library is decomposed into five main high-level modules:</p> <ol> <li><code>core</code> Module:</li> <li>Description: Forms the backbone of the library, providing essential services, base classes, protocols, and data models.</li> <li> <p>Sub-components: <code>Settings</code>, <code>ConfigManager</code>, <code>ResourceManager</code>, <code>BasePredictor</code>, <code>BaseProvider</code>, <code>BaseInferenceBackend</code>, <code>ProviderService</code>, <code>prediction_models</code>, <code>config_models</code>, <code>species_config</code>, <code>utils</code>.</p> </li> <li> <p><code>datasets</code> Module:</p> </li> <li>Description: Handles the high-level logic for managing and accessing datasets.</li> <li> <p>Sub-components: <code>DatasetsManager</code>.</p> </li> <li> <p><code>providers</code> Module:</p> </li> <li>Description: Contains concrete implementations of <code>core.BaseProvider</code> for fetching data from various external sources.</li> <li> <p>Sub-components: <code>HuggingFaceProvider</code>.</p> </li> <li> <p><code>predictors</code> Module:</p> </li> <li>Description: Contains concrete implementations of <code>BasePredictor</code> for specific machine learning tasks, the backend factory system, and concrete backend implementations.</li> <li> <p>Sub-components: <code>MosquitoClassifier</code>, <code>MosquitoDetector</code>, <code>MosquitoSegmenter</code>, <code>BackendFactory</code>, <code>backends/</code> (PyTorch and ONNX implementations).</p> </li> <li> <p><code>serve</code> Module:</p> </li> <li>Description: High-performance production API for optimized inference with automatic backend selection and in-memory caching.</li> <li>Sub-components: <code>serve()</code> function, <code>clear_serve_cache()</code> function.</li> </ol>"},{"location":"dev_docs/architecture/#33-component-interfaces","title":"3.3 Component Interfaces","text":"<ul> <li> <p><code>core.Settings</code>: The primary user-facing class, accessed via <code>get_settings()</code>. It acts as a singleton facade, providing simple access to configuration values, resource paths (<code>.model_dir</code>), helper objects, and utility functions like <code>list_models()</code> and <code>list_datasets()</code>. It initializes and holds instances of <code>ConfigManager</code> and <code>ResourceManager</code>.</p> </li> <li> <p><code>core.ConfigManager</code>: An internal component managed by <code>Settings</code>. It loads default and user YAML files, merges them, and validates the result against Pydantic models defined in <code>core.config_models</code>.</p> </li> <li> <p><code>core.ResourceManager</code>: Provides standardized paths for data storage (models, datasets, cache) used by <code>Settings</code>, <code>DatasetsManager</code>, and backend implementations.</p> </li> <li> <p><code>core.BaseProvider</code>: An abstract base class defining the contract for any component that provides data (datasets or model files), with methods like <code>download_dataset</code> and <code>download_model_weights</code>.</p> </li> <li> <p><code>core.ProviderService</code>: A factory and cache for provider instances. It uses <code>Settings</code> to look up a provider's configuration and instantiates the correct <code>BaseProvider</code> implementation (e.g., <code>providers.HuggingFaceProvider</code>).</p> </li> <li> <p><code>datasets.DatasetsManager</code>: Manages access to datasets. It uses <code>Settings</code> to get dataset configurations and the <code>ProviderService</code> to acquire the correct provider instance to download and load data.</p> </li> <li> <p><code>core.BaseInferenceBackend</code>: An abstract base class defining the contract for ML framework backends. It provides methods for model loading (<code>load_model</code>), inference (<code>predict</code>, <code>predict_batch</code>), and resource management (<code>unload_model</code>, <code>is_loaded</code>).</p> </li> <li> <p><code>predictors.BackendFactory</code>: Intelligent factory for creating backend instances. It automatically selects between PyTorch and ONNX backends based on user preferences, configuration, and environment capabilities.</p> </li> <li> <p><code>core.BasePredictor</code>: The abstract base class for all predictors. It defines the standard interface (<code>predict</code>, <code>evaluate</code>, <code>visualize</code>) and delegates model operations to a <code>BaseInferenceBackend</code> instance. It outputs structured Pydantic prediction models.</p> </li> <li> <p><code>core.prediction_models</code>: Pydantic models for structured, type-safe prediction outputs: <code>ClassificationPrediction</code>, <code>DetectionPrediction</code>, <code>SegmentationPrediction</code>. These replace the previous tuple-based outputs.</p> </li> <li> <p><code>predictors.*</code> (e.g., <code>MosquitoClassifier</code>, <code>MosquitoDetector</code>): Concrete implementations of <code>BasePredictor</code>. They are initialized with <code>Settings</code> and automatically create appropriate backends via the <code>BackendFactory</code>.</p> </li> <li> <p><code>serve</code>: High-performance production API that automatically uses ONNX backends and implements in-memory caching for minimal latency on subsequent calls.</p> </li> </ul>"},{"location":"dev_docs/architecture/#34-conceptual-interaction-flow","title":"3.4 Conceptual interaction flow","text":"<pre><code>sequenceDiagram\n    participant User\n    participant MosquitoClassifier\n    participant BackendFactory\n    participant ClassifierFastAIBackend\n    participant ProviderService\n    participant HuggingFaceProvider\n    participant ResourceManager\n    participant HuggingFaceHub\n\n    Note over User, HuggingFaceHub: Model initialization with new backend architecture\n\n    User-&gt;&gt;MosquitoClassifier: MosquitoClassifier(settings, load_model=True)\n    activate MosquitoClassifier\n    MosquitoClassifier-&gt;&gt;BackendFactory: create_backend(settings, \"classifier\")\n    activate BackendFactory\n    BackendFactory--&gt;&gt;MosquitoClassifier: ClassifierFastAIBackend instance\n    deactivate BackendFactory\n\n    MosquitoClassifier-&gt;&gt;ClassifierFastAIBackend: load_model()\n    activate ClassifierFastAIBackend\n    ClassifierFastAIBackend-&gt;&gt;ProviderService: get_provider(\"huggingface\")\n    activate ProviderService\n    ProviderService--&gt;&gt;ClassifierFastAIBackend: HuggingFaceProvider instance\n    deactivate ProviderService\n\n    ClassifierFastAIBackend-&gt;&gt;HuggingFaceProvider: download_model_weights()\n    activate HuggingFaceProvider\n    HuggingFaceProvider-&gt;&gt;ResourceManager: get_save_location()\n    activate ResourceManager\n    ResourceManager--&gt;&gt;HuggingFaceProvider: Path/to/save\n    deactivate ResourceManager\n    HuggingFaceProvider-&gt;&gt;HuggingFaceHub: Download file\n    activate HuggingFaceHub\n    HuggingFaceHub--&gt;&gt;HuggingFaceProvider: Model weights file\n    deactivate HuggingFaceHub\n    HuggingFaceProvider--&gt;&gt;ClassifierFastAIBackend: /path/to/model.pth\n    deactivate HuggingFaceProvider\n\n    ClassifierFastAIBackend-&gt;&gt;ClassifierFastAIBackend: load_learner(/path/to/model.pth)\n    ClassifierFastAIBackend--&gt;&gt;MosquitoClassifier: Backend ready\n    deactivate ClassifierFastAIBackend\n    deactivate MosquitoClassifier\n\n    Note over User, HuggingFaceHub: Prediction with structured output\n\n    User-&gt;&gt;MosquitoClassifier: predict(image)\n    activate MosquitoClassifier\n    MosquitoClassifier-&gt;&gt;ClassifierFastAIBackend: predict(image)\n    activate ClassifierFastAIBackend\n    ClassifierFastAIBackend--&gt;&gt;MosquitoClassifier: Raw prediction\n    deactivate ClassifierFastAIBackend\n    MosquitoClassifier-&gt;&gt;MosquitoClassifier: _convert_raw_to_prediction()\n    MosquitoClassifier--&gt;&gt;User: ClassificationPrediction (Pydantic model)\n    deactivate MosquitoClassifier\n</code></pre> <p>To illustrate how the components interact, consider the common scenario of classifying a mosquito image with the new backend architecture.</p> <ol> <li>Initialization: The user's application calls <code>get_settings()</code> to retrieve the <code>Settings</code> facade instance. The <code>Settings</code> object loads all necessary configurations from YAML files. The user then creates an instance of <code>MosquitoClassifier</code>, passing it the <code>settings</code> object.</li> </ol> <pre><code>from culicidaelab import MosquitoClassifier, get_settings\n\nsettings = get_settings()\nclassifier = MosquitoClassifier(settings=settings, load_model=True)\n</code></pre> <ol> <li> <p>Backend Selection: Upon initialization, the <code>MosquitoClassifier</code> uses the <code>BackendFactory</code> to intelligently select an appropriate backend. The factory examines the environment, configuration, and user preferences to choose between PyTorch (development) or ONNX (production) backends.</p> </li> <li> <p>Backend Initialization: The selected backend (e.g., <code>ClassifierFastAIBackend</code>) is instantiated and becomes responsible for all model operations.</p> </li> <li> <p>Model Weight Management: When <code>load_model=True</code>, the backend handles weight downloading through the provider system. It uses the <code>ProviderService</code> to get a <code>HuggingFaceProvider</code> instance, which downloads the model weights from the Hugging Face Hub and saves them locally via the <code>ResourceManager</code>.</p> </li> <li> <p>Model Loading: The backend loads the model into memory using the appropriate ML framework (PyTorch, ONNX, etc.).</p> </li> <li> <p>Prediction with Structured Output: When the user calls <code>predict()</code>, the predictor delegates to the backend for raw inference, then converts the raw output to a structured Pydantic model (<code>ClassificationPrediction</code>) that provides type safety and JSON serialization.</p> </li> </ol> <p>This new architecture provides several advantages: - Pluggable backends enable different ML frameworks and optimization levels - Automatic backend selection based on environment and preferences - Structured outputs with Pydantic models for type safety - Installation flexibility with lightweight serving vs full development profiles</p> <p>The entire complex process remains hidden from the end-user, who only needs to perform the initial creation step, but benefits from enhanced performance and flexibility.</p>"},{"location":"dev_docs/architecture/#35-data-design","title":"3.5 Data Design","text":"<ul> <li> <p>Configuration Data: Managed by <code>ConfigManager</code> and validated into a tree of Pydantic models, with <code>core.config_models.CulicidaeLabConfig</code> as the root. The original source is YAML files.</p> </li> <li> <p>Image Data: Represented as <code>np.ndarray</code> (NumPy arrays) or other formats supported by the backend system.</p> </li> <li> <p>Dataset Metadata: Formally defined by the <code>core.config_models.DatasetConfig</code> Pydantic model.</p> </li> <li> <p>Model Predictions: Used structured Pydantic models instead of tuples for type safety, validation, and JSON serialization:</p> </li> <li>Classifier: <code>ClassificationPrediction</code> containing a list of <code>Classification</code> objects with species names and confidence scores. Provides <code>top_prediction()</code> method for easy access.</li> <li>Detector: <code>DetectionPrediction</code> containing a list of <code>Detection</code> objects with <code>BoundingBox</code> coordinates and confidence scores.</li> <li> <p>Segmenter: <code>SegmentationPrediction</code> containing binary masks and metadata.</p> </li> <li> <p>Legacy Prediction Formats (deprecated but supported for backward compatibility):</p> </li> <li>Detector: <code>list[tuple[float, float, float, float, float]]</code> (center_x, center_y, width, height, confidence).</li> <li>Segmenter: <code>np.ndarray</code> (binary mask of shape HxW).</li> <li> <p>Classifier: <code>list[tuple[str, float]]</code> (species_name, confidence_score).</p> </li> <li> <p>Ground Truth Data: Similarly represented by a <code>typing.TypeAlias</code> (e.g., <code>DetectionGroundTruthType</code>) with formats matching the prediction types.</p> </li> <li> <p>Evaluation Metrics: Dictionaries mapping metric names to float values (<code>dict[str, float]</code>).</p> </li> <li> <p>Filesystem Paths: Managed as <code>pathlib.Path</code> objects by <code>ResourceManager</code> and <code>Settings</code>.</p> </li> <li> <p>Backend Data: Raw predictions from ML frameworks are converted to structured models via the <code>_convert_raw_to_prediction()</code> method in each predictor.</p> </li> </ul>"},{"location":"dev_docs/architecture/#4-system-detailed-design","title":"4. System Detailed Design","text":"<p>This section details each module and its components.</p>"},{"location":"dev_docs/architecture/#41-core-module-detailed-design","title":"4.1 <code>core</code> Module Detailed Design","text":"<p>The <code>core</code> module provides foundational classes, protocols, and utilities essential for the functioning of the entire library. It handles configuration, resource management, and defines the basic contracts for predictors and data providers.</p> <p>Project Structure:</p> <pre><code>core\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 base_inference_backend.py\n\u251c\u2500\u2500 base_predictor.py\n\u251c\u2500\u2500 base_provider.py\n\u251c\u2500\u2500 config_manager.py\n\u251c\u2500\u2500 config_models.py\n\u251c\u2500\u2500 provider_service.py\n\u251c\u2500\u2500 resource_manager.py\n\u251c\u2500\u2500 settings.py\n\u251c\u2500\u2500 species_config.py\n\u251c\u2500\u2500 utils.py\n\u2514\u2500\u2500 weights_manager_protocol.py\n</code></pre>"},{"location":"dev_docs/architecture/#411-corebase_predictorbasepredictor","title":"4.1.1 <code>core.base_predictor.BasePredictor</code>","text":"<ul> <li>Identification: <code>core.base_predictor.BasePredictor</code></li> <li>Purpose: An abstract base class that defines a common interface for all predictors (e.g., detector, segmenter, classifier). Major architectural overhaul - now delegates model operations to pluggable <code>BaseInferenceBackend</code> implementations.</li> <li>Inherits: <code>Generic[InputDataType, PredictionType, GroundTruthType]</code>, <code>ABC</code></li> <li>Function: Enforces a standard structure for model loading, prediction, evaluation, and visualization. It delegates all model operations to a <code>BaseInferenceBackend</code> instance, enabling support for multiple ML frameworks (PyTorch, ONNX). Outputs structured Pydantic prediction models for type safety and JSON serialization.</li> <li>Interfaces (Provided):</li> <li><code>__init__(self, settings: Settings, predictor_type: str, backend: BaseInferenceBackend, load_model: bool = False)</code>: Breaking Change - Initializes the predictor with a backend instance instead of weights manager.</li> <li><code>load_model(self) -&gt; None</code>: Delegates to <code>backend.load_model()</code> with enhanced error handling.</li> <li><code>unload_model(self) -&gt; None</code>: Delegates to <code>backend.unload_model()</code>.</li> <li><code>predict(self, input_data: InputDataType, **kwargs: Any) -&gt; PredictionType</code>: Enhanced with automatic model loading and structured output conversion via <code>_convert_raw_to_prediction()</code>.</li> <li><code>predict_batch(self, input_data_batch: Sequence[InputDataType], show_progress: bool = False, **kwargs: Any) -&gt; list[PredictionType]</code>: Enhanced batch processing with progress tracking.</li> <li><code>evaluate(self, ground_truth: GroundTruthType, prediction: PredictionType | None = None, input_data: InputDataType | None = None, **predict_kwargs: Any) -&gt; dict[str, float]</code>: Evaluates a single prediction against a ground truth.</li> <li><code>evaluate_batch(self, ground_truth_batch: list[GroundTruthType], predictions_batch: list[PredictionType] | None = None, input_data_batch: list[InputDataType] | None = None, num_workers: int = 4, show_progress: bool = True, **predict_kwargs) -&gt; dict[str, float]</code>: Evaluates on a batch of items using parallel processing.</li> <li><code>visualize(self, input_data: InputDataType, predictions: PredictionType, save_path: str | Path | None = None) -&gt; np.ndarray</code> (abstract): Visualizes predictions on the input data.</li> <li><code>get_model_info(self) -&gt; dict[str, Any]</code>: Gets information about the loaded model from the backend.</li> <li><code>model_context(self)</code> (context manager): Temporarily loads the model for a block of code.</li> <li><code>config</code> (property) <code>-&gt; PredictorConfig</code>: Gets the predictor's Pydantic configuration model.</li> <li><code>model_loaded</code> (property) <code>-&gt; bool</code>: Changed - Returns <code>self.backend.is_loaded</code> instead of internal state.</li> <li><code>__call__(self, input_data: InputDataType, **kwargs: Any) -&gt; PredictionType</code>: Convenience method for <code>predict()</code>.</li> <li><code>_convert_raw_to_prediction(self, raw_prediction: Any) -&gt; PredictionType</code> (abstract): New Required Method - Converts raw backend output to structured Pydantic prediction models.</li> <li><code>_evaluate_from_prediction(self, prediction: PredictionType, ground_truth: GroundTruthType) -&gt; dict[str, float]</code> (abstract): Core metric calculation logic.</li> <li>Interfaces (Used):</li> <li><code>core.settings.Settings</code></li> <li><code>core.base_inference_backend.BaseInferenceBackend</code></li> <li><code>core.config_models.PredictorConfig</code></li> <li><code>core.prediction_models.*</code> (Pydantic prediction models)</li> <li>Data: <code>settings</code>, <code>predictor_type</code>, <code>backend</code>.</li> <li>Migration Notes: </li> <li>Breaking Change: Constructor signature changed - requires <code>backend</code> parameter instead of <code>weights_manager</code></li> <li>New Abstract Method: Subclasses must implement <code>_convert_raw_to_prediction()</code> method</li> <li>Removed Methods: <code>_load_model()</code> and <code>model_path</code> property removed - now handled by backends</li> </ul>"},{"location":"dev_docs/architecture/#412-corebase_inference_backendbaseinferencebackend","title":"4.1.2 <code>core.base_inference_backend.BaseInferenceBackend</code>","text":"<ul> <li>Identification: <code>core.base_inference_backend.BaseInferenceBackend</code></li> <li>Purpose: New Architecture Component - Abstract base class for all ML framework backends, enabling pluggable support for PyTorch, ONNX, and other inference engines.</li> <li>Inherits: <code>Generic[InputDataType, PredictionType]</code>, <code>ABC</code></li> <li>Function: Defines the contract for model loading, inference, and resource management across different ML frameworks. Enables the library's flexible installation profiles and deployment modes.</li> <li>Interfaces (Provided):</li> <li><code>__init__(self, predictor_type: str)</code>: Initializes the backend with predictor type information.</li> <li><code>load_model(self, **kwargs: Any) -&gt; None</code> (abstract): Loads the model into memory using the specific ML framework.</li> <li><code>predict(self, input_data: InputDataType, **kwargs: Any) -&gt; PredictionType</code> (abstract): Performs inference on a single input.</li> <li><code>predict_batch(self, input_data_batch: list[InputDataType], show_progress: bool = False, **kwargs: Any) -&gt; list[PredictionType]</code>: Performs batch inference with optional progress tracking.</li> <li><code>unload_model(self) -&gt; None</code> (abstract): Unloads the model to free memory.</li> <li><code>is_loaded(self) -&gt; bool</code> (abstract): Checks if the model is currently loaded.</li> <li>Interfaces (Used):</li> <li>Framework-specific libraries (PyTorch, ONNX Runtime, etc.)</li> <li><code>core.settings.Settings</code> (via concrete implementations)</li> <li>Data: <code>predictor_type</code>, framework-specific model objects.</li> <li>Concrete Implementations:</li> <li><code>predictors.backends.classifier._fastai.ClassifierFastAIBackend</code>: PyTorch/FastAI-based classification</li> <li><code>predictors.backends.classifier._onnx.ClassifierONNXBackend</code>: ONNX-based classification</li> <li><code>predictors.backends.detector._yolo.DetectorYOLOBackend</code>: YOLO-based detection</li> <li><code>predictors.backends.segmenter._sam.SegmenterSAMBackend</code>: SAM-based segmentation</li> </ul>"},{"location":"dev_docs/architecture/#413-coreprediction_models","title":"4.1.3 <code>core.prediction_models</code>","text":"<ul> <li>Identification: <code>core.prediction_models</code></li> <li>Purpose: New Architecture Component - Pydantic models for structured, type-safe prediction outputs that replace the previous tuple-based formats.</li> <li>Function: Provides JSON-serializable, validated prediction outputs with convenient access methods. Enables consistent API responses across all predictor types.</li> <li>Key Models:</li> <li><code>BoundingBox</code>: Represents detection bounding boxes with <code>to_numpy()</code> conversion method.</li> <li><code>Detection</code>: Single detection result with bounding box, confidence, and optional class information.</li> <li><code>DetectionPrediction</code>: Container for multiple detections with metadata.</li> <li><code>Classification</code>: Single classification result with species name and confidence score.</li> <li><code>ClassificationPrediction</code>: Container for multiple classifications with <code>top_prediction()</code> convenience method.</li> <li><code>SegmentationPrediction</code>: Container for segmentation masks and metadata.</li> <li>Benefits:</li> <li>Type Safety: Full type hints and validation</li> <li>JSON Serialization: Direct conversion to/from JSON for API responses</li> <li>Convenience Methods: Easy access to common operations like <code>top_prediction()</code></li> <li>Backward Compatibility: Can be converted to legacy tuple formats when needed</li> </ul>"},{"location":"dev_docs/architecture/#414-corebase_providerbaseprovider","title":"4.1.4 <code>core.base_provider.BaseProvider</code>","text":"<ul> <li>Identification: <code>core.base_provider.BaseProvider</code></li> <li>Purpose: Abstract base class for all data and model providers.</li> <li>Inherits: <code>ABC</code></li> <li>Function: Defines a standard contract for downloading datasets and model weights from external or internal sources.</li> <li>Interfaces (Provided):</li> <li><code>download_dataset(self, dataset_name: str, save_dir: str | None = None, *args: Any, **kwargs: Any) -&gt; Path</code> (abstract): Downloads a dataset.</li> <li><code>download_model_weights(self, model_type: str, *args: Any, **kwargs: Any) -&gt; Path</code> (abstract): Downloads model weights.</li> <li><code>get_provider_name(self) -&gt; str</code> (abstract): Gets the unique name of the provider.</li> <li><code>load_dataset(self, dataset_path: str | Path, **kwargs: Any) -&gt; Any</code> (abstract): Loads a dataset from a local path.</li> <li>Data: N/A (abstract class).</li> </ul>"},{"location":"dev_docs/architecture/#413-coreconfig_managerconfigmanager","title":"4.1.3 <code>core.config_manager.ConfigManager</code>","text":"<ul> <li>Identification: <code>core.config_manager.ConfigManager</code></li> <li>Purpose: Handles loading, merging, and validating configurations for the library.</li> <li>Function: Implements a robust loading strategy: 1. Loads default YAML configurations bundled with the library. 2. Loads user-provided YAML configurations. 3. Merges the user's configuration on top of the defaults. 4. Validates the final merged configuration against the <code>CulicidaeLabConfig</code> Pydantic model. It also provides a utility to instantiate objects from their configuration definitions.</li> <li>Interfaces (Provided):</li> <li><code>__init__(self, user_config_dir: str | Path | None = None)</code>: Initializes the manager.</li> <li><code>get_config(self) -&gt; CulicidaeLabConfig</code>: Returns the fully validated Pydantic configuration object.</li> <li><code>instantiate_from_config(self, config_obj: Any, **kwargs: Any) -&gt; Any</code>: Instantiates a Python object from its Pydantic config model, which must contain a <code>target</code> field.</li> <li><code>save_config(self, file_path: str | Path) -&gt; None</code>: Saves the current configuration state to a YAML file.</li> <li>Interfaces (Used):</li> <li><code>core.config_models.CulicidaeLabConfig</code> and other Pydantic models.</li> <li><code>PyYAML</code> library (implicitly).</li> <li>Data: <code>user_config_dir</code>, <code>default_config_path</code>, <code>config</code> (a <code>CulicidaeLabConfig</code> instance).</li> </ul>"},{"location":"dev_docs/architecture/#414-coreconfig_modelspy","title":"4.1.4 <code>core.config_models.py</code>","text":"<ul> <li>Identification: <code>core.config_models.py</code></li> <li>Purpose: Defines the Pydantic models that represent the entire application's configuration structure.</li> <li>Function: Provides data validation, type safety, and a clear structure for all configuration sections, ensuring robustness and predictability.</li> <li>Key Models (Provided):</li> <li><code>CulicidaeLabConfig</code>: The root model for the entire configuration.</li> <li><code>PredictorConfig</code>: Defines the configuration for a single predictor, including its class (<code>target</code>), model path, and other parameters.</li> <li><code>ProviderConfig</code>: Defines the configuration for a data provider (e.g., Hugging Face, Roboflow).</li> <li><code>DatasetConfig</code>: Defines the configuration for a specific dataset.</li> <li><code>SpeciesModel</code>: Defines the configuration for species data, including class mappings and metadata.</li> <li><code>AppSettings</code>: Core application settings (e.g., environment, log level).</li> <li><code>ProcessingConfig</code>: General processing parameters (e.g., batch size, device).</li> <li><code>VisualizationConfig</code>: Settings for visualizing model outputs.</li> </ul>"},{"location":"dev_docs/architecture/#415-coreprovider_serviceproviderservice","title":"4.1.5 <code>core.provider_service.ProviderService</code>","text":"<ul> <li>Identification: <code>core.provider_service.ProviderService</code></li> <li>Purpose: Manages the instantiation and lifecycle of data providers.</li> <li>Function: Acts as a factory and cache for provider instances. It uses the application <code>Settings</code> to find the configuration for a requested provider, instantiates it using <code>ConfigManager</code>, and stores it for reuse.</li> <li>Interfaces (Provided):</li> <li><code>__init__(self, settings: Settings)</code>: Initializes the service.</li> <li><code>get_provider(self, provider_name: str) -&gt; BaseProvider</code>: Retrieves an instantiated provider by its name.</li> <li>Interfaces (Used):</li> <li><code>core.settings.Settings</code></li> <li><code>core.base_provider.BaseProvider</code></li> <li>Data: <code>_settings</code>, <code>_providers</code> (as a cache).</li> </ul>"},{"location":"dev_docs/architecture/#416-coreresource_managerresourcemanager","title":"4.1.6 <code>core.resource_manager.ResourceManager</code>","text":"<ul> <li>Identification: <code>core.resource_manager.ResourceManager</code></li> <li>Purpose: Centralized resource management for models, datasets, and temporary files, with cross-platform compatibility.</li> <li>Function: Manages application resource directories (models, datasets, cache, temp), provides standardized path generation, temporary workspace management (including an auto-cleaning context manager), file cleanup utilities, checksum creation/verification, and disk usage reporting.</li> <li>Interfaces (Provided):</li> <li><code>__init__(self, app_name: str | None = None, custom_base_dir: str | Path | None = None)</code>: Initializes resource paths.</li> <li><code>get_model_path(self, model_name: str, create_if_missing: bool = True) -&gt; Path</code>: Gets a standardized path for a specific model.</li> <li><code>get_dataset_path(self, dataset_name: str, create_if_missing: bool = True) -&gt; Path</code>: Gets a standardized path for a specific dataset.</li> <li><code>get_cache_path(self, cache_name: str, create_if_missing: bool = True) -&gt; Path</code>: Gets a path for cache files.</li> <li><code>create_temp_workspace(self, prefix: str = \"workspace\", suffix: str = \"\") -&gt; Path</code>: Creates a temporary workspace directory.</li> <li><code>temp_workspace(self, prefix: str = \"workspace\", suffix: str = \"\")</code> (context manager): Creates a temporary workspace that is automatically deleted on exit.</li> <li><code>clean_temp_workspace(self, workspace_path: Path, force: bool = False) -&gt; None</code>: Manually cleans a temporary workspace.</li> <li><code>clean_old_files(self, days: int = 5, include_cache: bool = True) -&gt; dict[str, int]</code>: Cleans up old download and temporary files.</li> <li><code>get_disk_usage(self) -&gt; dict[str, dict[str, int | str]]</code>: Gets disk usage statistics for all managed directories.</li> <li><code>create_checksum(self, file_path: str | Path, algorithm: str = \"md5\") -&gt; str</code>: Creates a checksum for a file.</li> <li><code>verify_checksum(self, file_path: str | Path, expected_checksum: str, algorithm: str = \"md5\") -&gt; bool</code>: Verifies a file's checksum.</li> <li><code>get_all_directories(self) -&gt; dict[str, Path]</code>: Gets all managed directories.</li> <li>Data: <code>app_name</code>, <code>user_data_dir</code>, <code>user_cache_dir</code>, <code>temp_dir</code>, <code>model_dir</code>, <code>dataset_dir</code>, <code>downloads_dir</code>.</li> </ul>"},{"location":"dev_docs/architecture/#417-coresettingssettings","title":"4.1.7 <code>core.settings.Settings</code>","text":"<ul> <li>Identification: <code>core.settings.Settings</code></li> <li>Purpose: A user-friendly facade for all configuration management, providing a simple and stable interface to access configuration values, resource directories, and application settings.</li> <li>Function: This class acts as a high-level interface that delegates complex operations to <code>ConfigManager</code> and <code>ResourceManager</code>. It is designed as a singleton, accessible via the <code>get_settings</code> function, ensuring a single, consistent source of configuration throughout the application.</li> <li>Interfaces (Provided):</li> <li><code>__init__(self, config_dir: str | Path | None = None)</code>: Initializes the Settings facade by setting up the underlying managers.</li> <li><code>get_config(self, path: str | None = None, default: Any = None) -&gt; Any</code>: Gets a configuration value using a dot-separated path.</li> <li><code>set_config(self, path: str, value: Any) -&gt; None</code>: Sets a configuration value in memory.</li> <li><code>save_config(self, file_path: str | Path | None = None) -&gt; None</code>: Saves the current in-memory configuration to a YAML file.</li> <li><code>instantiate_from_config(self, config_path: str, **kwargs: Any) -&gt; Any</code>: A convenience method to instantiate an object from its configuration path.</li> <li><code>get_dataset_path(self, dataset_type: str) -&gt; Path</code>: Gets the path for a specific dataset directory.</li> <li><code>get_model_weights_path(self, model_type: str) -&gt; Path</code>: Gets the configured path to a model's weights file.</li> <li><code>get_api_key(self, provider: str) -&gt; str | None</code>: Gets an API key for a specified provider.</li> <li><code>temp_workspace(self, prefix: str = \"workspace\")</code> (context manager): Provides a temporary workspace via the <code>ResourceManager</code>.</li> <li><code>model_dir</code> / <code>weights_dir</code> (property) <code>-&gt; Path</code>: The directory for model weights.</li> <li><code>dataset_dir</code> (property) <code>-&gt; Path</code>: The directory for datasets.</li> <li><code>cache_dir</code> (property) <code>-&gt; Path</code>: The cache directory.</li> <li><code>config_dir</code> (property) <code>-&gt; Path</code>: The active user configuration directory.</li> <li><code>species_config</code> (property) <code>-&gt; SpeciesConfig</code>: Provides lazy-loaded access to the <code>SpeciesConfig</code> helper.</li> <li>Interfaces (Used):</li> <li><code>core.config_manager.ConfigManager</code></li> <li><code>core.resource_manager.ResourceManager</code></li> <li><code>core.species_config.SpeciesConfig</code></li> <li>Data: <code>_instance</code>, <code>_lock</code>, <code>_initialized</code>.</li> </ul>"},{"location":"dev_docs/architecture/#418-coresettingsget_settings","title":"4.1.8 <code>core.settings.get_settings</code>","text":"<ul> <li>Identification: <code>core.settings.get_settings</code></li> <li>Purpose: Factory function to get the singleton <code>Settings</code> instance.</li> <li>Function: This is the primary entry point for accessing all application settings. It ensures that the <code>Settings</code> class is initialized only once.</li> <li>Interfaces (Provided):</li> <li><code>get_settings(config_dir: str | Path | None = None) -&gt; Settings</code>: Returns the <code>Settings</code> singleton instance.</li> </ul>"},{"location":"dev_docs/architecture/#419-corespecies_configspeciesconfig","title":"4.1.9 <code>core.species_config.SpeciesConfig</code>","text":"<ul> <li>Identification: <code>core.species_config.SpeciesConfig</code></li> <li>Purpose: A user-friendly facade for accessing species-specific configuration.</li> <li>Function: This class acts as an adapter, taking the validated <code>SpeciesModel</code> Pydantic object from the main configuration and providing simple, direct methods for querying species data, such as mapping between class indices and names or retrieving detailed metadata.</li> <li>Interfaces (Provided):</li> <li><code>__init__(self, config: SpeciesModel)</code>: Initializes with a validated <code>SpeciesModel</code> Pydantic object.</li> <li><code>species_map</code> (property) <code>-&gt; dict[int, str]</code>: Gets the mapping of class indices to full species names.</li> <li><code>get_species_metadata(self, species_name: str) -&gt; dict[str, Any] | None</code>: Gets detailed metadata for a specific species.</li> <li><code>get_species_by_index(self, index: int) -&gt; str | None</code>: Gets the full species name by its class index.</li> <li><code>get_index_by_species(self, species_name: str) -&gt; int | None</code>: Gets the class index for a given species name.</li> <li><code>list_species_names(self) -&gt; list[str]</code>: Returns a list of all configured species names.</li> <li>Interfaces (Used):</li> <li><code>core.config_models.SpeciesModel</code></li> <li>Data: <code>_config</code>, <code>_species_map</code>, <code>_reverse_species_map</code>, <code>_metadata_store</code>.</li> </ul>"},{"location":"dev_docs/architecture/#4110-coreutils","title":"4.1.10 <code>core.utils</code>","text":"<ul> <li>Identification: <code>core.utils</code></li> <li>Purpose: A collection of standalone utility functions used throughout the library.</li> <li>Functions (Provided):</li> <li><code>download_file(url: str, destination: str | Path | None = None, downloads_dir: str | Path | None = None, progress_callback: Callable | None = None, chunk_size: int = 8192, timeout: int = 30, desc: str | None = None) -&gt; Path</code>: Downloads a file from a URL with options for progress tracking, chunking, and timeout, returning the path to the downloaded file.</li> <li><code>str_to_bgr(str_color: str) -&gt; tuple[int, int, int]</code>: Converts a hexadecimal color string (e.g., '#RRGGBB') into a BGR integer tuple suitable for use with libraries like OpenCV.</li> </ul>"},{"location":"dev_docs/architecture/#4111-coreweights_manager_protocolweightsmanagerprotocol","title":"4.1.11 <code>core.weights_manager_protocol.WeightsManagerProtocol</code>","text":"<ul> <li>Identification: <code>core.weights_manager_protocol.WeightsManagerProtocol</code></li> <li>Purpose: Defines the protocol (interface) for any class that manages model weights.</li> <li>Type: <code>typing.Protocol</code></li> <li>Function: Ensures that core components like <code>BasePredictor</code> can work with any weights manager without depending on its concrete implementation. This promotes loose coupling and allows for different weight management strategies (e.g., local file system, cloud storage).</li> <li>Interfaces (Provided):</li> <li><code>ensure_weights(self, predictor_type: str) -&gt; Path</code>: Ensures weights for a given predictor type are available locally, potentially downloading them if missing, and returns the local path to the weights file.</li> </ul>"},{"location":"dev_docs/architecture/#42-datasets-module-detailed-design","title":"4.2 <code>datasets</code> Module Detailed Design","text":"<p>The <code>datasets</code> module is responsible for managing access to and loading of datasets based on the central application configuration. It acts as an intermediary between the user code and the underlying data providers.</p> <p>Project Structure:</p> <pre><code>datasets\n\u251c\u2500\u2500 __init__.py\n\u2514\u2500\u2500 datasets_manager.py\n</code></pre>"},{"location":"dev_docs/architecture/#421-datasetsdatasets_managerdatasetsmanager","title":"4.2.1 <code>datasets.datasets_manager.DatasetsManager</code>","text":"<ul> <li>Identification: <code>datasets.datasets_manager.DatasetsManager</code></li> <li>Purpose: Manages access, loading, and caching of configured datasets.</li> <li>Function: Provides a high-level interface that uses the global <code>Settings</code> for configuration and a <code>ProviderService</code> for the actual data loading. This decouples the logic of what datasets are available (defined in config) from how they are loaded and sourced (handled by providers). It maintains a session-local cache of downloaded dataset paths to avoid repeated downloads.</li> <li>Interfaces (Provided):</li> <li><code>__init__(self, settings: Settings, provider_service: ProviderService)</code>: Initializes the manager with its dependencies.</li> <li><code>get_dataset_info(self, dataset_name: str) -&gt; DatasetConfig</code>: Retrieves the Pydantic configuration model for a specific dataset.</li> <li><code>list_datasets(self) -&gt; list[str]</code>: Lists all available dataset names from the global configuration.</li> <li><code>list_loaded_datasets(self) -&gt; list[str]</code>: Lists all datasets that have been loaded (downloaded and cached) during the current session.</li> <li><code>load_dataset(self, dataset_name: str, split: str | None = None, **kwargs: Any) -&gt; Any</code>: Loads a specific dataset split. It uses the configured provider to download the dataset if it's not already cached, and then loads it into memory. The return type depends on the provider's implementation.</li> <li>Interfaces (Used):</li> <li><code>core.settings.Settings</code>: To access dataset configurations.</li> <li><code>core.provider_service.ProviderService</code>: To get the correct provider instance for downloading and loading data.</li> <li><code>core.config_models.DatasetConfig</code>: As a return type for <code>get_dataset_info</code>.</li> <li>Data: <code>settings</code>, <code>provider_service</code>, <code>loaded_datasets</code> (internal cache).</li> </ul>"},{"location":"dev_docs/architecture/#43-providers-module-detailed-design","title":"4.3 <code>providers</code> Module Detailed Design","text":"<p>The <code>providers</code> module contains concrete implementations of the <code>BaseProvider</code> interface. Each class in this module is responsible for interacting with a specific external data source (like Hugging Face) to download datasets or model weights.</p> <p>Project Structure:</p> <pre><code>providers\n\u251c\u2500\u2500 __init__.py\n\u2514\u2500\u2500 huggingface_provider.py\n</code></pre>"},{"location":"dev_docs/architecture/#431-providershuggingface_providerhuggingfaceprovider","title":"4.3.1 <code>providers.huggingface_provider.HuggingFaceProvider</code>","text":"<ul> <li>Identification: <code>providers.huggingface_provider.HuggingFaceProvider</code></li> <li>Inherits: <code>core.base_provider.BaseProvider</code></li> <li>Purpose: Provider for downloading and managing HuggingFace datasets and models.</li> <li>Function: This class implements the <code>BaseProvider</code> interface to interact with the Hugging Face Hub. It fetches dataset metadata, downloads full datasets or specific splits, and downloads model weights. It is designed to be instantiated by the <code>ProviderService</code>, which injects the main <code>Settings</code> object and provider-specific configuration (like <code>dataset_url</code> and <code>api_key</code>).</li> <li>Interfaces (Provided):</li> <li><code>__init__(self, settings: Settings, dataset_url: str, **kwargs: Any) -&gt; None</code>: Initializes the provider with the global settings and its specific configuration.</li> <li><code>download_dataset(self, dataset_name: str, save_dir: str | None = None, split: str | None = None, *args: Any, **kwargs: Any) -&gt; Path</code>: Downloads a dataset from the Hugging Face Hub to a local directory.</li> <li><code>download_model_weights(self, model_type: str, *args: Any, **kwargs: Any) -&gt; Path</code>: Downloads and caches model weights from the Hugging Face Hub based on configuration.</li> <li><code>get_dataset_metadata(self, dataset_name: str) -&gt; dict[str, Any]</code>: Fetches metadata for a specific dataset from the Hub.</li> <li><code>get_provider_name(self) -&gt; str</code>: Returns the provider's name: <code>\"huggingface\"</code>.</li> <li><code>load_dataset(self, dataset_path: str | Path, split: str | None = None, **kwargs) -&gt; Any</code>: Loads a Hugging Face dataset from a local disk path, which is typically the output of <code>download_dataset</code>.</li> <li>Interfaces (Used):</li> <li><code>core.base_provider.BaseProvider</code> (inheritance).</li> <li><code>core.settings.Settings</code> (for configuration, resource paths, and API keys).</li> <li><code>huggingface_hub</code> library (for downloading models and datasets).</li> <li><code>datasets</code> library (for loading datasets from disk).</li> <li><code>requests</code> library (for fetching metadata).</li> <li>Data: <code>provider_name</code>, <code>settings</code>, <code>dataset_url</code>, <code>api_key</code>.</li> </ul>"},{"location":"dev_docs/architecture/#44-predictors-module-detailed-design","title":"4.4 <code>predictors</code> Module Detailed Design","text":"<p>The <code>predictors</code> module contains concrete implementations of machine learning models for various mosquito analysis tasks, inheriting from <code>core.base_predictor.BasePredictor</code>. Major architectural overhaul - now features a pluggable backend system with intelligent backend selection and support for multiple ML frameworks.</p> <p>Project Structure:</p> <pre><code>predictors\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 classifier.py\n\u251c\u2500\u2500 detector.py\n\u251c\u2500\u2500 segmenter.py\n\u251c\u2500\u2500 backend_factory.py          # Intelligent backend selection\n\u2514\u2500\u2500 backends/                   # Pluggable backend implementations\n    \u251c\u2500\u2500 __init__.py\n    \u251c\u2500\u2500 classifier/\n    \u2502   \u251c\u2500\u2500 _fastai.py         # PyTorch/FastAI backend\n    \u2502   \u2514\u2500\u2500 _onnx.py           # ONNX backend\n    \u251c\u2500\u2500 detector/\n    \u2502   \u2514\u2500\u2500 _yolo.py           # YOLO backend\n    \u2514\u2500\u2500 segmenter/\n        \u2514\u2500\u2500 _sam.py            # SAM backend\n</code></pre>"},{"location":"dev_docs/architecture/#441-predictorsbackend_factorybackendfactory","title":"4.4.1 <code>predictors.backend_factory.BackendFactory</code>","text":"<ul> <li>Identification: <code>predictors.backend_factory.create_backend</code></li> <li>Purpose: New Architecture Component - Intelligent factory function for creating appropriate backend instances based on environment, configuration, and user preferences.</li> <li>Function: Implements a clear precedence order for backend selection: 1) Code override (mode parameter), 2) Configuration override (YAML), 3) Environment auto-detection. Enables the library's flexible installation profiles and graceful handling of different deployment scenarios.</li> <li>Interfaces (Provided):</li> <li><code>create_backend(settings: Settings, predictor_type: str, mode: str | None = None) -&gt; BaseInferenceBackend</code>: Creates and returns an appropriate backend instance.</li> <li>Selection Logic:</li> <li>Code Override: <code>mode='serve'</code> forces ONNX backend, <code>mode='experiments'</code> forces PyTorch backend</li> <li>Configuration Override: Checks predictor config for backend setting</li> <li>Environment Auto-Detection: Uses PyTorch if available, falls back to ONNX</li> <li>Interfaces (Used):</li> <li><code>core.settings.Settings</code></li> <li><code>core.base_inference_backend.BaseInferenceBackend</code></li> <li>Backend implementations in <code>predictors.backends.*</code></li> <li>Data: N/A (stateless factory function).</li> <li>Error Handling: Raises <code>RuntimeError</code> if PyTorch backend requested but not installed, <code>ValueError</code> if backend cannot be resolved.</li> </ul>"},{"location":"dev_docs/architecture/#442-predictorsclassifierset_posix_windows-context-manager","title":"4.4.2 <code>predictors.classifier.set_posix_windows</code> (Context Manager)","text":"<ul> <li>Identification: <code>predictors.classifier.set_posix_windows</code></li> <li>Purpose: A context manager to handle path compatibility issues when loading FastAI models trained on POSIX systems (Linux/macOS) onto a Windows system.</li> <li>Function: It temporarily patches <code>pathlib.PosixPath</code> to behave like <code>pathlib.WindowsPath</code> on Windows systems, allowing the model's pickled path objects to be deserialized correctly.</li> <li>Interfaces (Provided):</li> <li><code>@contextmanager def set_posix_windows()</code></li> <li>Data: N/A (functional).</li> </ul>"},{"location":"dev_docs/architecture/#443-predictorsclassifiermosquitoclassifier","title":"4.4.3 <code>predictors.classifier.MosquitoClassifier</code>","text":"<ul> <li>Identification: <code>predictors.classifier.MosquitoClassifier</code></li> <li>Inherits: <code>core.base_predictor.BasePredictor[np.ndarray, ClassificationPrediction, ClassificationGroundTruthType]</code></li> <li>Purpose: Classifies mosquito species from an image using pluggable backend implementations (PyTorch/FastAI or ONNX).</li> <li>Function: Major architectural update - Now delegates model operations to backend implementations while providing structured Pydantic prediction outputs. Automatically selects appropriate backend based on environment and configuration.</li> <li>Interfaces (Provided):</li> <li><code>__init__(self, settings: Settings, backend: BaseInferenceBackend | None = None, mode: str | None = None, load_model: bool = False) -&gt; None</code>: Enhanced - Can accept explicit backend or automatically create one via BackendFactory.</li> <li><code>predict(self, input_data: np.ndarray, **kwargs: Any) -&gt; ClassificationPrediction</code>: Enhanced - Returns structured <code>ClassificationPrediction</code> Pydantic model instead of tuples.</li> <li><code>predict_batch(self, input_data_batch: list[np.ndarray], show_progress: bool = False, **kwargs: Any) -&gt; list[ClassificationPrediction]</code>: Enhanced batch processing.</li> <li><code>visualize(self, input_data: np.ndarray, predictions: ClassificationPrediction, save_path: str | Path | None = None) -&gt; np.ndarray</code>: Overlays top classification results onto an image.</li> <li><code>get_species_names(self) -&gt; list[str]</code>: Gets a sorted list of all species names known to the classifier.</li> <li><code>get_class_index(self, species_name: str) -&gt; int | None</code>: Retrieves the class index for a given species name.</li> <li><code>_convert_raw_to_prediction(self, raw_prediction: Any) -&gt; ClassificationPrediction</code>: New Required Method - Converts raw backend output to structured Pydantic model.</li> <li>Interfaces (Used):</li> <li><code>core.base_predictor.BasePredictor</code> (inheritance).</li> <li><code>core.settings.Settings</code> (for configuration).</li> <li><code>predictors.backend_factory.create_backend</code> (for automatic backend selection).</li> <li><code>core.prediction_models.ClassificationPrediction</code> (structured output).</li> <li>Backend implementations via <code>BaseInferenceBackend</code> interface.</li> <li>Data: <code>settings</code>, <code>backend</code> (BaseInferenceBackend instance).</li> <li>Backend Support:</li> <li>PyTorch/FastAI Backend: Full development capabilities with training support</li> <li>ONNX Backend: Optimized inference for production deployments</li> </ul>"},{"location":"dev_docs/architecture/#443-predictorsdetectormosquitodetector","title":"4.4.3 <code>predictors.detector.MosquitoDetector</code>","text":"<ul> <li>Identification: <code>predictors.detector.MosquitoDetector</code></li> <li>Inherits: <code>core.base_predictor.BasePredictor[DetectionPredictionType, DetectionGroundTruthType]</code></li> <li>Purpose: Detects mosquitos in images using a YOLO model.</li> <li>Function: Loads a YOLO model and implements the full prediction lifecycle for object detection. It predicts bounding boxes on single or batches of images (leveraging YOLO's native batching), visualizes the results, and evaluates detection performance (precision, recall, AP, mean IoU).</li> <li>Interfaces (Provided):</li> <li><code>__init__(self, settings: Settings, load_model: bool = False) -&gt; None</code>: Initializes the detector.</li> <li><code>predict(self, input_data: np.ndarray, **kwargs: Any) -&gt; DetectionPredictionType</code>: Detects mosquitos in a single image, returning a list of bounding boxes <code>(cx, cy, w, h, conf)</code>.</li> <li><code>predict_batch(self, input_data_batch: list[np.ndarray], show_progress: bool = True, **kwargs: Any) -&gt; list[DetectionPredictionType]</code>: Detects mosquitos in a batch of images.</li> <li><code>visualize(self, input_data: np.ndarray, predictions: DetectionPredictionType, save_path: str | Path | None = None) -&gt; np.ndarray</code>: Draws predicted bounding boxes on an image.</li> <li>Interfaces (Used):</li> <li><code>core.base_predictor.BasePredictor</code> (inheritance).</li> <li><code>core.settings.Settings</code> (for configuration).</li> <li>Ultralytics YOLO library.</li> <li><code>numpy</code>, <code>cv2</code> (OpenCV for visualization).</li> <li>Data: <code>confidence_threshold</code>, <code>iou_threshold</code>, <code>max_detections</code>, <code>model</code> (YOLO model instance).</li> </ul>"},{"location":"dev_docs/architecture/#444-predictorsmodel_weights_managermodelweightsmanager","title":"4.4.4 <code>predictors.model_weights_manager.ModelWeightsManager</code>","text":"<ul> <li>Identification: <code>predictors.model_weights_manager.ModelWeightsManager</code></li> <li>Implements: <code>core.weights_manager_protocol.WeightsManagerProtocol</code></li> <li>Purpose: Manages the download and local availability of model weights.</li> <li>Function: Acts as the bridge between a predictor needing its weights and the <code>ProviderService</code> that can download them. When a predictor requests its weights, this manager checks if the file already exists locally. If not, it uses the configured provider to download the weights and returns the final, verified local path.</li> <li>Interfaces (Provided):</li> <li><code>__init__(self, settings: Settings, provider_service: ProviderService)</code>: Initializes with dependencies.</li> <li><code>ensure_weights(self, model_type: str) -&gt; Path</code>: Ensures model weights exist locally, downloading them if needed, and returns the path.</li> <li>Interfaces (Used):</li> <li><code>core.settings.Settings</code> (to get predictor configurations).</li> <li><code>core.provider_service.ProviderService</code> (to get a provider instance for downloading).</li> <li><code>core.base_provider.BaseProvider</code> (via the provider service).</li> <li>Data: <code>settings</code>, <code>provider_service</code>.</li> </ul>"},{"location":"dev_docs/architecture/#445-predictorssegmentermosquitosegmenter","title":"4.4.5 <code>predictors.segmenter.MosquitoSegmenter</code>","text":"<ul> <li>Identification: <code>predictors.segmenter.MosquitoSegmenter</code></li> <li>Inherits: <code>core.base_predictor.BasePredictor[SegmentationPredictionType, SegmentationGroundTruthType]</code></li> <li>Purpose: Segments mosquitos in images using the SAM2 model.</li> <li>Function: Loads a SAM2 model and provides methods to generate segmentation masks. It can perform whole-image segmentation or be guided by bounding boxes from a detector. It also implements visualization of masks and evaluation based on metrics like IoU.</li> <li>Interfaces (Provided):</li> <li><code>__init__(self, settings: Settings, load_model: bool = False) -&gt; None</code>: Initializes the segmenter.</li> <li><code>predict(self, input_data: np.ndarray, **kwargs: Any) -&gt; np.ndarray</code>: Generates a binary segmentation mask. Can be guided by <code>detection_boxes</code> provided in kwargs.</li> <li><code>visualize(self, input_data: np.ndarray, predictions: SegmentationPredictionType, save_path: str | Path | None = None) -&gt; np.ndarray</code>: Overlays the segmentation mask as a colored layer on the original image.</li> <li>Interfaces (Used):</li> <li><code>core.base_predictor.BasePredictor</code> (inheritance).</li> <li><code>core.settings.Settings</code> (for configuration).</li> <li><code>segment_anything</code> (SAM2) library and PyTorch.</li> <li><code>numpy</code>.</li> <li>Data: <code>model</code> (SAM2 model instance/predictor).</li> </ul>"},{"location":"dev_docs/architecture/#45-serve-module-detailed-design","title":"4.5 <code>serve</code> Module Detailed Design","text":"<p>The <code>serve</code> module provides a high-performance, production-optimized inference API designed for web services and applications requiring minimal latency. New architecture component that automatically uses ONNX backends and implements in-memory caching.</p> <p>Project Structure:</p> <pre><code>serve.py                    # High-performance production API\n</code></pre>"},{"location":"dev_docs/architecture/#451-serveserve","title":"4.5.1 <code>serve.serve</code>","text":"<ul> <li>Identification: <code>serve.serve</code></li> <li>Purpose: New Production API - High-performance inference function optimized for production environments with automatic backend selection and in-memory caching.</li> <li>Function: Provides a single, unified interface for all prediction types while automatically selecting ONNX backends for optimal performance. Implements intelligent caching to eliminate model loading overhead on subsequent calls.</li> <li>Interfaces (Provided):</li> <li><code>serve(image: ImageInput, predictor_type: str = \"classifier\", **kwargs) -&gt; PredictionResult</code>: Runs prediction using specified predictor type in high-performance mode.</li> <li><code>clear_serve_cache() -&gt; None</code>: Clears the in-memory predictor cache and unloads models.</li> <li>Type Aliases:</li> <li><code>ImageInput</code>: Union of acceptable image input formats (np.ndarray, str, Path, PIL.Image, bytes)</li> <li><code>PredictionResult</code>: Union of structured prediction outputs (ClassificationPrediction, DetectionPrediction, SegmentationPrediction)</li> <li>Interfaces (Used):</li> <li>All predictor classes (<code>MosquitoClassifier</code>, <code>MosquitoDetector</code>, <code>MosquitoSegmenter</code>)</li> <li><code>core.settings.Settings</code></li> <li><code>core.prediction_models.*</code> (structured outputs)</li> <li>Data: Internal cache dictionary for predictor instances.</li> <li>Performance Features:</li> <li>Automatic ONNX Backend: Selects optimized ONNX backends for fastest inference</li> <li>In-Memory Caching: First call loads model, subsequent calls are near-instantaneous</li> <li>Unified Interface: Single function for all prediction types</li> <li>Type Safety: Structured Pydantic outputs with full type hints</li> <li>Use Cases:</li> <li>Web APIs: FastAPI/Flask endpoints with minimal latency</li> <li>Batch Processing: Efficient processing of large image sets</li> <li>Production Deployments: Optimized for serving environments</li> </ul>"},{"location":"dev_docs/architecture/#452-integration-examples","title":"4.5.2 Integration Examples","text":"<p>Web API Integration: <pre><code>from fastapi import FastAPI, UploadFile\nfrom culicidaelab.serve import serve\nimport json\n\napp = FastAPI()\n\n@app.post(\"/predict/{predictor_type}\")\nasync def predict(predictor_type: str, file: UploadFile):\n    image_bytes = await file.read()\n    result = serve(image_bytes, predictor_type=predictor_type)\n    return json.loads(result.model_dump_json())\n</code></pre></p> <p>Performance Comparison: - Traditional PyTorch: ~500ms per prediction (including model loading) - Serve API (first call): ~300ms (ONNX optimization + model loading) - Serve API (cached): ~50ms (10x faster with cached model)</p>"},{"location":"dev_docs/architecture/#5-traceability","title":"5. Traceability","text":"<p>This section establishes comprehensive traceability between the system's functional requirements, architectural objectives, and their corresponding implementation components. The traceability matrix demonstrates how each design decision directly addresses specific requirements and ensures complete coverage of the system's intended functionality.</p>"},{"location":"dev_docs/architecture/#51-requirements-to-components-mapping","title":"5.1 Requirements-to-Components Mapping","text":"<p>The following table maps each functional requirement to its implementing components, providing clear visibility into how the architecture fulfills the system's objectives:</p> Functional Requirement Primary Component(s) Supporting Components Implementation Details Centralized Configuration Management <code>core.ConfigManager</code> <code>core.settings.Settings</code>, Pydantic models in <code>core.config_models</code> ConfigManager provides singleton access to configuration, while Settings handles environment-specific parameters and Pydantic models ensure type safety and validation Flexible Dataset Access &amp; Management <code>datasets.DatasetsManager</code> <code>providers</code> module, <code>core.BaseProvider</code>, <code>core.ProviderService</code> DatasetsManager orchestrates dataset operations, BaseProvider defines provider interface, concrete providers handle specific data sources Pluggable Backend Architecture <code>core.BaseInferenceBackend</code> <code>predictors.BackendFactory</code>, concrete backend implementations NEW - Enables support for multiple ML frameworks (PyTorch, ONNX) with intelligent backend selection based on environment and deployment needs Standardized Predictor Interface <code>core.BasePredictor</code> All predictor implementations, <code>BaseInferenceBackend</code> Enhanced - Abstract base class delegates model operations to pluggable backends while maintaining consistent API with structured Pydantic outputs Structured Prediction Outputs <code>core.prediction_models</code> All predictor implementations NEW - Pydantic models provide type-safe, JSON-serializable prediction outputs replacing previous tuple-based formats Species Classification <code>predictors.MosquitoClassifier</code> <code>core.BasePredictor</code>, backend implementations Enhanced - Implements species-specific classification with pluggable backend support (PyTorch/FastAI, ONNX) High-Performance Production API <code>serve.serve</code> All predictors, ONNX backends, in-memory caching NEW - Production-optimized API with automatic ONNX backend selection and intelligent caching for minimal latency Installation Flexibility <code>predictors.BackendFactory</code> Backend implementations, dependency management NEW - Supports lightweight serving installations (ONNX-only) and full development environments (PyTorch+ONNX) Object Detection <code>predictors.MosquitoDetector</code> <code>core.BasePredictor</code>, visualization utilities Provides bounding box detection with batch processing capabilities and integrated visualization Image Segmentation <code>predictors.MosquitoSegmenter</code> <code>core.BasePredictor</code>, post-processing utilities Implements pixel-level segmentation with support for multiple output formats and mask processing Efficient Batch Processing <code>predict_batch()</code> methods <code>core.BasePredictor</code>, resource management Optimized batch processing with memory management and progress tracking across all predictor types Result Visualization <code>visualize()</code> methods Plotting libraries,<code>core.BasePredictor</code> Consistent visualization interface with customizable output formats and annotation overlays Model Performance Evaluation <code>evaluate()</code> and <code>evaluate_batch()</code> Metrics calculation, validation utilities Comprehensive evaluation framework with standard metrics and custom evaluation protocols Resource Management <code>core.ResourceManager</code> File system utilities, path management Cross-platform resource handling with automatic directory creation and cleanup Model Weight Management <code>predictors.ModelWeightsManager</code> <code>core.WeightsManagerProtocol</code>, download utilities Automated model weight downloading, caching, and version management with integrity verification External Data Source Integration <code>core.BaseProvider</code> <code>providers.HuggingFaceProvider</code>, <code>core.ProviderService</code> Extensible provider system supporting multiple data sources with unified access patterns Species Metadata Handling <code>core.SpeciesConfig</code> Configuration system, validation Structured species information management with taxonomic validation and metadata enrichment Cross-Platform Compatibility All core modules Platform-specific utilities Consistent behavior across operating systems with platform-aware file handling"},{"location":"dev_docs/architecture/#52-architectural-objectives-traceability","title":"5.2 Architectural Objectives Traceability","text":"<p>The architecture addresses several implicit but critical objectives that ensure the system's long-term viability and usability:</p>"},{"location":"dev_docs/architecture/#521-modularity-and-extensibility","title":"5.2.1 Modularity and Extensibility","text":"<p>Objective: Enable easy addition of new predictors, data sources, and ML framework backends without modifying existing code.</p> <p>Implementation:</p> <ul> <li>Core Abstractions: <code>BasePredictor</code>, <code>BaseProvider</code>, <code>BaseInferenceBackend</code> define clear contracts</li> <li>Module Separation: Distinct <code>core</code>, <code>datasets</code>, <code>providers</code>, and <code>predictors</code> modules with minimal interdependencies</li> <li>Plugin Architecture: Provider system allows new data sources, backend system enables new ML frameworks</li> <li>Inheritance Hierarchy: Well-defined base classes enable new predictor types and backends with minimal boilerplate</li> <li>Factory Pattern: <code>BackendFactory</code> enables dynamic backend selection without code changes</li> </ul> <p>Verification: New mosquito species predictors can be added by subclassing <code>BasePredictor</code> without modifying existing components.</p>"},{"location":"dev_docs/architecture/#522-configuration-driven-behavior","title":"5.2.2 Configuration-Driven Behavior","text":"<p>Objective: Maximize system flexibility through external configuration rather than hard-coded values.</p> <p>Implementation:</p> <ul> <li>Centralized Settings: <code>core.ConfigManager</code> provides single source of configuration truth</li> <li>Environment Awareness: <code>core.Settings</code> adapts to different deployment environments</li> <li>Type Safety: Pydantic models in <code>core.config_models</code> ensure configuration validation</li> <li>Hierarchical Configuration: Support for global, module-specific, and instance-specific settings</li> </ul> <p>Verification: Users can modify system behavior through configuration files without code changes.</p>"},{"location":"dev_docs/architecture/#523-deployment-flexibility-and-performance-optimization","title":"5.2.3 Deployment Flexibility and Performance Optimization","text":"<p>Objective: Support multiple deployment scenarios from lightweight production serving to full development environments with optimal performance for each use case.</p> <p>Implementation:</p> <ul> <li>Pluggable Backend Architecture: <code>BaseInferenceBackend</code> enables switching between PyTorch (development) and ONNX (production) backends</li> <li>Intelligent Backend Selection: <code>BackendFactory</code> automatically chooses optimal backend based on environment and configuration</li> <li>Installation Profiles: Support for lightweight <code>[serve]</code> (ONNX-only, ~200MB) and full <code>[full]</code> (PyTorch+ONNX, ~2GB+) installations</li> <li>High-Performance Serving API: <code>serve.serve</code> provides production-optimized inference with automatic ONNX backend selection and in-memory caching</li> <li>Structured Outputs: Pydantic models enable efficient JSON serialization for web APIs while maintaining type safety</li> </ul> <p>Verification: Same codebase can be deployed in lightweight serving mode (ONNX-only) or full development mode (PyTorch+ONNX) with 10x+ performance improvements in production scenarios.</p>"},{"location":"dev_docs/architecture/#524-robust-error-handling-and-resource-management","title":"5.2.4 Robust Error Handling and Resource Management","text":"<p>Objective: Ensure system stability and proper resource cleanup under all conditions.</p> <p>Implementation:</p> <ul> <li>Resource Management: <code>core.ResourceManager</code> handles file system operations with proper cleanup</li> <li>Weight Management: <code>ModelWeightsManager</code> manages model files with integrity checking</li> <li>Provider Resilience: Data source failures are handled gracefully with fallback mechanisms</li> <li>Memory Management: Batch processing includes memory optimization and cleanup procedures</li> </ul> <p>Verification: System continues operating and properly cleans up resources even when individual components fail.</p>"},{"location":"dev_docs/architecture/#525-performance-optimization","title":"5.2.5 Performance Optimization","text":"<p>Objective: Provide efficient processing capabilities for both single predictions and batch operations with framework-specific optimizations.</p> <p>Implementation:</p> <ul> <li>Backend-Specific Optimization: PyTorch backends for development flexibility, ONNX backends for production performance</li> <li>Intelligent Caching: <code>serve.serve</code> implements in-memory predictor caching for near-instantaneous subsequent calls</li> <li>Batch Processing: All predictors implement optimized batch methods with memory management and progress tracking</li> <li>Lazy Loading: Models and datasets are loaded only when needed to minimize memory footprint</li> <li>Framework Selection: Automatic selection of optimal ML framework based on deployment scenario</li> <li>Resource Pooling: Shared resources are managed efficiently across multiple operations</li> </ul> <p>Verification: ONNX backends provide 10x+ performance improvements over PyTorch in production scenarios, while batch operations scale efficiently with dataset size.</p>"},{"location":"dev_docs/architecture/#526-developer-experience-and-usability","title":"5.2.6 Developer Experience and Usability","text":"<p>Objective: Provide intuitive APIs and comprehensive functionality for researchers and developers with enhanced type safety and modern development practices.</p> <p>Implementation:</p> <ul> <li>Consistent Interface: All predictors share common method signatures (predict, visualize, evaluate) with enhanced type hints</li> <li>Structured Outputs: Pydantic models provide type-safe, JSON-serializable results with convenient access methods</li> <li>Rich Visualization: Built-in visualization capabilities with customizable output formats</li> <li>Comprehensive Evaluation: Standard metrics and custom evaluation protocols</li> <li>Utility Functions: <code>list_models()</code> and <code>list_datasets()</code> for programmatic discovery</li> <li>Production-Ready API: <code>serve.serve</code> provides single-function access to all prediction types</li> <li>Documentation Integration: Code structure supports comprehensive documentation generation</li> <li>Modern Python Features: Full type hints, context managers, and async-compatible design</li> </ul> <p>Verification: New users can accomplish common tasks with minimal learning curve, while advanced users benefit from type safety and production-ready APIs.</p>"},{"location":"dev_docs/architecture/#53-cross-cutting-concerns-traceability","title":"5.3 Cross-Cutting Concerns Traceability","text":"<p>Several system-wide concerns are addressed through coordinated implementation across multiple components:</p>"},{"location":"dev_docs/architecture/#531-data-flow-integrity","title":"5.3.1 Data Flow Integrity","text":"<ul> <li>Source: <code>providers</code> module ensures data authenticity</li> <li>Processing: <code>predictors</code> maintain data lineage through processing pipeline</li> <li>Storage: <code>ResourceManager</code> handles data persistence with integrity checks</li> <li>Validation: Configuration system validates data formats and parameters</li> </ul>"},{"location":"dev_docs/architecture/#532-scalability-considerations","title":"5.3.2 Scalability Considerations","text":"<ul> <li>Horizontal Scaling: Provider system supports distributed data sources</li> <li>Vertical Scaling: Batch processing optimizes memory and compute usage</li> <li>Caching Strategy: Multi-level caching reduces redundant operations</li> <li>Resource Management: Efficient cleanup prevents resource leaks</li> </ul>"},{"location":"dev_docs/architecture/#533-maintainability-and-testing","title":"5.3.3 Maintainability and Testing","text":"<ul> <li>Clear Separation: Modular design enables focused testing of individual components</li> <li>Dependency Injection: Configuration-driven dependencies support test isolation</li> <li>Protocol Compliance: Abstract base classes define testable contracts</li> <li>Mock Support: Provider abstraction enables comprehensive unit testing</li> </ul>"},{"location":"dev_docs/architecture/#54-compliance-verification","title":"5.4 Compliance Verification","text":"<p>Each requirement can be verified through specific implementation artifacts:</p> <ol> <li>Interface Compliance: Abstract base classes define contracts that concrete implementations must fulfill</li> <li>Configuration Coverage: All configurable behavior is exposed through the settings system</li> <li>Error Handling: Each component includes appropriate exception handling and resource cleanup</li> <li>Performance Metrics: Batch processing methods include optimization</li> <li>Extension Points: New functionality can be added through well-defined extension mechanisms</li> </ol> <p>This traceability matrix ensures that every aspect of the system design directly addresses identified requirements while maintaining architectural integrity and supporting future enhancements.</p>"},{"location":"dev_docs/code_of_conduct/","title":"Contributor Covenant Code of Conduct","text":""},{"location":"dev_docs/code_of_conduct/#our-pledge","title":"Our Pledge","text":"<p>We as members, contributors, and leaders pledge to make participation in our community a harassment-free experience for everyone, regardless of age, body size, visible or invisible disability, ethnicity, sex characteristics, gender identity and expression, level of experience, education, socio-economic status, nationality, personal appearance, race, religion, or sexual identity and orientation.</p> <p>We pledge to act and interact in ways that contribute to an open, welcoming, diverse, inclusive, and healthy community.</p>"},{"location":"dev_docs/code_of_conduct/#our-standards","title":"Our Standards","text":"<p>Examples of behavior that contributes to a positive environment for our community include:</p> <ul> <li>Demonstrating empathy and kindness toward other people</li> <li>Being respectful of differing opinions, viewpoints, and experiences</li> <li>Giving and gracefully accepting constructive feedback</li> <li>Accepting responsibility and apologizing to those affected by our mistakes, and learning from the experience</li> <li>Focusing on what is best not just for us as individuals, but for the overall community</li> </ul> <p>Examples of unacceptable behavior include:</p> <ul> <li>The use of sexualized language or imagery, and sexual attention or advances of any kind</li> <li>Trolling, insulting or derogatory comments, and personal or political attacks</li> <li>Public or private harassment</li> <li>Publishing others' private information, such as a physical or email address, without their explicit permission</li> <li>Other conduct which could reasonably be considered inappropriate in a professional setting</li> </ul>"},{"location":"dev_docs/code_of_conduct/#enforcement-responsibilities","title":"Enforcement Responsibilities","text":"<p>Community leaders are responsible for clarifying and enforcing our standards of acceptable behavior and will take appropriate and fair corrective action in response to any behavior that they deem inappropriate, threatening, offensive, or harmful.</p> <p>Community leaders have the right and responsibility to remove, edit, or reject comments, commits, code, wiki edits, issues, and other contributions that are not aligned to this Code of Conduct, and will communicate reasons for moderation decisions when appropriate.</p>"},{"location":"dev_docs/code_of_conduct/#scope","title":"Scope","text":"<p>This Code of Conduct applies within all community spaces, and also applies when an individual is officially representing the community in public spaces. Examples of representing our community include using an official e-mail address, posting via an official social media account, or acting as an appointed representative at an online or offline event.</p>"},{"location":"dev_docs/code_of_conduct/#enforcement","title":"Enforcement","text":"<p>Instances of abusive, harassing, or otherwise unacceptable behavior may be reported to the community leaders responsible for enforcement by contacting the project team at iloncka.ds@gmail.com.</p> <p>All complaints will be reviewed and investigated promptly and fairly.</p> <p>All community leaders are obligated to respect the privacy and security of the reporter of any incident.</p>"},{"location":"dev_docs/code_of_conduct/#enforcement-guidelines","title":"Enforcement Guidelines","text":"<p>Community leaders will follow these Community Impact Guidelines in determining the consequences for any action they deem in violation of this Code of Conduct:</p>"},{"location":"dev_docs/code_of_conduct/#1-correction","title":"1. Correction","text":"<p>Community Impact: Use of inappropriate language or other behavior deemed unprofessional or unwelcome in the community.</p> <p>Consequence: A private, written warning from community leaders, providing clarity around the nature of the violation and an explanation of why the behavior was inappropriate. A public apology may be requested.</p>"},{"location":"dev_docs/code_of_conduct/#2-warning","title":"2. Warning","text":"<p>Community Impact: A violation through a single incident or series of actions.</p> <p>Consequence: A warning with consequences for continued behavior. No interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, for a specified period of time. This includes avoiding interaction in community spaces as well as external channels like social media. Violating these terms may lead to a temporary or permanent ban.</p>"},{"location":"dev_docs/code_of_conduct/#3-temporary-ban","title":"3. Temporary Ban","text":"<p>Community Impact: A serious violation of community standards, including sustained inappropriate behavior.</p> <p>Consequence: A temporary ban from any sort of interaction or public communication with the community for a specified period of time. No public or private interaction with the people involved, including unsolicited interaction with those enforcing the Code of Conduct, is allowed during this period. Violating these terms may lead to a permanent ban.</p>"},{"location":"dev_docs/code_of_conduct/#4-permanent-ban","title":"4. Permanent Ban","text":"<p>Community Impact: Demonstrating a pattern of violation of community standards, including sustained inappropriate behavior, harassment of an individual, or aggression toward or disparagement of classes of individuals.</p> <p>Consequence: A permanent ban from any sort of public interaction within the community.</p>"},{"location":"dev_docs/code_of_conduct/#attribution","title":"Attribution","text":"<p>This Code of Conduct is adapted from the Contributor Covenant, version 2.1, available at https://www.contributor-covenant.org/version/2/1/code_of_conduct.html.</p>"},{"location":"dev_docs/contributing/","title":"Contributing to CulicidaeLab","text":"<p>First off, thank you for considering contributing to <code>CulicidaeLab</code>! We are thrilled you're here and appreciate your interest in making this project better. Every contribution, from a small typo fix to a major new feature, is valuable.</p> <p>This document provides guidelines for contributing to the project. Please read it carefully to ensure a smooth and effective collaboration process.</p>"},{"location":"dev_docs/contributing/#code-of-conduct","title":"Code of Conduct","text":"<p>This project and everyone participating in it is governed by the CulicidaeLab Code of Conduct. By participating, you are expected to uphold this code. Please report unacceptable behavior to iloncka.ds@gmail.com.</p>"},{"location":"dev_docs/contributing/#how-can-i-contribute","title":"How Can I Contribute?","text":"<p>There are many ways to contribute, and all of them are welcome:</p> <ul> <li>Reporting Bugs: If you find a bug, please open an issue and provide detailed information, including steps to reproduce it.</li> <li>Suggesting Enhancements: Have an idea for a new feature or an improvement to an existing one? Open an issue to start a discussion.</li> <li>Writing Documentation: Help us improve our documentation by fixing typos, clarifying confusing sections, or adding new examples.</li> <li>Submitting Pull Requests: If you're ready to contribute code, this is the way to go.</li> </ul>"},{"location":"dev_docs/contributing/#reporting-bugs","title":"Reporting Bugs","text":"<p>Before creating a bug report, please check the existing issues to see if the problem has already been reported. If it hasn't, please open a new issue and include the following:</p> <ul> <li>A clear and descriptive title.</li> <li>The version of <code>culicidaelab</code> you are using.</li> <li>Your operating system and Python version.</li> <li>A step-by-step description of how to reproduce the bug.</li> <li>A code snippet that demonstrates the issue.</li> <li>The full traceback of any error messages.</li> </ul>"},{"location":"dev_docs/contributing/#suggesting-enhancements","title":"Suggesting Enhancements","text":"<p>We'd love to hear your ideas for improving <code>CulicidaeLab</code>. To suggest an enhancement, please open an issue and provide:</p> <ul> <li>A clear and descriptive title.</li> <li>A detailed explanation of the proposed enhancement and why it would be beneficial.</li> <li>(Optional) A rough sketch of how the feature might be implemented or used in code.</li> </ul>"},{"location":"dev_docs/contributing/#development-setup","title":"Development Setup","text":"<p>Ready to write some code? Here\u2019s how to set up your development environment.</p> <ol> <li> <p>Fork the Repository     Start by forking the main repository on GitHub.</p> </li> <li> <p>Clone Your Fork     Clone your forked repository to your local machine:     <pre><code>git clone https://github.com/YOUR_USERNAME/culicidaelab.git\ncd culicidaelab\n</code></pre></p> </li> <li> <p>Create a Virtual Environment     It is highly recommended to work in a virtual environment. You can use <code>uv</code> or Python's built-in <code>venv</code> module.     <pre><code># Using uv (recommended)\nuv venv\n\n# Or using venv\npython -m venv .venv\n</code></pre>     Activate the environment:     <pre><code># On macOS/Linux\nsource .venv/bin/activate\n\n# On Windows\n.venv\\Scripts\\activate\n</code></pre></p> </li> <li> <p>Install Dependencies     Install the project in editable mode (<code>-e</code>) along with all development dependencies (<code>[dev]</code>).     <pre><code>uv pip install -e \".[dev]\"\n</code></pre>     This command installs everything you need for development, including testing tools, linters, and documentation generators.</p> </li> <li> <p>Install pre-commit Hooks     We use <code>pre-commit</code> to automatically run linters and formatters before each commit. This ensures code quality and consistency across the project.     <pre><code>pre-commit install\n</code></pre>     This is a one-time setup per clone. Now, whenever you run <code>git commit</code>, the hooks defined in <code>.pre-commit-config.yaml</code> will be executed.</p> </li> </ol>"},{"location":"dev_docs/contributing/#our-development-workflow","title":"Our Development Workflow","text":"<p>We use a suite of tools to maintain code quality. Your <code>pre-commit</code> setup handles all of this automatically, but it's good to know what's happening under the hood.</p> <ul> <li>Formatting: <code>black</code> and <code>ruff-format</code> are used for deterministic, consistent code formatting.</li> <li>Linting: <code>ruff</code> and <code>flake8</code> catch common programming errors and style issues.</li> <li>Type Checking: <code>mypy</code> performs static type checking to find type-related bugs before runtime.</li> <li>Security: <code>bandit</code> scans for common security vulnerabilities in the code.</li> <li>Modernization: <code>pyupgrade</code> automatically upgrades syntax to newer Python versions.</li> </ul>"},{"location":"dev_docs/contributing/#running-tests","title":"Running Tests","text":"<p>To ensure your changes haven't introduced any regressions, please run the full test suite using <code>pytest</code>. <pre><code>pytest\n</code></pre> All tests should pass before you submit a pull request.</p>"},{"location":"dev_docs/contributing/#writing-documentation","title":"Writing Documentation","text":"<p>Good documentation is as important as good code. If you add or modify a feature, please update the documentation in the <code>docs/</code> directory accordingly.</p> <p>You can preview your changes locally by running: <pre><code>mkdocs serve\n</code></pre> This will start a local server, and you can view the documentation site in your browser at <code>http://127.0.0.1:8000</code>.</p>"},{"location":"dev_docs/contributing/#submitting-a-pull-request","title":"Submitting a Pull Request","text":"<p>When you're ready to submit your changes, please follow these steps:</p> <ol> <li> <p>Create a New Branch     Create a descriptive branch for your changes from the <code>main</code> branch.     <pre><code>git checkout -b feature/your-awesome-feature\n</code></pre></p> </li> <li> <p>Make Your Changes     Write your code, add or update tests, and write documentation.</p> </li> <li> <p>Commit Your Work     Commit your changes with a clear and concise message. When you commit, the <code>pre-commit</code> hooks will run. If they fail, fix the reported issues and commit again.     <pre><code>git add .\ngit commit -m \"feat: Add awesome new feature\"\n</code></pre></p> </li> <li> <p>Push to Your Fork     Push your branch to your forked repository on GitHub.     <pre><code>git push origin feature/your-awesome-feature\n</code></pre></p> </li> <li> <p>Open a Pull Request     Go to the <code>CulicidaeLab</code> repository on GitHub and open a pull request.</p> <ul> <li>Provide a clear title and a detailed description of your changes.</li> <li>If your PR addresses an existing issue, link to it by including <code>Closes #123</code> in the description.</li> </ul> </li> <li> <p>Code Review     Once your PR is submitted, a maintainer will review it. We may suggest some changes or improvements. We will do our best to provide timely and constructive feedback.</p> </li> </ol> <p>Thank you again for your interest in contributing! We look forward to your submissions.</p>"},{"location":"generated/gallery/","title":"Tutorials &amp; Usage Examples","text":"<p>Welcome to the Usage Examples section, where we move from theory to practice. Here, you will find a series of hands-on tutorials designed to walk you through the core functionalities of <code>CulicidaeLab</code>. Each example is self-contained, executable, and builds upon the last, demonstrating a complete and logical workflow for mosquito image analysis.</p> <p>We will follow a common real-world scenario, taking an image and processing it from start to finish. You will learn how to:</p> <ol> <li>Understand and Use the <code>settings</code> Module: We'll start with the foundation. You will learn how to access configurations and understand how the library manages resources. This is the central nervous system of <code>CulicidaeLab</code>.</li> <li>Managing Datasets: This guide shows you how to use the DatasetsManager to discover, load, and cache the datasets configured within the library. It is essential for anyone looking to perform large-scale model evaluation or exploratory data analysis (EDA).</li> <li>Detect Mosquitoes: Next, we'll use the <code>MosquitoDetector</code> to answer the first critical question: \"Is there a mosquito in this image, and where is it?\"</li> <li>Segment Mosquitoes: For the most detailed analysis, we'll use the <code>MosquitoSegmenter</code> to generate a precise, pixel-level mask of the mosquito's exact shape.</li> <li>Classify Mosquito Species: Once a mosquito is found, we'll use the <code>MosquitoClassifier</code> to identify its species, a crucial step for epidemiological studies.</li> </ol> <p>Before diving into the examples, please ensure you have successfully installed <code>CulicidaeLab</code>. If you haven't, please see the Installation Guide.</p> <p>The examples use sample images that are assumed to be in a local <code>test_imgs/</code> directory. You can download these from our GitHub repository or simply replace the file paths with your own images.</p> <p>We encourage you to run the code snippets yourself in a Jupyter Notebook or a Python script to get a feel for how everything works together. Let's get started</p> <p> Understanding and Using the Settings </p> <p> Managing and Loading Datasets </p> <p> Mosquito Detection Tutorial </p> <p> Mosquito Segmentation Tutorial </p> <p> Classifying Mosquito Species </p> <p> Using the Serve Module for Production Inference </p> <p> Download all examples in Python source code: gallery_python.zip</p> <p> Download all examples in Jupyter notebooks: gallery_jupyter.zip</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/mg_execution_times/","title":"Computation times","text":"<p>01:16.860 total execution time for generated_gallery files:</p> <p>+-------------------------------------------------------------------------------------------------------------------------------------------------------+------------+--------+ | tutorial_part_4_mosquito_classification (docs/en/examples/tutorial_part_4_mosquito_classification.py) | 00:30.130  | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------------------------------+------------+--------+ | tutorial_part_2_mosquito_detection (docs/en/examples/tutorial_part_2_mosquito_detection.py)                | 00:18.595  | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------------------------------+------------+--------+ | tutorial_part_3_mosquito_segmentation (docs/en/examples/tutorial_part_3_mosquito_segmentation.py)       | 00:14.1000 | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------------------------------+------------+--------+ | tutorial_part_1_datasets_example (docs/en/examples/tutorial_part_1_datasets_example.py)                      | 00:07.317  | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------------------------------+------------+--------+ | tutorial_part_0_settings_example (docs/en/examples/tutorial_part_0_settings_example.py)                      | 00:05.820  | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------------------------------+------------+--------+ | tutorial_part_5_serve_module (docs/en/examples/tutorial_part_5_serve_module.py)                                  | 00:00.000  | 0.0 MB | +-------------------------------------------------------------------------------------------------------------------------------------------------------+------------+--------+</p>"},{"location":"generated/gallery/tutorial_part_0_settings_example/","title":"Understanding and Using the Settings","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/tutorial_part_0_settings_example/#understanding-and-using-the-settings","title":"Understanding and Using the Settings","text":"<p>This tutorial demonstrates how to use the core <code>settings</code> object in CulicidaeLab. The <code>settings</code> object is the main entry point for accessing configurations, file paths, and model parameters throughout the library.</p> <p>Install the <code>culicidaelab</code> library if not already installed <pre><code>!pip install -q culicidaelab[full]\n</code></pre> or, if you have access to GPU <pre><code>!pip install -q culicidaelab[full-gpu]\n`\n\n&lt;!-- GENERATED FROM PYTHON SOURCE LINES 36-39 --&gt;\n\n```{.python }\nimport yaml\nfrom pathlib import Path\n</code></pre></p> <pre><code>from culicidaelab import get_settings\n</code></pre>"},{"location":"generated/gallery/tutorial_part_0_settings_example/#1-using-default-settings","title":"1. Using Default Settings","text":"<p>The easiest way to start with <code>CulicidaeLab</code> is by loading the default settings. The <code>get_settings()</code> function acts as a singleton; it loads the configuration once and returns the same instance on subsequent calls. This ensures a consistent state across your application.</p> <p>The default settings are loaded from the configuration files bundled with the library.</p> <p>Get the default settings instance</p> <pre><code>settings = get_settings()\n\n# The settings object provides easy access to key resource directories.\n# The library will automatically create these directories if they don't exist.\nprint(\"--- Default Resource Directories ---\")\nprint(f\"Active Config Directory: {settings.config_dir}\")\nprint(f\"Models Directory: {settings.model_dir}\")\nprint(f\"Datasets Directory: {settings.dataset_dir}\")\nprint(f\"Cache Directory: {settings.cache_dir}\")\n</code></pre> <p>Out:</p> <pre><code>--- Default Resource Directories ---\nActive Config Directory: C:\\Users\\lenova\\CascadeProjects\\culicidaelab\\culicidaelab\\conf\nModels Directory: C:\\Users\\lenova\\AppData\\Local\\culicidaelab\\culicidaelab\\models\nDatasets Directory: C:\\Users\\lenova\\AppData\\Local\\culicidaelab\\culicidaelab\\datasets\nCache Directory: C:\\Users\\lenova\\AppData\\Local\\culicidaelab\\culicidaelab\\Cache\n</code></pre>"},{"location":"generated/gallery/tutorial_part_0_settings_example/#2-accessing-model-weight-paths","title":"2. Accessing Model Weight Paths","text":"<p>The <code>settings</code> object knows the default local paths for all predictor model weights. When you instantiate a predictor, it uses these paths to find or download the models.</p> <p>Get the configured local file paths for different model types</p> <pre><code>detection_weights = settings.get_model_weights_path(\"detector\")\nsegmentation_weights = settings.get_model_weights_path(\"segmenter\")\nclassification_weights = settings.get_model_weights_path(\"classifier\")\n\nprint(\"--- Default Model Weight Paths ---\")\nprint(f\"Detection Model: {detection_weights}\")\nprint(f\"Segmentation Model: {segmentation_weights}\")\nprint(f\"Classification Model: {classification_weights}\")\n</code></pre> <p>Out:</p> <pre><code>--- Default Model Weight Paths ---\nDetection Model: C:\\Users\\lenova\\AppData\\Local\\culicidaelab\\culicidaelab\\models\\detector\\torch\\culico-net-det-v1-nano.pt\nSegmentation Model: C:\\Users\\lenova\\AppData\\Local\\culicidaelab\\culicidaelab\\models\\segmenter\\torch\\sam2.1_t.pt\nClassification Model: C:\\Users\\lenova\\AppData\\Local\\culicidaelab\\culicidaelab\\models\\classifier\\torch\\culico-net-cls-v1-17.pkl\n</code></pre>"},{"location":"generated/gallery/tutorial_part_0_settings_example/#3-working-with-species-configuration","title":"3. Working with Species Configuration","text":"<p>All species-related information, including class names and detailed metadata, is managed through the <code>species_config</code> property. This is crucial for interpreting the output of the classification model.</p> <p>Get the dedicated species configuration object</p> <pre><code>species_config = settings.species_config\n\n# You can easily retrieve the mapping of class indices to species names.\nprint(\"\\n--- Species Index-to-Name Mapping ---\")\nfor idx, species in species_config.species_map.items():\n    print(f\"Class {idx}: {species}\")\n\n# You can also fetch detailed metadata for any specific species.\nspecies_name = \"Aedes aegypti\"\nmetadata = species_config.get_species_metadata(species_name)\nif isinstance(metadata, dict):\n    print(f\"\\n--- Metadata for '{species_name}' ---\")\n    for key, value in metadata.items():\n        print(f\"{key}: {value}\")\n</code></pre> <p>Out:</p> <pre><code>--- Species Index-to-Name Mapping ---\nClass 0: Aedes aegypti\nClass 1: Aedes albopictus\nClass 2: Aedes canadensis\nClass 3: Aedes dorsalis\nClass 4: Aedes geniculatus\nClass 5: Aedes koreicus\nClass 6: Aedes triseriatus\nClass 7: Aedes vexans\nClass 8: Anopheles arabiensis\nClass 9: Anopheles freeborni\nClass 10: Anopheles sinensis\nClass 11: Species not defined\nClass 12: Culex inatomii\nClass 13: Culex pipiens\nClass 14: Culex quinquefasciatus\nClass 15: Culex tritaeniorhynchus\nClass 16: Culiseta annulata\nClass 17: Culiseta longiareolata\n\n--- Metadata for 'Aedes aegypti' ---\ncommon_name: Yellow fever mosquito\ntaxonomy: {'family': 'Culicidae', 'subfamily': 'Culicinae', 'genus': 'Aedes', 'subgenus': 'Stegomyia', 'species_complex': None}\nmetadata: {'vector_status': True, 'diseases': ['Yellow fever', 'Dengue', 'Zika'], 'habitat': 'Urban', 'breeding_sites': ['Artificial containers', 'Tree holes'], 'sources': ['https://www.cdc.gov/zika/geo/aedes-aegypti.html']}\n</code></pre>"},{"location":"generated/gallery/tutorial_part_0_settings_example/#4-using-a-custom-configuration-directory","title":"4. Using a Custom Configuration Directory","text":"<p>For advanced use cases, such as providing your own species metadata or changing default model parameters, you can point the library to a custom configuration directory.</p> <p><code>CulicidaeLab</code> will load your custom <code>.yaml</code> files and merge them on top of the defaults. This allows you to override only the settings you need to change.</p> <p>Create a custom config directory and a new config file</p> <pre><code>custom_config_dir = Path(\"custom_configs\")\ncustom_config_dir.mkdir(exist_ok=True)\n\n# Define a minimal custom configuration. We'll just override the species info.\n# Any settings not defined here will fall back to the library's defaults.\nexample_config = {\n    \"species\": {\n        \"species_classes\": {0: \"Aedes aegypti\", 1: \"Anopheles gambiae\"},\n        \"species_metadata\": {\n            \"species_info_mapping\": {\n                \"aedes_aegypti\": \"Aedes aegypti\",\n                \"anopheles_gambiae\": \"Anopheles gambiae\",\n            },\n            \"species_metadata\": {\n                \"Aedes aegypti\": {\n                    \"common_name\": \"Custom Yellow Fever Mosquito\",\n                    \"taxonomy\": {\n                        \"family\": \"Culicidae\",\n                        \"subfamily\": \"Culicinae\",\n                        \"genus\": \"Aedes\",\n                    },\n                    \"metadata\": {\n                        \"vector_status\": True,\n                        \"diseases\": [\"Dengue\", \"Zika\"],\n                        \"habitat\": \"Urban\",\n                        \"breeding_sites\": [\"Artificial containers\"],\n                        \"sources\": [\"custom_source\"],\n                    },\n                },\n                \"Anopheles gambiae\": {\n                    \"common_name\": \"Custom African Malaria Mosquito\",\n                    \"taxonomy\": {\n                        \"family\": \"Culicidae\",\n                        \"subfamily\": \"Anophelinae\",\n                        \"genus\": \"Anopheles\",\n                    },\n                    \"metadata\": {\n                        \"vector_status\": True,\n                        \"diseases\": [\"Malaria\"],\n                        \"habitat\": \"Rural\",\n                        \"breeding_sites\": [\"Puddles\"],\n                        \"sources\": [\"custom_source\"],\n                    },\n                },\n            },\n        },\n    },\n}\n\n\n# Write the custom config file\nconfig_file_path = custom_config_dir / \"species.yaml\"\nwith open(config_file_path, \"w\") as f:\n    yaml.safe_dump(example_config, f)\n\n# Now, initialize settings with the path to our custom directory.\n# `get_settings` is smart enough to create a *new* instance if a different config_dir is provided.\nprint(\"\\n--- Initializing with Custom Settings ---\")\ncustom_settings = get_settings(config_dir=str(custom_config_dir))\n\nprint(f\"Active Config Directory: {custom_settings.config_dir}\")\n\n# Let's check if our custom species map was loaded\nprint(\"\\n--- Custom Species Mapping ---\")\nfor idx, species in custom_settings.species_config.species_map.items():\n    print(f\"Class {idx}: {species}\")\n</code></pre> <p>Out:</p> <pre><code>--- Initializing with Custom Settings ---\nActive Config Directory: custom_configs\n\n--- Custom Species Mapping ---\nClass 0: Aedes aegypti\nClass 1: Aedes albopictus\nClass 2: Aedes canadensis\nClass 3: Aedes dorsalis\nClass 4: Aedes geniculatus\nClass 5: Aedes koreicus\nClass 6: Aedes triseriatus\nClass 7: Aedes vexans\nClass 8: Anopheles arabiensis\nClass 9: Anopheles freeborni\nClass 10: Anopheles sinensis\nClass 11: Species not defined\nClass 12: Culex inatomii\nClass 13: Culex pipiens\nClass 14: Culex quinquefasciatus\nClass 15: Culex tritaeniorhynchus\nClass 16: Culiseta annulata\nClass 17: Culiseta longiareolata\n</code></pre>"},{"location":"generated/gallery/tutorial_part_0_settings_example/#5-overriding-a-single-configuration-value","title":"5. Overriding a Single Configuration Value","text":"<p>Sometimes, you may only want to change a single value at runtime without creating new YAML files. The <code>set_config</code> method is perfect for this.</p> <p>Let's load the default settings and change the confidence threshold for the detector.</p> <p>Load default settings again (or use the previous 'settings' instance)</p> <pre><code>runtime_settings = get_settings()\noriginal_confidence = runtime_settings.get_config(\"predictors.detector.confidence\")\nprint(f\"Original detector confidence: {original_confidence}\")\n\n# Set a new confidence value at runtime\nruntime_settings.set_config(\"predictors.detector.confidence\", 0.85)\nnew_confidence = runtime_settings.get_config(\"predictors.detector.confidence\")\nprint(f\"New detector confidence: {new_confidence}\")\n</code></pre> <p>Out:</p> <pre><code>Original detector confidence: 0.25\nNew detector confidence: 0.85\n</code></pre> <p>Total running time of the script: ( 0 minutes  5.820 seconds)</p> <p> Download Python source code: tutorial_part_0_settings_example.py</p> <p> Download Jupyter notebook: tutorial_part_0_settings_example.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/","title":"Managing and Loading Datasets","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#managing-and-loading-datasets","title":"Managing and Loading Datasets","text":"<p>This tutorial demonstrates how to use the <code>DatasetsManager</code> in CulicidaeLab to interact with the datasets defined in the library's configuration.</p>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#who-is-this-guide-for","title":"Who is this guide for?","text":"<p>This tutorial is for researchers, developers, and students working on entomology, epidemiology, and computer vision. Whether you're training a new AI model, benchmarking an algorithm, or exploring mosquito biodiversity, this guide will help you get up and running quickly with available mosquito datasets.</p>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#what-you-will-learn","title":"What you will learn:","text":"<ul> <li>How to initialize the <code>DatasetsManager</code>.</li> <li>To list available mosquito datasets and view their specific details.</li> <li>How to load classification, detection, and segmentation datasets.</li> <li>How to perform exploratory data analysis (EDA) on a mosquito diversity dataset.</li> </ul>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#prerequisites","title":"Prerequisites","text":"<p>Before you start, make sure you have <code>culicidaelab</code> and other necessary libraries installed with code:</p> <p>Install the <code>culicidaelab</code> library if not already installed <pre><code>!pip install -q culicidaelab[full]\n</code></pre> or, if you have access to GPU <pre><code>!pip install -q culicidaelab[full-gpu]\n`\n\n&lt;!-- GENERATED FROM PYTHON SOURCE LINES 56-57 --&gt;\n\nStandard library imports\n\n&lt;!-- GENERATED FROM PYTHON SOURCE LINES 57-71 --&gt;\n\n```{.python }\nfrom collections import defaultdict\nfrom pathlib import Path\nimport json\n\n# Third-party imports\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport requests\nimport yaml\nimport cv2\n\n# CulicidaeLab imports\nfrom culicidaelab import get_settings, DatasetsManager, DatasetConfig\n</code></pre></p>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#1-quick-start-load-a-dataset-in-3-lines","title":"1. Quick Start: Load a Dataset in 3 Lines","text":"<p>For those who want to get data immediately. This snippet initializes the library and loads the test split of the mosquito species classification dataset.</p> <pre><code>print(\"--- Quick Start: Loading Classification Dataset ---\")\n# Initialize settings and datasets manager\nsettings = get_settings()\nmanager = DatasetsManager(settings)\n# Load the classification dataset\nclassification_dataset = manager.load_dataset(\"classification\", split=\"test\")\n\nprint(f\"\ud83d\ude80 Quick Start successful! Loaded {len(classification_dataset)} classification samples.\")\n</code></pre> <p>Out:</p> <pre><code>--- Quick Start: Loading Classification Dataset ---\nCache hit for split config: test C:\\Users\\lenova\\AppData\\Local\\culicidaelab\\culicidaelab\\datasets\\mosquito_species_classification\\4d967a30111bf29f\n\ud83d\ude80 Quick Start successful! Loaded 328 classification samples.\n</code></pre>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#2-initializing-and-exploring-available-datasets","title":"2. Initializing and Exploring Available Datasets","text":"<p>Now, let's dive deeper with each component.</p> <pre><code>print(\"--- Initializing Core Components ---\")\n# The get_settings() function is a singleton, so it will return the\n# already loaded instance\nsettings = get_settings()\n# The `DatasetsManager` is your central hub for all dataset-related\n# tasks. It handles downloading, caching, and loading.\nmanager = DatasetsManager(settings)\nprint(\"\u2705 Core components initialized.\")\n</code></pre> <p>Out:</p> <pre><code>--- Initializing Core Components ---\n\u2705 Core components initialized.\n</code></pre>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#listing-datasets-and-their-statistics","title":"Listing Datasets and Their Statistics","text":"<p>You can easily see all datasets configured in the library and get a quick overview of their contents.</p> <pre><code>print(\"\\n--- Available Datasets ---\")\ndataset_names = manager.list_datasets()\n\nfor name in dataset_names:\n    try:\n        # Access the dataset's configuration directly from settings\n        config = settings.get_config(f\"datasets.{name}\")\n        class_count = len(config.classes)\n        print(f\"\\n\ud83d\udccb Dataset: '{name}'\")\n        print(f\"   - Provider: {config.provider_name}\")\n        print(f\"   - Repository: {config.repository}\")\n        print(f\"   - Format: {config.format}\")\n        print(f\"   - Classes: {class_count}\")\n    except KeyError:\n        print(f\"\\nCould not find configuration for dataset: {name}\")\n</code></pre> <p>Out:</p> <pre><code>--- Available Datasets ---\n\n\ud83d\udccb Dataset: 'classification'\n   - Provider: huggingface\n   - Repository: iloncka/mosquito-species-classification-dataset\n   - Format: imagefolder\n   - Classes: 18\n\n\ud83d\udccb Dataset: 'detection'\n   - Provider: huggingface\n   - Repository: iloncka/mosquito-species-detection-dataset\n   - Format: yolo\n   - Classes: 1\n\n\ud83d\udccb Dataset: 'segmentation'\n   - Provider: huggingface\n   - Repository: iloncka/mosquito-species-segmentation-dataset\n   - Format: coco\n   - Classes: 1\n\n\ud83d\udccb Dataset: 'species_diversity'\n   - Provider: huggingface\n   - Repository: iloncka/mosquito_dataset_46_3139\n   - Format: imagefolder\n   - Classes: 46\n</code></pre>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#3-loading-and-visualizing-each-dataset-type","title":"3. Loading and Visualizing Each Dataset Type","text":"<p><code>culicidaelab</code> supports three main task types: classification, detection, and segmentation. Let's load a sample from each and visualize the data to understand its structure.</p>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#use-case-1-species-classification","title":"Use Case 1: Species Classification","text":"<p>Goal: Identify the species of a mosquito from an image.</p> <p>Data Structure: The dataset returns a dictionary containing a PIL <code>Image</code> and an string <code>label</code>.</p> <pre><code>print(\"\\n--- Loading Classification Dataset ---\")\nclass_data = manager.load_dataset(\"classification\", split=\"test\")\n\n# Let's inspect a single sample\nsample = class_data[10]\nimage = sample[\"image\"]\nlabel = sample[\"label\"]\n\n# The dataset features contain the mapping from integer ID to class name\nclass_name = class_data.features[\"label\"]\nspecies_name = label.replace(\"_\", \" \").title()\n\nprint(f\"Sample image size: {image.size}\")\nprint(f\"Sample label: {label}\")\nprint(f\"Corresponding species name: {species_name}\")\n\n# Visualize the sample\nplt.figure(figsize=(6, 6))\nplt.imshow(image)\nplt.title(f\"Classification Sample\\nLabel: {label} ({species_name})\")\nplt.axis(\"off\")\nplt.show()\n</code></pre> <p></p> <p>Out:</p> <pre><code>--- Loading Classification Dataset ---\nCache hit for split config: test C:\\Users\\lenova\\AppData\\Local\\culicidaelab\\culicidaelab\\datasets\\mosquito_species_classification\\4d967a30111bf29f\nSample image size: (224, 224)\nSample label: aedes_triseriatus\nCorresponding species name: Aedes Triseriatus\nC:/Users/lenova/CascadeProjects/culicidaelab/docs/en/examples/tutorial_part_1_datasets_example.py:160: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n  plt.show()\n</code></pre>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#use-case-2-mosquito-detection","title":"Use Case 2: Mosquito Detection","text":"<p>Goal: Draw a bounding box around each mosquito in an image.</p> <p>Data Structure: The dataset provides bounding boxes in <code>[x_min, y_min, x_max, y_max]</code> format and corresponding labels for each object.</p> <pre><code>print(\"\\n--- Loading Detection Dataset ---\")\n# Note: YOLO format may require special handling not covered here.\n# We will use the COCO-formatted segmentation dataset and treat its boxes as\n# detection boxes for this example.\ndetect_data = manager.load_dataset(\"detection\", split=\"train[:20]\")\n\n# Inspect a detection sample\ndetect_sample = detect_data[5]\ndetect_image_pil = detect_sample[\"image\"]\n# Convert PIL image to OpenCV format for drawing\ndetect_image_cv2 = cv2.cvtColor(np.array(detect_image_pil), cv2.COLOR_RGB2BGR)\n\nobjects = detect_sample[\"objects\"]\nprint(f\"Found {len(objects['bboxes'])} object(s) in this image.\")\n\n# Draw bounding boxes on the image\nfor bbox in objects[\"bboxes\"]:\n    x_min, y_min, x_max, y_max = (int(v) for v in bbox)\n    # Draw a green rectangle\n    cv2.rectangle(detect_image_cv2, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n\n# Visualize the sample\nplt.figure(figsize=(8, 8))\nplt.imshow(cv2.cvtColor(detect_image_cv2, cv2.COLOR_BGR2RGB))\nplt.title(\"Detection Sample with Bounding Boxes\")\nplt.axis(\"off\")\nplt.show()\n</code></pre> <p></p> <p>Out:</p> <pre><code>--- Loading Detection Dataset ---\nCache hit for split config: train[:20] C:\\Users\\lenova\\AppData\\Local\\culicidaelab\\culicidaelab\\datasets\\mosquito_detection\\9e9940e1c673b6f0\nFound 1 object(s) in this image.\nC:/Users/lenova/CascadeProjects/culicidaelab/docs/en/examples/tutorial_part_1_datasets_example.py:197: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n  plt.show()\n</code></pre>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#use-case-3-image-segmentation","title":"Use Case 3: Image Segmentation","text":"<p>Goal: Isolate the exact pixels of a mosquito's body from the background.</p> <p>Data Structure: The dataset provides a <code>label</code> which is a 2D array (mask) where pixel values indicate the class.</p> <pre><code>print(\"\\n--- Loading Segmentation Dataset ---\")\nseg_data = manager.load_dataset(\"segmentation\", split=\"train[:20]\")\n\n# Inspect a segmentation sample\nseg_sample = seg_data[0]\nseg_image = seg_sample[\"image\"]\nseg_mask = np.array(seg_sample[\"label\"])  # Convert mask to numpy array\n\nprint(f\"Image size: {seg_image.size}\")\nprint(f\"Segmentation mask shape: {seg_mask.shape}\")\nprint(f\"Unique values in mask: {np.unique(seg_mask)}\")  # 0 is background, 1 is mosquito\n\n# Create a colored overlay for the mask\n# Where the mask is 1 (mosquito), we make it red\noverlay = np.zeros((*seg_mask.shape, 4), dtype=np.uint8)\noverlay[seg_mask &gt;= 1] = [255, 0, 0, 128]  # Red color with 50% opacity\n\n# Visualize the image with the mask overlay\nfig, ax = plt.subplots(figsize=(8, 8))\nax.imshow(seg_image)\nax.imshow(overlay)\nax.set_title(\"Segmentation Sample with Mask Overlay\")\nax.axis(\"off\")\nplt.show()\n</code></pre> <p></p> <p>Out:</p> <pre><code>--- Loading Segmentation Dataset ---\nCache hit for split config: train[:20] C:\\Users\\lenova\\AppData\\Local\\culicidaelab\\culicidaelab\\datasets\\mosquito_segmentation\\9e9940e1c673b6f0\nImage size: (224, 224)\nSegmentation mask shape: (224, 224)\nUnique values in mask: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 160 161 162\n 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180\n 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198\n 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216\n 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234\n 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252\n 253 254]\nC:/Users/lenova/CascadeProjects/culicidaelab/docs/en/examples/tutorial_part_1_datasets_example.py:230: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n  plt.show()\n</code></pre>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#4-advanced-exploratory-data-analysis-eda","title":"4. Advanced: Exploratory Data Analysis (EDA)","text":"<p>Understanding your data's distribution is vital. Here, we'll analyze the foundational <code>mosquito-species-diversity</code> dataset.</p> <p>We will fetch the <code>repository_id</code> using datasets manager, making the code robust and reusable.</p> <p>Get the repository ID from the dataset config.</p> <pre><code>try:\n    diversity_config = manager.get_dataset_info(\"species_diversity\")\n    repo_id = diversity_config.repository\n    print(f\"\u2705 Successfully found repository ID from settings: {repo_id}\")\nexcept KeyError:\n    print(\"\u274c Could not find 'mosquito-species-diversity' dataset in settings.\")\n    repo_id = None\n</code></pre> <p>Out:</p> <pre><code>\u2705 Successfully found repository ID from settings: iloncka/mosquito_dataset_46_3139\n</code></pre>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#exploring-the-mosquito-species-diversity-dataset","title":"Exploring the mosquito species diversity dataset","text":"<p>This dataset serves as the foundational source for the classification, detection, and segmentation datasets. It contains a rich collection of images with corresponding labels and bounding box information.</p> <p>Let's start by fetching some basic statistics.</p> <p>The repository ID for our source dataset on Hugging Face</p> <pre><code>def get_dataset_statistics(repo_id, config_name=\"default\", split_name=\"train\"):\n    \"\"\"Fetch detailed column statistics for a dataset split from the Hugging Face API.\"\"\"\n    api_url = (\n        f\"https://datasets-server.huggingface.co/statistics?dataset={repo_id}&amp;config={config_name}&amp;split={split_name}\"\n    )\n    print(f\"Querying API: {api_url}\")\n    response = requests.get(api_url, timeout=10)\n    response.raise_for_status()  # Will raise an error for bad responses\n    return response.json()\n\n\n# Fetch the statistics\nprint(f\"--- Fetching statistics for '{repo_id}' ---\")\ntry:\n    dataset_info = get_dataset_statistics(repo_id)\n    print(\"\u2705 Statistics fetched successfully.\")\nexcept requests.exceptions.RequestException as e:\n    print(f\"\u274c Failed to fetch statistics: {e}\")\n    dataset_info = None\n</code></pre> <p>Out:</p> <pre><code>--- Fetching statistics for 'iloncka/mosquito_dataset_46_3139' ---\nQuerying API: https://datasets-server.huggingface.co/statistics?dataset=iloncka/mosquito_dataset_46_3139&amp;config=default&amp;split=train\n\u2705 Statistics fetched successfully.\n</code></pre>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#visualizing-class-distribution","title":"Visualizing Class Distribution","text":"<p>A balanced dataset is crucial for training a robust model. Let's write a function to visualize the number of samples for each mosquito species to check for any significant imbalances.</p> <pre><code>def get_label_stats(dataset_info):\n    \"\"\"Extract label frequencies from the fetched dataset statistics.\"\"\"\n    if not dataset_info:\n        return None\n\n    for column in dataset_info.get(\"statistics\", []):\n        if column.get(\"column_name\") == \"label\" and column.get(\"column_type\") == \"string_label\":\n            return column[\"column_statistics\"].get(\"frequencies\", {})\n\n    print(\"Warning: 'label' statistics not found.\")\n    return None\n\n\ndef create_distribution_plot(\n    dataset_info,\n    repo_id,\n    color=\"teal\",\n    figsize=(15, 12),\n    output_file=\"class_distribution.png\",\n):\n    \"\"\"Creates and saves a bar chart of the class distribution.\"\"\"\n    label_stats = get_label_stats(dataset_info)\n    if not label_stats:\n        print(\"Cannot create plot: No label statistics available.\")\n        return\n\n    # Sort classes by the number of samples for better visualization\n    sorted_items = sorted(label_stats.items(), key=lambda x: x[1], reverse=True)\n    classes, counts = zip(*sorted_items)\n\n    _, ax = plt.subplots(figsize=figsize)\n    y_pos = np.arange(len(classes))\n    ax.barh(y_pos, counts, align=\"center\", color=color, alpha=0.8)\n\n    # Format plot for clarity\n    ax.set_yticks(y_pos)\n    formatted_classes = [c.replace(\"_\", \" \").title() for c in classes]\n    ax.set_yticklabels(formatted_classes, fontsize=12)\n    ax.invert_yaxis()  # Display the class with the most samples at the top\n    ax.set_xlabel(\"Number of Samples\", fontsize=14)\n    ax.set_title(f\"Distribution of Mosquito Species in {repo_id}\", pad=20, fontsize=18)\n\n    # Add count labels to each bar\n    for i, v in enumerate(counts):\n        ax.text(v + 3, i, str(v), color=\"blue\", va=\"center\", fontsize=10)\n\n    plt.tight_layout()\n    plt.savefig(output_file, dpi=300, bbox_inches=\"tight\")\n    print(f\"\u2705 Distribution plot saved as {output_file}\")\n    plt.show()\n\n\n# Generate and display the plot\nif dataset_info:\n    create_distribution_plot(dataset_info, repo_id)\n</code></pre> <p></p> <p>Out:</p> <pre><code>\u2705 Distribution plot saved as class_distribution.png\nC:/Users/lenova/CascadeProjects/culicidaelab/docs/en/examples/tutorial_part_1_datasets_example.py:341: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n  plt.show()\n</code></pre> <p>This chart gives you an immediate understanding of which species are well-represented and which might require techniques like data augmentation or weighted loss functions during model training.</p>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#visualizing-taxonomic-distribution","title":"Visualizing Taxonomic Distribution","text":"<p>To better understand the relationships between species, we can visualize the dataset in a hierarchical tree structure, grouping species by their genus. This provides insight into the taxonomic diversity of the data.</p> <pre><code>def create_tree_visualization(\n    dataset_info,\n    figsize=(16, 12),\n    output_file=\"taxonomic_tree.png\",\n):\n    \"\"\"Creates a tree-like visualization of species grouped by genus.\"\"\"\n    label_stats = get_label_stats(dataset_info)\n    if not label_stats:\n        print(\"Cannot create visualization: No label statistics available.\")\n        return\n\n    # Group species by genus and calculate totals\n    genus_groups = defaultdict(list)\n    genus_totals = defaultdict(int)\n    for species, count in label_stats.items():\n        genus = species.split(\"_\")[0]\n        genus_groups[genus].append((species, count))\n        genus_totals[genus] += count\n\n    # Sort genera by the total number of samples\n    sorted_genera = sorted(genus_totals.items(), key=lambda x: x[1], reverse=True)\n\n    fig, ax = plt.subplots(figsize=figsize)\n\n    # --- Plotting Logic ---\n    total_species_count = len(label_stats)\n    y_positions = np.linspace(0.95, 0.05, total_species_count)\n    current_y_idx = 0\n\n    # Use a color map for different genera\n    colors = plt.cm.get_cmap(\"tab20\", len(sorted_genera))\n\n    for i, (genus, total_count) in enumerate(sorted_genera):\n        species_in_genus = sorted(genus_groups[genus], key=lambda x: x[1], reverse=True)\n        num_species = len(species_in_genus)\n\n        # Define y-coordinates for this genus block\n        y_start = y_positions[current_y_idx]\n        y_end = y_positions[current_y_idx + num_species - 1]\n        y_genus_mid = (y_start + y_end) / 2\n\n        # Draw genus branch and label\n        ax.plot([0.1, 0.2], [y_genus_mid, y_genus_mid], color=colors(i), linewidth=3)\n        ax.text(\n            0.08,\n            y_genus_mid,\n            f\"{genus.title()}\\n({total_count})\",\n            ha=\"right\",\n            va=\"center\",\n            fontsize=14,\n            weight=\"bold\",\n        )\n\n        # Draw vertical connector for species in this genus\n        ax.plot([0.2, 0.2], [y_start, y_end], color=colors(i), linewidth=1)\n\n        # Draw branches for each species\n        for species_name, count in species_in_genus:\n            y_species = y_positions[current_y_idx]\n            branch_length = 0.1 + 0.5 * (count / max(label_stats.values()))\n\n            ax.plot([0.2, 0.2 + branch_length], [y_species, y_species], color=colors(i), linewidth=1.5)\n            ax.text(\n                0.22 + branch_length,\n                y_species,\n                f\"{species_name.replace('_', ' ').title()} ({count})\",\n                va=\"center\",\n                fontsize=12,\n            )\n            current_y_idx += 1\n\n    # --- Final Plot Customization ---\n    ax.axis(\"off\")\n    plt.title(\"Taxonomic Distribution of Mosquito Species\", fontsize=20, pad=20)\n    plt.savefig(output_file, dpi=300, bbox_inches=\"tight\")\n    print(f\"\u2705 Tree visualization saved as {output_file}\")\n    plt.show()\n\n\n# Generate and display the tree visualization\nif dataset_info:\n    create_tree_visualization(dataset_info)\n</code></pre> <p></p> <p>Out:</p> <pre><code>C:/Users/lenova/CascadeProjects/culicidaelab/docs/en/examples/tutorial_part_1_datasets_example.py:392: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n  colors = plt.cm.get_cmap(\"tab20\", len(sorted_genera))\n\u2705 Tree visualization saved as taxonomic_tree.png\nC:/Users/lenova/CascadeProjects/culicidaelab/docs/en/examples/tutorial_part_1_datasets_example.py:438: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n  plt.show()\n</code></pre> <p>This plot provides a clear visual summary of the dataset's structure, showing which genera are most prevalent and how the samples are distributed among their respective species. It's an invaluable tool for both educational purposes and for guiding research that may focus on specific genera.</p>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#5-advanced-adding-a-custom-dataset","title":"5. Advanced: Adding a Custom Dataset","text":"<p><code>culicidaelab</code> is designed to be extensible. You can easily add your own Hugging Face datasets by creating a simple YAML configuration file.</p>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#step-1-understanding-the-required-structure-with-datasetconfig","title":"Step 1: Understanding the Required Structure with <code>DatasetConfig</code>","text":"<p>Before writing a configuration, you need to know what fields are required. All dataset configurations are validated against the <code>DatasetConfig</code> Pydantic model. We can inspect this model directly to get a perfect template.</p> <pre><code># Let's print the model's docstring for a human-readable explanation.\nprint(\"--- DatasetConfig Model Documentation ---\")\nprint(DatasetConfig.__doc__)\n\n# For a precise, technical blueprint, we can generate its JSON Schema.\n# This shows all fields, their types, and which ones are required.\nprint(\"\\n--- DatasetConfig JSON Schema ---\")\nschema = DatasetConfig.model_json_schema()\nprint(json.dumps(schema, indent=2))\n</code></pre> <p>Out:</p> <pre><code>--- DatasetConfig Model Documentation ---\nConfiguration for a single dataset.\n\n    Attributes:\n        name (str): The unique internal name for the dataset.\n        path (str): The local directory path for storing the dataset.\n        format (str): The dataset format (e.g., \"imagefolder\", \"coco\", \"yolo\").\n        classes (list[str]): A list of class names present in the dataset.\n        provider_name (str): The name of the data provider (e.g., \"huggingface\").\n        repository (str): The repository ID on the provider's platform.\n        config_name (str | None): The specific configuration of a Hugging Face dataset.\n        derived_datasets (list[str] | None): A list of Hugging Face repository IDs\n            for datasets that were derived from this one. Defaults to None.\n        trained_models_repositories (list[str] | None): A list of Hugging Face\n            repository IDs for models trained on this dataset. Defaults to None.\n\n\n--- DatasetConfig JSON Schema ---\n{\n  \"additionalProperties\": true,\n  \"description\": \"Configuration for a single dataset.\\n\\nAttributes:\\n    name (str): The unique internal name for the dataset.\\n    path (str): The local directory path for storing the dataset.\\n    format (str): The dataset format (e.g., \\\"imagefolder\\\", \\\"coco\\\", \\\"yolo\\\").\\n    classes (list[str]): A list of class names present in the dataset.\\n    provider_name (str): The name of the data provider (e.g., \\\"huggingface\\\").\\n    repository (str): The repository ID on the provider's platform.\\n    config_name (str | None): The specific configuration of a Hugging Face dataset.\\n    derived_datasets (list[str] | None): A list of Hugging Face repository IDs\\n        for datasets that were derived from this one. Defaults to None.\\n    trained_models_repositories (list[str] | None): A list of Hugging Face\\n        repository IDs for models trained on this dataset. Defaults to None.\",\n  \"properties\": {\n    \"name\": {\n      \"title\": \"Name\",\n      \"type\": \"string\"\n    },\n    \"path\": {\n      \"title\": \"Path\",\n      \"type\": \"string\"\n    },\n    \"format\": {\n      \"title\": \"Format\",\n      \"type\": \"string\"\n    },\n    \"classes\": {\n      \"items\": {\n        \"type\": \"string\"\n      },\n      \"title\": \"Classes\",\n      \"type\": \"array\"\n    },\n    \"provider_name\": {\n      \"title\": \"Provider Name\",\n      \"type\": \"string\"\n    },\n    \"repository\": {\n      \"title\": \"Repository\",\n      \"type\": \"string\"\n    },\n    \"config_name\": {\n      \"anyOf\": [\n        {\n          \"type\": \"string\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": \"default\",\n      \"title\": \"Config Name\"\n    },\n    \"derived_datasets\": {\n      \"anyOf\": [\n        {\n          \"items\": {\n            \"type\": \"string\"\n          },\n          \"type\": \"array\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"title\": \"Derived Datasets\"\n    },\n    \"trained_models_repositories\": {\n      \"anyOf\": [\n        {\n          \"items\": {\n            \"type\": \"string\"\n          },\n          \"type\": \"array\"\n        },\n        {\n          \"type\": \"null\"\n        }\n      ],\n      \"default\": null,\n      \"title\": \"Trained Models Repositories\"\n    }\n  },\n  \"required\": [\n    \"name\",\n    \"path\",\n    \"format\",\n    \"classes\",\n    \"provider_name\",\n    \"repository\"\n  ],\n  \"title\": \"DatasetConfig\",\n  \"type\": \"object\"\n}\n</code></pre>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#step-2-create-a-custom-configuration-file","title":"Step 2: Create a Custom Configuration File","text":"<p>Now that we know the required structure, let's create a custom configuration.</p> <p>First, it's best practice to keep your custom configurations separate from the library's defaults. We'll create a dedicated directory for them.</p> <pre><code>custom_config_dir = Path(\"culicidae_custom_config\")\ncustom_config_dir.mkdir(exist_ok=True)\nprint(f\"Created custom config directory at: ./{custom_config_dir.name}\")\n</code></pre> <p>Out:</p> <pre><code>Created custom config directory at: ./culicidae_custom_config\n</code></pre> <p>Next, create a <code>.yaml</code> file inside this directory. Your file must name <code>datasets</code>, in this file you can define one or more named dataset configurations, where each one follows the <code>DatasetConfig</code> structure we just inspected.</p> <p>Example: Let's add a configuration for a hypothetical <code>culex-pipiens-complex</code> dataset.</p> <p>The file's stem will become the top-level key in the merged config. To override the library's 'datasets' section, save the mapping directly</p> <pre><code>custom_dataset_config = {\n    \"culex-pipiens-complex\": {\n        \"name\": \"culex-pipiens-complex\",\n        \"path\": \"culex_pipiens_complex\",\n        \"format\": \"imagefolder\",\n        \"classes\": [\"culex_pipiens\", \"culex_torrentium\"],\n        \"provider_name\": \"huggingface\",\n        \"repository\": \"my-org/culex-pipiens-complex-dataset\",\n    },\n}\n\n\nconfig_file_path = custom_config_dir / \"datasets.yaml\"\nwith open(config_file_path, \"w\") as f:\n    yaml.safe_dump(custom_dataset_config, f)\n\nprint(f\"\u2705 Custom dataset config saved to: {config_file_path}\")\n</code></pre> <p>Out:</p> <pre><code>\u2705 Custom dataset config saved to: culicidae_custom_config\\datasets.yaml\n</code></pre>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#step-3-load-culicidaelab-with-your-custom-configuration","title":"Step 3: Load <code>culicidaelab</code> with Your Custom Configuration","text":"<p>The <code>get_settings</code> function will create a new, merged settings instance when a <code>config_dir</code> is provided, loading your custom file on top of the defaults.</p> <pre><code>print(\"\\n--- Initializing with Custom Settings ---\")\ncustom_settings = get_settings(config_dir=str(custom_config_dir))\n\n# Create a new manager with the custom settings\ncustom_manager = DatasetsManager(custom_settings)\n\nprint(\"\\n--- Listing All Datasets (including custom) ---\")\nall_datasets = custom_manager.list_datasets()\nprint(all_datasets)\n\nif \"culex-pipiens-complex\" in all_datasets:\n    print(\"\\n\u2705 Successfully added 'culex-pipiens-complex' to the available datasets!\")\nelse:\n    print(\"\\n\u274c Custom dataset was not loaded correctly.\")\n</code></pre> <p>Out:</p> <pre><code>--- Initializing with Custom Settings ---\n\n--- Listing All Datasets (including custom) ---\n['classification', 'detection', 'segmentation', 'species_diversity', 'culex-pipiens-complex']\n\n\u2705 Successfully added 'culex-pipiens-complex' to the available datasets!\n</code></pre>"},{"location":"generated/gallery/tutorial_part_1_datasets_example/#6-next-steps-further-reading","title":"6. Next Steps &amp; Further Reading","text":"<p>You now have a solid understanding of how to use the <code>DatasetsManager</code> in <code>culicidaelab</code>. From here, you can:</p> <ul> <li>Train a new model: Use the loaded data with your favorite deep learning framework.</li> <li>Contribute to the project: If you have your own labeled mosquito datasets, consider sharing them with the community.</li> <li>Explore the API: Dive deeper into the <code>culicidaelab</code> source code to discover more functionalities.</li> </ul> <p>By providing standardized datasets and an easy-to-use interface, <code>culicidaelab</code> aims to accelerate innovation in the fight against mosquito-borne diseases. Happy coding!</p> <p>Total running time of the script: ( 0 minutes  7.317 seconds)</p> <p> Download Python source code: tutorial_part_1_datasets_example.py</p> <p> Download Jupyter notebook: tutorial_part_1_datasets_example.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/tutorial_part_2_mosquito_detection/","title":"Mosquito Detection Tutorial","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/tutorial_part_2_mosquito_detection/#mosquito-detection-tutorial","title":"Mosquito Detection Tutorial","text":"<p>This tutorial shows how to use the <code>MosquitoDetector</code> from the CulicidaeLab library to perform object detection on images. We will cover:</p> <ul> <li>Loading the detector model</li> <li>Preparing an image from the dataset</li> <li>Running the model to get bounding boxes</li> <li>Visualizing the results</li> <li>Evaluating prediction accuracy</li> <li>Running predictions on a batch of images</li> </ul> <p>Install the <code>culicidaelab</code> library if not already installed <pre><code>!pip install -q culicidaelab[full]\n</code></pre> or, if you have access to GPU <pre><code>!pip install -q culicidaelab[full-gpu]\n`\n\n&lt;!-- GENERATED FROM PYTHON SOURCE LINES 44-49 --&gt;\n\n## 1. Initialization\n\nFirst, we'll get the global `settings` instance and use it to initialize our `MosquitoDetector`.\nBy setting `load_model=True`, we tell the detector to load the model weights into memory immediately.\nIf the model file doesn't exist locally, it will be downloaded automatically.\n\n&lt;!-- GENERATED FROM PYTHON SOURCE LINES 51-73 --&gt;\n\n```{.python }\n\nfrom PIL import Image, ImageDraw, ImageFont\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom culicidaelab import get_settings\nfrom culicidaelab import MosquitoDetector, DatasetsManager\n\n# Get settings instance\nsettings = get_settings()\n\n# Initialize the datasets manager\nmanager = DatasetsManager(settings)\n\n# Load detection dataset\ndetect_data = manager.load_dataset(\"detection\", split=\"train[:20]\")\n\n# Instantiate the detector and load the model\nprint(\"Initializing MosquitoDetector and loading model...\")\ndetector = MosquitoDetector(settings=settings, load_model=True)\nprint(\"Model loaded successfully.\")\n</code></pre></p> <p>Out:</p> <pre><code>Cache hit for split config: train[:20] C:\\Users\\lenova\\AppData\\Local\\culicidaelab\\culicidaelab\\datasets\\mosquito_detection\\9e9940e1c673b6f0\nInitializing MosquitoDetector and loading model...\nModel loaded successfully.\n</code></pre>"},{"location":"generated/gallery/tutorial_part_2_mosquito_detection/#2-detecting-mosquitoes-in-a-dataset-image","title":"2. Detecting Mosquitoes in a Dataset Image","text":"<p>Now let's use an image from the detection dataset and run the detector on it.</p> <p>Inspect a detection sample</p> <pre><code>detect_sample = detect_data[5]\ndetect_image = detect_sample[\"image\"]\n\n# Get ground truth objects\nobjects = detect_sample[\"objects\"]\nprint(f\"Found {len(objects['bboxes'])} object(s) in this image.\")\n\n# The `predict` method returns a list of detections.\n# Each detection is a tuple: (x1, y1, x2, y2, confidence_score)\nresult = detector.predict(detect_image)\n\n# The `visualize` method draws the bounding boxes onto the image for easy inspection.\nannotated_image = detector.visualize(detect_image, result)\n\n# Display the result\nplt.figure(figsize=(12, 8))\nplt.imshow(annotated_image)\nplt.axis(\"off\")\nplt.title(\"Detected Mosquitoes\")\nplt.show()\n\n# Print the numerical detection results\nprint(\"\\nDetection Results:\")\nif result:\n    for i, det in enumerate(result.detections):\n        print(\n            f\"  - Mosquito {i+1}: \\\n            Confidence = {det.confidence:.2f}, \\\n            Box = (x1={det.box.x1:.1f}, y1={det.box.y1:.1f}, x2={det.box.x2:.1f}, y2={det.box.y2:.1f})\",\n        )\nelse:\n    print(\"  No mosquitoes detected.\")\n</code></pre> <p></p> <p>Out:</p> <pre><code>Found 1 object(s) in this image.\nC:/Users/lenova/CascadeProjects/culicidaelab/docs/en/examples/tutorial_part_2_mosquito_detection.py:99: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n  plt.show()\n\nDetection Results:\n  - Mosquito 1:             Confidence = 0.44,             Box = (x1=73.8, y1=141.9, x2=820.1, y2=511.1)\n</code></pre>"},{"location":"generated/gallery/tutorial_part_2_mosquito_detection/#3-evaluating-a-prediction-with-ground-truth","title":"3. Evaluating a Prediction with Ground Truth","text":"<p>The <code>evaluate</code> method allows you to compare a prediction against a ground truth. This is useful for measuring the model's accuracy. The method returns several metrics, which are a standard for object detection. Now let's evaluate the prediction against the actual ground truth from the dataset.</p> <p>Extract ground truth boxes from the dataset sample</p> <pre><code>ground_truth_boxes = []\nfor bbox in objects[\"bboxes\"]:\n    x_min, y_min, x_max, y_max = bbox\n    ground_truth_boxes.append((x_min, y_min, x_max, y_max))\n\n# Evaluate using the ground truth from the dataset\nprint(\"--- Evaluating with dataset ground truth ---\")\nevaluation = detector.evaluate(ground_truth=ground_truth_boxes, prediction=result)\nprint(evaluation)\n</code></pre> <p>Out:</p> <pre><code>--- Evaluating with dataset ground truth ---\n{'precision': 0.9999999989999999, 'recall': 1.0, 'f1': 0.9999999989999999, 'ap': 0.9999999989999999, 'mean_iou': 0.6156440556082946}\n</code></pre> <p>You can let the method run prediction internally by passing the raw image</p> <pre><code>print(\"\\n--- Evaluating directly from an image ---\")\nevaluation_from_raw = detector.evaluate(ground_truth=ground_truth_boxes, input_data=detect_image)\nprint(evaluation_from_raw)\n</code></pre> <p>Out:</p> <pre><code>--- Evaluating directly from an image ---\n{'precision': 0.9999999989999999, 'recall': 1.0, 'f1': 0.9999999989999999, 'ap': 0.9999999989999999, 'mean_iou': 0.6156440556082946}\n</code></pre>"},{"location":"generated/gallery/tutorial_part_2_mosquito_detection/#4-running-batch-predictions-on-dataset-images","title":"4. Running Batch Predictions on Dataset Images","text":"<p>For efficiency, you can process multiple images at once using <code>predict_batch</code>.</p> <p>Extract images from the detection dataset</p> <pre><code>image_batch = [sample[\"image\"] for sample in detect_data]\n\n# Run batch prediction\ndetections_batch = detector.predict_batch(image_batch)\nprint(\"Batch prediction complete.\")\n\nfor i, dets in enumerate(detections_batch):\n    print(f\"  - Image {i+1}: Found {len(dets.detections)} detection(s).\")\n</code></pre> <p>Out:</p> <pre><code>Batch prediction complete.\n  - Image 1: Found 1 detection(s).\n  - Image 2: Found 1 detection(s).\n  - Image 3: Found 1 detection(s).\n  - Image 4: Found 1 detection(s).\n  - Image 5: Found 1 detection(s).\n  - Image 6: Found 1 detection(s).\n  - Image 7: Found 1 detection(s).\n  - Image 8: Found 1 detection(s).\n  - Image 9: Found 1 detection(s).\n  - Image 10: Found 1 detection(s).\n  - Image 11: Found 1 detection(s).\n  - Image 12: Found 1 detection(s).\n  - Image 13: Found 1 detection(s).\n  - Image 14: Found 1 detection(s).\n  - Image 15: Found 1 detection(s).\n  - Image 16: Found 1 detection(s).\n  - Image 17: Found 1 detection(s).\n  - Image 18: Found 1 detection(s).\n  - Image 19: Found 1 detection(s).\n  - Image 20: Found 1 detection(s).\n</code></pre>"},{"location":"generated/gallery/tutorial_part_2_mosquito_detection/#5-evaluating-a-batch-of-predictions-with-dataset-ground-truth","title":"5. Evaluating a Batch of Predictions with Dataset Ground Truth","text":"<p>Similarly, <code>evaluate_batch</code> can be used to get aggregated metrics over the entire dataset.</p> <p>Extract ground truth from the detection dataset</p> <pre><code>ground_truth_batch = []\nfor sample in detect_data:\n    boxes = []\n    for bbox in sample[\"objects\"][\"bboxes\"]:\n        x_min, y_min, x_max, y_max = bbox\n        boxes.append((x_min, y_min, x_max, y_max))\n    ground_truth_batch.append(boxes)\n\n# Call evaluate_batch with dataset ground truth\nprint(\"\\n--- Evaluating the entire batch with dataset ground truth ---\")\nbatch_evaluation = detector.evaluate_batch(\n    ground_truth_batch=ground_truth_batch,\n    predictions_batch=detections_batch,\n    num_workers=2,  # Use multiple workers for faster processing\n)\n\nprint(\"Aggregated batch evaluation metrics:\")\nprint(batch_evaluation)\n</code></pre> <p>Out:</p> <pre><code>--- Evaluating the entire batch with dataset ground truth ---\nAggregated batch evaluation metrics:\n{'precision_mean': 0.9999999989999999, 'precision_std': 0.0, 'ap_mean': 0.9999999989999999, 'ap_std': 0.0, 'recall_mean': 1.0, 'recall_std': 0.0, 'mean_iou_mean': 0.7802580509636634, 'mean_iou_std': 0.11935857019771838, 'f1_mean': 0.9999999989999999, 'f1_std': 0.0, 'count': 20}\n</code></pre>"},{"location":"generated/gallery/tutorial_part_2_mosquito_detection/#6-visualizing-ground-truth-vs-predictions","title":"6. Visualizing Ground Truth vs Predictions","text":"<p>Let's create a comparison visualization showing both ground truth and predictions.</p> <p>Create a function to visualize both ground truth and predictions</p> <pre><code>def visualize_comparison(image_rgb, ground_truth_boxes, detections):\n    \"\"\"\n    Visualize ground truth and detection bounding boxes on an image using Pillow.\n\n    Args:\n        image_rgb: RGB image as numpy array or PIL Image\n        ground_truth_boxes: List of ground truth bounding boxes [x_min, y_min, x_max, y_max]\n        detections: List of detections results\n\n    Returns:\n        PIL Image with bounding boxes drawn\n    \"\"\"\n    # Convert numpy array to PIL Image if needed\n    if isinstance(image_rgb, np.ndarray):\n        if image_rgb.dtype == np.float32 or image_rgb.dtype == np.float64:\n            image_rgb = (image_rgb * 255).astype(np.uint8)\n        image = Image.fromarray(image_rgb)\n    else:\n        image = image_rgb.copy()\n\n    # Create a drawing context\n    draw = ImageDraw.Draw(image)\n\n    # Try to load a default font, fall back to default if not available\n    try:\n        font = ImageFont.truetype(\"arial.ttf\", 16)\n    except OSError:\n        try:\n            font = ImageFont.load_default()\n        except Exception:\n            font = None\n\n    # Draw ground truth boxes in green\n    for bbox in ground_truth_boxes:\n        x_min, y_min, x_max, y_max = (int(v) for v in bbox)\n\n        # Draw rectangle\n        draw.rectangle(\n            [(x_min, y_min), (x_max, y_max)],\n            outline=\"green\",\n            width=2,\n        )\n\n        # Draw label\n        text = \"GT\"\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width = text_bbox[2] - text_bbox[0]\n        text_height = text_bbox[3] - text_bbox[1]\n\n        # Position text above the box\n        text_x = x_min\n        text_y = max(0, y_min - text_height - 2)\n\n        # Draw text background\n        draw.rectangle(\n            [(text_x, text_y), (text_x + text_width, text_y + text_height)],\n            fill=\"green\",\n        )\n\n        # Draw text\n        draw.text((text_x, text_y), text, fill=\"white\", font=font)\n\n    # Draw detection boxes in blue with confidence\n    for det in detections.detections:\n        x_min, y_min, x_max, y_max = int(det.box.x1), int(det.box.y1), int(det.box.x2), int(det.box.y2)\n\n        # Draw rectangle\n        draw.rectangle(\n            [(x_min, y_min), (x_max, y_max)],\n            outline=\"red\",\n            width=2,\n        )\n\n        # Draw confidence label\n        text = f\"{det.confidence:.2f}\"\n        text_bbox = draw.textbbox((0, 0), text, font=font)\n        text_width = text_bbox[2] - text_bbox[0]\n        text_height = text_bbox[3] - text_bbox[1]\n\n        # Position text above the box\n        text_x = x_min\n        text_y = max(0, y_min - text_height - 2)\n\n        # Draw text background\n        draw.rectangle(\n            [(text_x, text_y), (text_x + text_width, text_y + text_height)],\n            fill=\"red\",\n        )\n\n        # Draw text\n        draw.text((text_x, text_y), text, fill=\"white\", font=font)\n\n    return image\n\n\n# Create comparison visualization\ncomparison_image = visualize_comparison(np.array(detect_image), ground_truth_boxes, result)\n\n# Display the comparison\nplt.figure(figsize=(12, 8))\nplt.imshow(comparison_image)\nplt.axis(\"off\")\nplt.title(\"Ground Truth vs Predictions\\nGreen: Ground Truth\\nRed: Predictions with Confidence\")\nplt.show()\n</code></pre> <p></p> <p>Out:</p> <pre><code>C:/Users/lenova/CascadeProjects/culicidaelab/docs/en/examples/tutorial_part_2_mosquito_detection.py:292: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n  plt.show()\n</code></pre> <p>Total running time of the script: ( 0 minutes  18.595 seconds)</p> <p> Download Python source code: tutorial_part_2_mosquito_detection.py</p> <p> Download Jupyter notebook: tutorial_part_2_mosquito_detection.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/tutorial_part_3_mosquito_segmentation/","title":"Mosquito Segmentation Tutorial","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/tutorial_part_3_mosquito_segmentation/#mosquito-segmentation-tutorial","title":"Mosquito Segmentation Tutorial","text":"<p>This tutorial demonstrates how to use the <code>culicidaelab</code> library to perform mosquito segmentation on images. We'll cover:</p> <ol> <li>Setting up the segmentation model</li> <li>Loading segmentation data from the dataset</li> <li>Running segmentation</li> <li>Visualizing results</li> <li>Evaluating performance with ground truth masks</li> </ol> <p>Install the <code>culicidaelab</code> library if not already installed <pre><code>!pip install -q culicidaelab[full]\n</code></pre> or, if you have access to GPU <pre><code>!pip install -q culicidaelab[full-gpu]\n`\n\n&lt;!-- GENERATED FROM PYTHON SOURCE LINES 43-49 --&gt;\n\n```{.python }\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nfrom culicidaelab import MosquitoSegmenter, MosquitoDetector\nfrom culicidaelab import DatasetsManager, get_settings\n</code></pre></p>"},{"location":"generated/gallery/tutorial_part_3_mosquito_segmentation/#1-initialize-settings-and-load-dataset","title":"1. Initialize Settings and Load Dataset","text":"<p>First, we'll initialize our settings, create MosquitoSegmenter and load the segmentation dataset:</p> <p>Get settings instance and initialize dataset manager</p> <pre><code>settings = get_settings()\nmanager = DatasetsManager(settings)\n\n# Load segmentation dataset\nseg_data = manager.load_dataset(\"segmentation\", split=\"train[:20]\")\n\n# Initialize segmenter and detector\nsegmenter = MosquitoSegmenter(settings=settings, load_model=True)\ndetector = MosquitoDetector(settings=settings, load_model=True)\n</code></pre> <p>Out:</p> <pre><code>Cache hit for split config: train[:20] C:\\Users\\lenova\\AppData\\Local\\culicidaelab\\culicidaelab\\datasets\\mosquito_segmentation\\9e9940e1c673b6f0\n</code></pre>"},{"location":"generated/gallery/tutorial_part_3_mosquito_segmentation/#2-inspect-a-segmentation-sample","title":"2. Inspect a Segmentation Sample","text":"<p>Let's examine a sample from the segmentation dataset to understand its structure:</p> <p>Inspect a segmentation sample</p> <pre><code>seg_sample = seg_data[0]\nseg_image = seg_sample[\"image\"]\nseg_mask = np.array(seg_sample[\"label\"])  # Convert mask to numpy array\n\nprint(f\"Image size: {seg_image.size}\")\nprint(f\"Segmentation mask shape: {seg_mask.shape}\")\nprint(f\"Unique values in mask: {np.unique(seg_mask)}\")  # 0 is background, 1 and above is mosquito\n\n# Create a colored overlay for the mask\n# Where the mask is 1 and above (mosquito), we make it red\noverlay = np.zeros((*seg_mask.shape, 4), dtype=np.uint8)\noverlay[seg_mask &gt;= 1] = [255, 0, 0, 128]  # Red color with 50% opacity\n</code></pre> <p>Out:</p> <pre><code>Image size: (224, 224)\nSegmentation mask shape: (224, 224)\nUnique values in mask: [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72  73  74  75  76  77  78\n  79  80  81  82  83  84  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157\n 158 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237\n 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254]\n</code></pre>"},{"location":"generated/gallery/tutorial_part_3_mosquito_segmentation/#3-run-segmentation-on-dataset-image","title":"3. Run Segmentation on Dataset Image","text":"<p>Now we can run the segmentation model on our dataset image:</p> <p>Run detection to get bounding boxes</p> <pre><code>result = detector.predict(seg_image)\nbboxes = [detection.box.to_numpy() for detection in result.detections]\n# Run segmentation with detection boxes\npredicted_mask = segmenter.predict(seg_image, detection_boxes=np.array(bboxes))\n\n# Create visualizations\nannotated_image = detector.visualize(seg_image, result)\nsegmented_image = segmenter.visualize(annotated_image, predicted_mask)\n</code></pre>"},{"location":"generated/gallery/tutorial_part_3_mosquito_segmentation/#4-visualize-results-with-ground-truth-comparison","title":"4. Visualize Results with Ground Truth Comparison","text":"<p>Let's visualize the segmentation results alongside the ground truth mask:</p> <pre><code>plt.figure(figsize=(20, 10))\n\n# Original image\nplt.subplot(2, 4, 1)\nplt.imshow(seg_image)\nplt.axis(\"off\")\nplt.title(\"Original Image\")\n\n# Ground truth mask\nplt.subplot(2, 4, 2)\nplt.imshow(seg_mask, cmap=\"gray\")\nplt.axis(\"off\")\nplt.title(\"Ground Truth Mask\")\n\n# Ground truth overlay\nplt.subplot(2, 4, 3)\nplt.imshow(seg_image)\nplt.imshow(overlay, alpha=0.5)\nplt.axis(\"off\")\nplt.title(\"Ground Truth Overlay\")\n\n# Detections\nplt.subplot(2, 4, 4)\nplt.imshow(annotated_image)\nplt.axis(\"off\")\nplt.title(\"Detected Mosquitoes\")\n\n# Predicted mask\nplt.subplot(2, 4, 5)\nplt.imshow(predicted_mask.mask, cmap=\"gray\")\nplt.axis(\"off\")\nplt.title(\"Predicted Mask\")\n\n# Predicted overlay\npredicted_overlay = np.zeros((*predicted_mask.mask.shape, 4), dtype=np.uint8)\npredicted_overlay[predicted_mask.mask &gt;= 0.5] = [0, 255, 0, 128]  # Green for predictions\nplt.subplot(2, 4, 6)\nplt.imshow(seg_image)\nplt.imshow(predicted_overlay, alpha=0.5)\nplt.axis(\"off\")\nplt.title(\"Predicted Overlay\")\n\n# Combined overlay (ground truth + predictions)\ncombined_overlay = np.zeros((*predicted_mask.mask.shape, 4), dtype=np.uint8)\ncombined_overlay[seg_mask &gt;= 1] = [255, 0, 0, 128]  # Red for ground truth\ncombined_overlay[predicted_mask.mask &gt;= 0.5] = [0, 255, 0, 128]  # Green for predictions\nplt.subplot(2, 4, 7)\nplt.imshow(seg_image)\nplt.imshow(combined_overlay, alpha=0.5)\nplt.axis(\"off\")\nplt.title(\"Combined Overlay\\n(Red: GT, Green: Pred)\")\n\n# Final segmented image\nplt.subplot(2, 4, 8)\nplt.imshow(segmented_image)\nplt.axis(\"off\")\nplt.title(\"Final Segmented Image\")\n\nplt.tight_layout()\nplt.show()\n</code></pre> <p></p> <p>Out:</p> <pre><code>C:/Users/lenova/CascadeProjects/culicidaelab/docs/en/examples/tutorial_part_3_mosquito_segmentation.py:167: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n  plt.show()\n</code></pre>"},{"location":"generated/gallery/tutorial_part_3_mosquito_segmentation/#5-evaluate-segmentation-performance","title":"5. Evaluate Segmentation Performance","text":"<p>Let's evaluate the segmentation results using the ground truth mask:</p> <pre><code>metrics = segmenter.evaluate(\n    prediction=predicted_mask,\n    ground_truth=seg_mask,\n)\nprint(\"Segmentation Evaluation Metrics:\")\nfor key, value in metrics.items():\n    if isinstance(value, float):\n        print(f\"  {key}: {value:.4f}\")\n    else:\n        print(f\"  {key}: {value}\")\n</code></pre> <p>Out:</p> <pre><code>Segmentation Evaluation Metrics:\n  iou: 0.8464\n  precision: 0.9984\n  recall: 0.8476\n  f1: 0.9168\n</code></pre> <p>Total running time of the script: ( 0 minutes  15.000 seconds)</p> <p> Download Python source code: tutorial_part_3_mosquito_segmentation.py</p> <p> Download Jupyter notebook: tutorial_part_3_mosquito_segmentation.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/tutorial_part_4_mosquito_classification/","title":"Classifying Mosquito Species","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/tutorial_part_4_mosquito_classification/#classifying-mosquito-species","title":"Classifying Mosquito Species","text":"<p>This tutorial demonstrates how to use the <code>MosquitoClassifier</code> from the CulicidaeLab library to identify mosquito species from images. We will walk through the entire process, from loading the model to evaluating its performance on a batch of data.</p> <p>This guide will cover:</p> <ul> <li>Initialization: How to load the settings and the pre-trained model.</li> <li>Data Handling: How to use the <code>DatasetsManager</code> to fetch sample data.</li> <li>Single Image Prediction: How to classify a single mosquito image.</li> <li>Visualization: How to interpret and visualize the model's predictions.</li> <li>Batch Evaluation: How to measure the model's accuracy on a set of test images.</li> <li>Reporting: How to generate and visualize a comprehensive performance report.</li> </ul> <p>Install the <code>culicidaelab</code> library if not already installed <pre><code>!pip install -q culicidaelab[full]\n</code></pre> or, if you have access to GPU <pre><code>!pip install -q culicidaelab[full-gpu]\n`\n\n&lt;!-- GENERATED FROM PYTHON SOURCE LINES 46-57 --&gt;\n\n## 1. Initialization and Setup\n\nOur first step is to set up the necessary components. We will initialize:\n\n- **`settings`**: An object that holds all library configuration, such as\n  model paths and hyperparameters.\n- **`DatasetsManager`**: A helper class to download and manage the sample\n  datasets used in this tutorial.\n- **`MosquitoClassifier`**: The main class for our classification task. We'll\n  pass `load_model=True` to ensure the pre-trained model weights are downloaded\n  and loaded into memory immediately.\n\n&lt;!-- GENERATED FROM PYTHON SOURCE LINES 59-60 --&gt;\n\nImport necessary libraries\n\n&lt;!-- GENERATED FROM PYTHON SOURCE LINES 60-82 --&gt;\n\n```{.python }\nimport matplotlib.pyplot as plt\n\n# Import the required classes from the CulicidaeLab library\nfrom culicidaelab import (\n    DatasetsManager,\n    MosquitoClassifier,\n    get_settings,\n)\n\n# Get the default library settings instance\nsettings = get_settings()\n\n# Initialize the services needed to manage and download data\n\nmanager = DatasetsManager(settings)\n\n# Instantiate the classifier and load the model.\n# This might take a moment on the first run as it downloads the model weights.\nprint(\"Initializing MosquitoClassifier and loading model...\")\nclassifier = MosquitoClassifier(settings, load_model=True)\nprint(\"Model loaded successfully.\")\n</code></pre></p> <p>Out:</p> <pre><code>Initializing MosquitoClassifier and loading model...\nC:\\Users\\lenova\\CascadeProjects\\culicidaelab\\.venv\\Lib\\site-packages\\fastai\\learner.py:455: UserWarning: load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\n  warn(\"load_learner` uses Python's insecure pickle module, which can execute malicious arbitrary code when loading. Only load files you trust.\\nIf you only need to load model weights and optimizer state, use the safe `Learner.load` instead.\")\nModel loaded successfully.\n</code></pre>"},{"location":"generated/gallery/tutorial_part_4_mosquito_classification/#inspecting-model-classes","title":"Inspecting Model Classes","text":"<p>Before we start predicting, it's useful to know which species the model was trained to recognize. We can easily access this information from the settings object.</p> <pre><code>species_map = settings.species_config.species_map\nprint(f\"--- The model can recognize {len(species_map)} classes ---\")\n# Print the first 5 for brevity\nfor idx, name in list(species_map.items())[:5]:\n    print(f\"  Class Index {idx}: {name}\")\nprint(\"  ...\")\n</code></pre> <p>Out:</p> <pre><code>--- The model can recognize 18 classes ---\n  Class Index 0: Aedes aegypti\n  Class Index 1: Aedes albopictus\n  Class Index 2: Aedes canadensis\n  Class Index 3: Aedes dorsalis\n  Class Index 4: Aedes geniculatus\n  ...\n</code></pre>"},{"location":"generated/gallery/tutorial_part_4_mosquito_classification/#2-loading-the-test-dataset","title":"2. Loading the Test Dataset","text":"<p>For this tutorial, we will use a built-in test dataset provided by the library. The <code>DatasetsManager</code> makes it simple to download and load this data. The dataset contains images and their corresponding correct labels, which we will use for prediction and later for evaluation.</p> <pre><code>print(\"\\n--- Loading the 'classification' dataset's 'test' split ---\")\nclassification_test_data = manager.load_dataset(\"classification\", split=\"test\")\nprint(\"Test dataset loaded successfully!\")\nprint(f\"Number of samples in the test dataset: {len(classification_test_data)}\")\n\n# Let's select one sample to work with.\n# The sample is a dictionary containing the image and its ground truth label.\nclassification_test_data = classification_test_data.shuffle(seed=35)\nsample_index = 285\nsample = classification_test_data[sample_index]\nimage = sample[\"image\"]\nground_truth_label = sample[\"label\"]\n\nprint(f\"\\nSelected sample's ground truth label: '{ground_truth_label}'\")\n\n# Display the input image\nplt.figure(figsize=(6, 6))\nplt.imshow(image)\nplt.title(f\"Input Image\\n(Ground Truth: {ground_truth_label})\")\nplt.axis(\"off\")\nplt.show()\n</code></pre> <p></p> <p>Out:</p> <pre><code>--- Loading the 'classification' dataset's 'test' split ---\nCache hit for split config: test C:\\Users\\lenova\\AppData\\Local\\culicidaelab\\culicidaelab\\datasets\\mosquito_species_classification\\4d967a30111bf29f\nTest dataset loaded successfully!\nNumber of samples in the test dataset: 328\n\nSelected sample's ground truth label: 'culex_pipiens'\nC:/Users/lenova/CascadeProjects/culicidaelab/docs/en/examples/tutorial_part_4_mosquito_classification.py:126: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n  plt.show()\n</code></pre>"},{"location":"generated/gallery/tutorial_part_4_mosquito_classification/#3-classifying-a-single-image","title":"3. Classifying a Single Image","text":"<p>Now we'll use the classifier to predict the species of the mosquito in our selected image. The <code>predict()</code> method takes an image (as a NumPy array, file path, or PIL Image) and returns a list of predictions, sorted from most to least confident.</p> <p>Run the classification on our sample image</p> <pre><code>result = classifier.predict(image)\n\n# Print the top 5 predictions in a readable format\nprint(\"--- Top 5 Predictions ---\")\nfor p in result.predictions[:5]:\n    print(f\"{p.species_name}: {p.confidence:.2%}\")\n</code></pre> <p>Out:</p> <pre><code>\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n--- Top 5 Predictions ---\nCulex pipiens: 100.00%\nCulex quinquefasciatus: 0.00%\nAedes canadensis: 0.00%\nCulex inatomii: 0.00%\nCulex tritaeniorhynchus: 0.00%\n</code></pre>"},{"location":"generated/gallery/tutorial_part_4_mosquito_classification/#4-visualizing-and-interpreting-the-results","title":"4. Visualizing and Interpreting the Results","text":"<p>A raw list of predictions is useful, but visualizations make the results much easier to understand. We'll create two plots:</p> <ol> <li>A Bar Plot: This shows the model's confidence for every possible     species. It's great for seeing not just the top prediction, but also which     other species the model considered.</li> <li>A Composite Image: This uses the built-in <code>visualize()</code> method to create     a clean image that displays the top predictions alongside the input image.</li> </ol> <p>Create a bar plot to visualize the probabilities for all species</p> <pre><code>plt.figure(figsize=(10, 8))\n\n# The predictions are already sorted, so we can plot them directly\nspecies_names = [p.species_name for p in result.predictions]\nprobabilities = [p.confidence for p in result.predictions]\n\n# We'll reverse the lists (`[::-1]`) so the highest probability is at the top\nbars = plt.barh(species_names[::-1], probabilities[::-1])\n\n# Highlight the bars that meet our confidence threshold\nconf_threshold = settings.get_config(\"predictors.classifier.confidence\")\nfor bar in bars:\n    if bar.get_width() &gt;= conf_threshold:\n        bar.set_color(\"teal\")\n    else:\n        bar.set_color(\"lightgray\")\n\n# Add a reference line for the confidence threshold\nplt.axvline(\n    x=conf_threshold,\n    color=\"red\",\n    linestyle=\"--\",\n    label=f\"Confidence Threshold ({conf_threshold:.0%})\",\n)\nplt.xlabel(\"Assigned Probability\")\nplt.title(\"Species Classification Probabilities\")\nplt.legend()\nplt.tight_layout()\nplt.show()\n</code></pre> <p></p> <p>Out:</p> <pre><code>C:/Users/lenova/CascadeProjects/culicidaelab/docs/en/examples/tutorial_part_4_mosquito_classification.py:188: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n  plt.show()\n</code></pre> <p>Now, let's use the built-in visualizer for a clean presentation</p> <pre><code>annotated_image = classifier.visualize(image, result)\n\n# Display the final annotated image\nplt.figure(figsize=(10, 6))\nplt.imshow(annotated_image)\nplt.title(\"Classification Result\")\nplt.axis(\"off\")\nplt.show()\n</code></pre> <p></p> <p>Out:</p> <pre><code>C:/Users/lenova/CascadeProjects/culicidaelab/docs/en/examples/tutorial_part_4_mosquito_classification.py:199: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n  plt.show()\n</code></pre>"},{"location":"generated/gallery/tutorial_part_4_mosquito_classification/#5-evaluating-model-performance-on-a-batch","title":"5. Evaluating Model Performance on a Batch","text":"<p>While classifying a single image is useful, a more rigorous test involves evaluating the model's performance across an entire dataset. The <code>evaluate_batch()</code> method is designed for this. It processes a batch of images and their corresponding ground truth labels, then computes aggregate metrics.</p> <p>The result is a <code>report</code> dictionary containing key metrics like mean accuracy and a confusion matrix, which shows exactly where the model is succeeding or failing.</p> <p>Let's evaluate the first 30 images from the test set for this example</p> <pre><code>num_samples_to_evaluate = 30\nbatch_samples = classification_test_data.select(range(num_samples_to_evaluate))\nbatch_images = [sample[\"image\"] for sample in batch_samples]\nground_truths = [sample[\"label\"] for sample in batch_samples]\n\nprint(f\"\\n--- Evaluating a batch of {len(batch_images)} images ---\")\n\n# Run the batch evaluation.\n# The method can take images and ground truths separately, or it can\n# run predictions internally if you only provide the images.\nreport = classifier.evaluate_batch(\n    input_data_batch=batch_images,\n    ground_truth_batch=ground_truths,\n    show_progress=True,\n)\n\nprint(\"\\n--- Evaluation Report Summary ---\")\nfor key, value in report.items():\n    if key != \"confusion_matrix\":\n        # Check if value is a float before formatting\n        if isinstance(value, float):\n            print(f\"  {key}: {value:.4f}\")\n        else:\n            print(f\"  {key}: {value}\")\n</code></pre> <p>Out:</p> <pre><code>--- Evaluating a batch of 30 images ---\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/30 00:00&lt;?]\n\n |\u2588\u2588----------------------------------------------------------| 3.33% [1/30 00:00&lt;00:00]\n\n |\u2588\u2588\u2588\u2588--------------------------------------------------------| 6.67% [2/30 00:00&lt;00:00]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588------------------------------------------------------| 10.00% [3/30 00:00&lt;00:00]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588----------------------------------------------------| 13.33% [4/30 00:00&lt;00:00]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588--------------------------------------------------| 16.67% [5/30 00:00&lt;00:00]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [30/30 00:00&lt;00:00]\nC:\\Users\\lenova\\CascadeProjects\\culicidaelab\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n  warnings.warn(\nC:\\Users\\lenova\\CascadeProjects\\culicidaelab\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n  warnings.warn(\nC:\\Users\\lenova\\CascadeProjects\\culicidaelab\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n  warnings.warn(\nC:\\Users\\lenova\\CascadeProjects\\culicidaelab\\.venv\\Lib\\site-packages\\sklearn\\metrics\\_ranking.py:424: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.\n  warnings.warn(\n\n--- Evaluation Report Summary ---\n  accuracy_mean: 0.9667\n  accuracy_std: 0.1795\n  top_1_correct_mean: 0.9667\n  top_1_correct_std: 0.1795\n  confidence_mean: 0.9960\n  confidence_std: 0.0095\n  top_5_correct_mean: 1.0000\n  top_5_correct_std: 0.0000\n  count: 30\n  roc_auc: nan\n</code></pre>"},{"location":"generated/gallery/tutorial_part_4_mosquito_classification/#6-visualizing-the-evaluation-report","title":"6. Visualizing the Evaluation Report","text":"<p>The generated <code>report</code> dictionary contains a wealth of information, but the confusion matrix is best understood visually. The <code>visualize_report()</code> method creates a comprehensive plot that summarizes the evaluation results.</p> <p>How to read the confusion matrix: - Each row represents the actual ground truth species. - Each column represents the species that the model predicted. - The diagonal (from top-left to bottom-right) shows the number of correct   predictions for each class. - Off-diagonal numbers indicate misclassifications. For example, a number   in row \"A\" and column \"B\" means an image of species A was incorrectly   classified as species B.</p> <p>Pass the report dictionary to the visualization function</p> <pre><code>classifier.visualize_report(report)\n</code></pre> <p></p> <p>Out:</p> <pre><code>C:\\Users\\lenova\\CascadeProjects\\culicidaelab\\culicidaelab\\predictors\\classifier.py:285: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n  plt.show()\n</code></pre>"},{"location":"generated/gallery/tutorial_part_4_mosquito_classification/#7-batch-prediction-for-efficiency","title":"7. Batch Prediction for Efficiency","text":"<p>If your goal is to classify many images using <code>predict_batch()</code> is much more efficient than looping over <code>predict()</code>, if it leverages the GPU to process images in parallel, results will be returned in a significant speed-up.</p> <p>We'll use the same small batch from our evaluation example</p> <pre><code>print(\n    f\"\\n--- Classifying a batch of {len(batch_images)} images with predict_batch ---\",\n)\nbatch_predictions = classifier.predict_batch(batch_images, show_progress=True)\n\nprint(\"\\n--- Batch Classification Results (Top prediction for each image) ---\")\nfor i, single_image_preds in enumerate(batch_predictions):\n    if single_image_preds:  # Check if the prediction list is not empty\n        top_pred_species = single_image_preds.predictions[0].species_name\n        top_pred_conf = single_image_preds.predictions[0].confidence\n        print(\n            f\"  - Image {i+1} (GT: {ground_truths[i]}): \"\n            f\"Predicted '{top_pred_species}' with {top_pred_conf:.2%} confidence.\",\n        )\n    else:\n        print(f\"  - Image {i+1} (GT: {ground_truths[i]}): Prediction failed.\")\n</code></pre> <p>Out:</p> <pre><code>--- Classifying a batch of 30 images with predict_batch ---\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\u2588\n\n |------------------------------------------------------------| 0.00% [0/1 00:00&lt;?]\n\n |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 100.00% [1/1 00:00&lt;00:00]\n\n\n\n\n\n--- Batch Classification Results (Top prediction for each image) ---\n  - Image 1 (GT: aedes_aegypti): Predicted 'Aedes aegypti' with 100.00% confidence.\n  - Image 2 (GT: culex_tritaeniorhynchus): Predicted 'Culex tritaeniorhynchus' with 99.95% confidence.\n  - Image 3 (GT: aedes_koreicus): Predicted 'Aedes koreicus' with 100.00% confidence.\n  - Image 4 (GT: culiseta_annulata): Predicted 'Culiseta annulata' with 100.00% confidence.\n  - Image 5 (GT: aedes_albopictus): Predicted 'Aedes albopictus' with 100.00% confidence.\n  - Image 6 (GT: aedes_aegypti): Predicted 'Aedes aegypti' with 98.94% confidence.\n  - Image 7 (GT: aedes_vexans): Predicted 'Aedes vexans' with 100.00% confidence.\n  - Image 8 (GT: aedes_dorsalis): Predicted 'Aedes dorsalis' with 99.96% confidence.\n  - Image 9 (GT: aedes_albopictus): Predicted 'Aedes albopictus' with 100.00% confidence.\n  - Image 10 (GT: culiseta_annulata): Predicted 'Culiseta annulata' with 100.00% confidence.\n  - Image 11 (GT: aedes_vexans): Predicted 'Aedes vexans' with 100.00% confidence.\n  - Image 12 (GT: aedes_albopictus): Predicted 'Aedes albopictus' with 100.00% confidence.\n  - Image 13 (GT: culex_inatomii): Predicted 'Culex inatomii' with 100.00% confidence.\n  - Image 14 (GT: culiseta_longiareolata): Predicted 'Culiseta longiareolata' with 98.63% confidence.\n  - Image 15 (GT: anopheles_sinensis): Predicted 'Anopheles sinensis' with 100.00% confidence.\n  - Image 16 (GT: aedes_aegypti): Predicted 'Aedes aegypti' with 100.00% confidence.\n  - Image 17 (GT: aedes_aegypti): Predicted 'Aedes aegypti' with 100.00% confidence.\n  - Image 18 (GT: culiseta_annulata): Predicted 'Culiseta annulata' with 99.98% confidence.\n  - Image 19 (GT: culex_tritaeniorhynchus): Predicted 'Culex tritaeniorhynchus' with 95.28% confidence.\n  - Image 20 (GT: aedes_albopictus): Predicted 'Aedes albopictus' with 100.00% confidence.\n  - Image 21 (GT: aedes_vexans): Predicted 'Aedes vexans' with 98.64% confidence.\n  - Image 22 (GT: culex_tritaeniorhynchus): Predicted 'Culex tritaeniorhynchus' with 100.00% confidence.\n  - Image 23 (GT: aedes_albopictus): Predicted 'Aedes aegypti' with 98.10% confidence.\n  - Image 24 (GT: culex_pipiens): Predicted 'Culex pipiens' with 100.00% confidence.\n  - Image 25 (GT: aedes_triseriatus): Predicted 'Aedes triseriatus' with 99.98% confidence.\n  - Image 26 (GT: aedes_dorsalis): Predicted 'Aedes dorsalis' with 99.97% confidence.\n  - Image 27 (GT: aedes_vexans): Predicted 'Aedes vexans' with 100.00% confidence.\n  - Image 28 (GT: aedes_canadensis): Predicted 'Aedes canadensis' with 99.26% confidence.\n  - Image 29 (GT: aedes_aegypti): Predicted 'Aedes aegypti' with 99.41% confidence.\n  - Image 30 (GT: culex_pipiens): Predicted 'Culex pipiens' with 100.00% confidence.\n</code></pre> <p>Total running time of the script: ( 0 minutes  30.130 seconds)</p> <p> Download Python source code: tutorial_part_4_mosquito_classification.py</p> <p> Download Jupyter notebook: tutorial_part_4_mosquito_classification.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"generated/gallery/tutorial_part_5_serve_module/","title":"Using the Serve Module for Production Inference","text":"<p>Note</p> <p>Click here to download the full example code</p>"},{"location":"generated/gallery/tutorial_part_5_serve_module/#using-the-serve-module-for-production-inference","title":"Using the Serve Module for Production Inference","text":"<p>This tutorial demonstrates how to use the <code>serve</code> function from the CulicidaeLab library for high-performance, production-ready inference. The <code>serve</code> function is designed to be a lightweight, fast, and safe way to run predictions.</p> <p>This guide will cover:</p> <ul> <li>Speed and Safety: How the <code>serve</code> function uses the ONNX backend for fast inference.</li> <li>Single Image Prediction: How to use <code>serve</code> for classification.</li> <li>Caching: Understand the in-memory caching for predictor instances.</li> <li>Clearing the Cache: How to clear the cache when needed.</li> </ul> <p>Install the <code>culicidaelab</code> library if not already installed</p>"},{"location":"generated/gallery/tutorial_part_5_serve_module/#pip-install-q-culicidaelab","title":"!pip install -q culicidaelab","text":""},{"location":"generated/gallery/tutorial_part_5_serve_module/#1-initialization-and-setup","title":"1. Initialization and Setup","text":"<p>We will initialize the <code>DatasetsManager</code> to get some sample data. The <code>serve</code> function doesn't require manual initialization of predictors.</p> <p>Import necessary libraries</p> <pre><code>import matplotlib.pyplot as plt\n\n# Import the required classes from the CulicidaeLab library\nfrom culicidaelab import (\n    DatasetsManager,\n    get_settings,\n    serve,\n    clear_serve_cache,\n)\n\n# Get the default library settings instance\nsettings = get_settings()\n\n# Initialize the services needed to manage and download data\nmanager = DatasetsManager(settings)\n</code></pre>"},{"location":"generated/gallery/tutorial_part_5_serve_module/#2-loading-the-test-dataset","title":"2. Loading the Test Dataset","text":"<p>We will use a built-in test dataset to get an image for our predictions.</p> <pre><code>print(\"--- Loading the 'classification' dataset's 'test' split ---\")\nclassification_test_data = manager.load_dataset(\"classification\", split=\"test\")\nprint(\"Test dataset loaded successfully!\")\nprint(f\"Number of samples in the test dataset: {len(classification_test_data)}\")\n\n# Let's select one sample to work with.\nclassification_test_data = classification_test_data.shuffle(seed=42)\nsample = classification_test_data[0]\nimage = sample[\"image\"]\nground_truth_label = sample[\"label\"]\n\nprint(f\"\\nSelected sample's ground truth label: '{ground_truth_label}'\")\n\n# Display the input image\nplt.figure(figsize=(6, 6))\nplt.imshow(image)\nplt.title(f\"Input Image\\n(Ground Truth: {ground_truth_label})\")\nplt.axis(\"off\")\nplt.show()\n</code></pre> <p></p> <p>Out:</p> <pre><code>--- Loading the 'classification' dataset's 'test' split ---\nCache hit for split config: test C:\\Users\\lenova\\AppData\\Local\\culicidaelab\\culicidaelab\\datasets\\mosquito_species_classification\\4d967a30111bf29f\nTest dataset loaded successfully!\nNumber of samples in the test dataset: 328\n\nSelected sample's ground truth label: 'aedes_triseriatus'\nC:/Users/lenova/CascadeProjects/culicidaelab/docs/en/examples/tutorial_part_5_serve_module.py:85: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n  plt.show()\n</code></pre>"},{"location":"generated/gallery/tutorial_part_5_serve_module/#3-using-serve-for-classification","title":"3. Using <code>serve</code> for Classification","text":"<p>The <code>serve</code> function automatically initializes the predictor with the ONNX backend on the first call and caches it for subsequent requests.</p> <p>Run classification using the serve function</p> <pre><code>print(\"--- Running classification for the first time (will initialize predictor) ---\")\nclassification_result = serve(image)\n\n# Print the top 5 predictions\nprint(\"\\n--- Top 5 Classification Predictions ---\")\nfor p in classification_result.predictions[:5]:\n    print(f\"{p.species_name}: {p.confidence:.2%}\")\n</code></pre> <p>Out:</p> <pre><code>--- Running classification for the first time (will initialize predictor) ---\nInitializing 'classifier' predictor for serving...\n\n--- Top 5 Classification Predictions ---\nAedes triseriatus: 99.81%\nAedes geniculatus: 0.19%\nCuliseta longiareolata: 0.00%\nAedes canadensis: 0.00%\nCulex pipiens: 0.00%\n</code></pre>"},{"location":"generated/gallery/tutorial_part_5_serve_module/#4-caching-in-action","title":"4. Caching in Action","text":"<p>If you run the same request again, you'll notice it's much faster because the predictor is already in memory.</p> <p>Run classification again to see the caching effect</p> <pre><code>print(\"\\n--- Running classification for the second time (should be faster) ---\")\nclassification_result_cached = serve(image, predictor_type=\"classifier\")\n\n# Print the top 5 predictions again\nprint(\"\\n--- Top 5 Classification Predictions (from cache) ---\")\nfor p in classification_result_cached.predictions[:5]:\n    print(f\"{p.species_name}: {p.confidence:.2%}\")\n</code></pre> <p>Out:</p> <pre><code>--- Running classification for the second time (should be faster) ---\n\n--- Top 5 Classification Predictions (from cache) ---\nAedes triseriatus: 99.81%\nAedes geniculatus: 0.19%\nCuliseta longiareolata: 0.00%\nAedes canadensis: 0.00%\nCulex pipiens: 0.00%\n</code></pre>"},{"location":"generated/gallery/tutorial_part_5_serve_module/#5-clearing-the-cache","title":"5. Clearing the Cache","text":"<p>If you need to free up memory or reload the predictors, you can use the <code>clear_serve_cache</code> function.</p> <p>Clear the cache</p> <pre><code>print(\"\\n--- Clearing the predictor cache ---\")\nclear_serve_cache()\n\n# Run classification again, it will re-initialize the predictor\nprint(\"\\n--- Running classification again after clearing cache (will re-initialize) ---\")\nclassification_result_after_clear = serve(image)\n\nprint(\"\\n--- Top 5 Classification Predictions (after cache clear) ---\")\nfor p in classification_result_after_clear.predictions[:5]:\n    print(f\"{p.species_name}: {p.confidence:.2%}\")\n</code></pre> <p>Out:</p> <pre><code>--- Clearing the predictor cache ---\n\n--- Running classification again after clearing cache (will re-initialize) ---\nInitializing 'classifier' predictor for serving...\n\n--- Top 5 Classification Predictions (after cache clear) ---\nAedes triseriatus: 99.81%\nAedes geniculatus: 0.19%\nCuliseta longiareolata: 0.00%\nAedes canadensis: 0.00%\nCulex pipiens: 0.00%\n</code></pre> <p>Total running time of the script: ( 0 minutes  2.157 seconds)</p> <p> Download Python source code: tutorial_part_5_serve_module.py</p> <p> Download Jupyter notebook: tutorial_part_5_serve_module.ipynb</p> <p>Gallery generated by mkdocs-gallery</p>"},{"location":"user_manual/user_manual/","title":"CulicidaeLab User Guide","text":"<p>Welcome to the <code>CulicidaeLab</code> User Guide! This guide will walk you through the essential features of the library, showing you how to perform mosquito detection, classification, and segmentation. We will cover everything from initial setup to running predictions and visualizing the results.</p>"},{"location":"user_manual/user_manual/#1-before-you-begin-core-concepts","title":"1. Before You Begin: Core Concepts","text":""},{"location":"user_manual/user_manual/#the-settings-object","title":"The <code>settings</code> Object","text":"<p>The single most important concept in <code>CulicidaeLab</code> is the <code>settings</code> object. It is your centralized entry point for everything. Instead of importing and initializing each component manually with complex parameters, you simply:</p> <ol> <li>Get the <code>settings</code> object.</li> <li>Ask it to create the component you need (<code>Detector</code>, <code>Classifier</code>, etc.).</li> </ol> <p>The <code>settings</code> object automatically handles loading configurations, managing file paths, downloading models, and selecting the optimal backend for your use case.</p>"},{"location":"user_manual/user_manual/#the-predictor-workflow","title":"The Predictor Workflow","text":"<p>All three main components (<code>MosquitoDetector</code>, <code>MosquitoClassifier</code>, <code>MosquitoSegmenter</code>) are Predictors. They share a consistent and predictable workflow:</p> <ol> <li>Initialize: Create an instance using the simplified constructor that automatically selects the best backend.</li> <li>Load Model: The model weights are lazy-loaded, meaning they are only downloaded and loaded into memory on the first prediction or when you explicitly tell them to. We will use <code>load_model=True</code> for clarity.</li> <li>Predict: Use the <code>.predict()</code> method on an image to get structured, type-safe results.</li> <li>Visualize: Use the <code>.visualize()</code> method to see the results.</li> </ol>"},{"location":"user_manual/user_manual/#structured-prediction-outputs","title":"Structured Prediction Outputs","text":"<p>CulicidaeLab now returns structured prediction results instead of simple tuples or lists. This means:</p> <ul> <li>Type Safety: All outputs are validated Pydantic models with clear structure</li> <li>Easy Access: Use convenient methods like <code>.top_prediction()</code> for classification results</li> <li>Rich Information: Each prediction includes confidence scores, bounding boxes, and metadata</li> <li>JSON Serializable: Perfect for web APIs and data storage</li> </ul>"},{"location":"user_manual/user_manual/#automatic-backend-selection","title":"Automatic Backend Selection","text":"<p>The library automatically chooses the best backend for your needs:</p> <ul> <li>Development Mode: Uses PyTorch for full flexibility and debugging capabilities</li> <li>Production Mode: Automatically selects ONNX for optimal performance and smaller memory footprint</li> <li>Transparent: The same prediction API works regardless of the backend</li> </ul> <p>Let's get started!</p>"},{"location":"user_manual/user_manual/#2-initialization-and-setup","title":"2. Initialization and Setup","text":"<p>First, let's set up our environment and get the all-important <code>settings</code> object.</p> <pre><code># Import necessary libraries for image handling and plotting\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\nimport numpy as np\n\n# Import the main CulicidaeLab components\nfrom culicidaelab import get_settings, MosquitoDetector, MosquitoClassifier, MosquitoSegmenter\n\n# Get the central settings object.\n# This single object will be used to initialize all other components.\nsettings = get_settings()\n\nprint(\"CulicidaeLab settings initialized successfully.\")\n</code></pre>"},{"location":"user_manual/user_manual/#3-mosquito-detection","title":"3. Mosquito Detection","text":"<p>The first step in many analysis pipelines is to find out if a mosquito is in the image and where it is. This is the job of the <code>MosquitoDetector</code>.</p>"},{"location":"user_manual/user_manual/#31-initializing-the-detector-and-loading-an-image","title":"3.1. Initializing the Detector and Loading an Image","text":"<p>When we initialize the detector with <code>load_model=True</code>, the library checks if the YOLO model weights are present locally. If not, they will be automatically downloaded and cached for all future uses.</p> <pre><code># Initialize the detector.\n# With load_model=True, the model weights will be loaded into memory.\nprint(\"Initializing MosquitoDetector...\")\ndetector = MosquitoDetector(settings=settings, load_model=True)\nprint(\"Detector model loaded and ready.\")\n\n# Let's load a test image to work with.\n# Make sure to replace this path with the path to your own image.\nimage_path = Path(\"test_imgs\") / \"640px-Aedes_aegypti.jpg\"\n\n# CulicidaeLab accepts various image input formats:\n# - File path (str or Path)\n# - PIL Image (already in RGB)\n# - NumPy array\n# - Image bytes\n# For simplicity, we use PIL Image which is already in RGB mode\nimage = Image.open(image_path)\nimage_rgb = np.array(image)\n</code></pre>"},{"location":"user_manual/user_manual/#32-performing-detection","title":"3.2. Performing Detection","text":"<p>The <code>predict</code> method takes an image as input and returns a structured <code>DetectionPrediction</code> object containing all detected mosquitoes. Each detection includes a bounding box, confidence score, and additional metadata in a type-safe format.</p> <pre><code># Run the prediction on our RGB image\nresult = detector.predict(image_rgb)\n\n# Let's print the results in a human-readable format.\nprint(\"\\nDetection Results:\")\nif result.detections:\n    for i, detection in enumerate(result.detections):\n        bbox = detection.box\n        conf = detection.confidence\n        print(\n            f\"  - Mosquito {i+1}: Confidence = {conf:.2f}, \"\n            f\"Box = (x1={bbox.x1:.1f}, y1={bbox.y1:.1f}, \"\n            f\"x2={bbox.x2:.1f}, y2={bbox.y2:.1f})\"\n        )\nelse:\n    print(\"  No mosquitoes were detected in the image.\")\n</code></pre>"},{"location":"user_manual/user_manual/#33-visualizing-detection-results","title":"3.3. Visualizing Detection Results","text":"<p>Reading coordinates is useful, but seeing the result is better. The <code>.visualize()</code> method draws the bounding boxes and confidence scores directly onto the image.</p> <pre><code># Pass the original image and the detection result to the visualize method\nannotated_image = detector.visualize(image_rgb, result)\n\n# Use matplotlib to display the final image\nplt.figure(figsize=(10, 7))\nplt.imshow(annotated_image)\nplt.axis(\"off\")\nplt.title(\"Detected Mosquitoes\")\nplt.show()\n</code></pre>"},{"location":"user_manual/user_manual/#4-mosquito-species-classification","title":"4. Mosquito Species Classification","text":"<p>Once you have an image of a mosquito, the next question is often, \"What species is it?\" The <code>MosquitoClassifier</code> is trained to answer this.</p>"},{"location":"user_manual/user_manual/#41-initializing-the-classifier","title":"4.1. Initializing the Classifier","text":"<p>Similar to the detector, we initialize the classifier from the <code>settings</code> object. The corresponding classification model will be downloaded on first use.</p> <pre><code># Initialize the classifier\nprint(\"\\nInitializing MosquitoClassifier...\")\nclassifier = MosquitoClassifier(settings=settings, load_model=True)\nprint(\"Classifier model loaded and ready.\")\n\n# For this example, we'll use the same image we used for detection.\n# In a real application, you might use a cropped image from the detector's output.\n</code></pre>"},{"location":"user_manual/user_manual/#42-performing-classification","title":"4.2. Performing Classification","text":"<p>The classifier's <code>predict</code> method returns a structured <code>ClassificationPrediction</code> object containing all possible species predictions, sorted by confidence score. You can easily access the top prediction or iterate through all predictions.</p> <pre><code># Run the classification\nresult = classifier.predict(image_rgb)\n\n# Print the top prediction using the convenient method\ntop_pred = result.top_prediction()\nif top_pred:\n    print(f\"\\nTop Prediction: {top_pred.species_name} ({top_pred.confidence:.4f})\")\n\n# Print the top 3 most likely species\nprint(\"\\nTop 3 Predictions:\")\nfor prediction in result.predictions[:3]:\n    print(f\"- {prediction.species_name}: {prediction.confidence:.4f}\")\n</code></pre>"},{"location":"user_manual/user_manual/#43-interpreting-and-visualizing-classification-results","title":"4.3. Interpreting and Visualizing Classification Results","text":"<p>A bar chart is a great way to understand the model's confidence across all potential species. Let's visualize the top 5 predictions using the structured prediction format.</p> <pre><code># Extract the names and probabilities of the top 5 predictions for our chart\ntop_5_predictions = result.predictions[:5]\nspecies_names = [pred.species_name for pred in top_5_predictions]\nprobabilities = [pred.confidence for pred in top_5_predictions]\n\n# Create a horizontal bar plot\nplt.figure(figsize=(10, 6))\nplt.barh(species_names, probabilities, color=\"skyblue\")\nplt.xlabel(\"Probability\")\nplt.title(\"Species Classification Probabilities (Top 5)\")\nplt.gca().invert_yaxis()  # Invert axis to show the most likely result at the top\n\n# Add the probability values as text on the bars for clarity\nfor index, value in enumerate(probabilities):\n    plt.text(value, index, f\" {value:.2%}\", va='center')\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"user_manual/user_manual/#5-mosquito-segmentation","title":"5. Mosquito Segmentation","text":"<p>Segmentation goes one step further than detection. Instead of just a box, it provides a precise, pixel-level mask outlining the exact shape of the mosquito.</p>"},{"location":"user_manual/user_manual/#51-initializing-the-segmenter","title":"5.1. Initializing the Segmenter","text":"<p>Again, we initialize our <code>MosquitoSegmenter</code> from the <code>settings</code> object.</p> <pre><code># Initialize the segmenter\nprint(\"\\nInitializing MosquitoSegmenter...\")\nsegmenter = MosquitoSegmenter(settings=settings, load_model=True)\nprint(\"Segmenter model loaded and ready.\")\n</code></pre>"},{"location":"user_manual/user_manual/#52-performing-segmentation","title":"5.2. Performing Segmentation","text":"<p>The <code>predict</code> method returns a structured <code>SegmentationPrediction</code> object containing the binary mask and additional metadata. The mask is a 2D numpy array where pixels belonging to the mosquito are marked as <code>True</code> (or <code>255</code>), while background pixels are <code>False</code> (or <code>0</code>).</p> <p>There are two ways to perform segmentation:</p>"},{"location":"user_manual/user_manual/#method-1-basic-segmentation","title":"Method 1: Basic Segmentation","text":"<p>You can run the segmenter on the whole image. It will try to find and segment the most prominent object.</p> <pre><code>print(\"\\n--- Performing basic segmentation on the full image ---\")\nbasic_result = segmenter.predict(image_rgb)\nbasic_mask = basic_result.mask\nprint(\"Basic segmentation complete.\")\n</code></pre>"},{"location":"user_manual/user_manual/#method-2-detection-guided-segmentation-recommended","title":"Method 2: Detection-Guided Segmentation (Recommended)","text":"<p>For the best results, you can pass the detection result obtained from the <code>MosquitoDetector</code>. This tells the segmenter exactly where to look, resulting in a more accurate and cleaner mask.</p> <pre><code># We'll use the detection results from the detector earlier\n# Convert detections to the format expected by the segmenter\ndetection_boxes = [detection.box.to_numpy() for detection in result.detections]\n\nprint(\"\\n--- Performing segmentation using detection boxes as a guide ---\")\nguided_result = segmenter.predict(image_rgb, detection_boxes=detection_boxes)\nguided_mask = guided_result.mask\nprint(\"Guided segmentation complete.\")\n</code></pre>"},{"location":"user_manual/user_manual/#53-visualizing-segmentation-results","title":"5.3. Visualizing Segmentation Results","text":"<p>The <code>.visualize()</code> method is perfect for seeing the final mask overlaid on the original image.</p> <pre><code># Visualize the more accurate, guided segmentation result\nsegmented_image = segmenter.visualize(image_rgb, guided_result)\n\n# Display the original image, the mask itself, and the final overlay\nplt.figure(figsize=(18, 6))\n\nplt.subplot(1, 3, 1)\nplt.imshow(image_rgb)\nplt.axis(\"off\")\nplt.title(\"Original Image\")\n\nplt.subplot(1, 3, 2)\nplt.imshow(guided_mask, cmap=\"gray\")\nplt.axis(\"off\")\nplt.title(\"Segmentation Mask (Guided)\")\n\nplt.subplot(1, 3, 3)\nplt.imshow(segmented_image)\nplt.axis(\"off\")\nplt.title(\"Segmented Overlay\")\n\nplt.tight_layout()\nplt.show()\n</code></pre>"},{"location":"user_manual/user_manual/#6-advanced-features-and-production-deployment","title":"6. Advanced Features and Production Deployment","text":""},{"location":"user_manual/user_manual/#61-high-performance-serve-api","title":"6.1. High-Performance Serve API","text":"<p>For production applications and high-throughput scenarios, CulicidaeLab provides a dedicated <code>serve</code> API that offers significant performance improvements through automatic ONNX backend selection and intelligent caching.</p>"},{"location":"user_manual/user_manual/#basic-serve-api-usage","title":"Basic Serve API Usage","text":"<pre><code>from culicidaelab.serve import serve, clear_serve_cache\n\n# The serve API accepts the same image formats as regular predictors:\n# - File paths (str or Path): \"image.jpg\"\n# - PIL Images: Image.open(\"image.jpg\")\n# - NumPy arrays: np.array(image)\n# - Image bytes: image_bytes\n\n# Fast classification - automatically uses ONNX backend\nresult = serve(\"mosquito.jpg\", predictor_type=\"classifier\")\nspecies = result.top_prediction().species_name\nconfidence = result.top_prediction().confidence\n\nprint(f\"Species: {species} (Confidence: {confidence:.2%})\")\n\n# Fast detection with confidence threshold\nresult = serve(\"image.jpg\", predictor_type=\"detector\", confidence_threshold=0.7)\nprint(f\"Found {len(result.detections)} mosquitoes\")\n\n# Fast segmentation\nresult = serve(\"image.jpg\", predictor_type=\"segmenter\")\nmask = result.mask\nprint(f\"Segmentation mask shape: {mask.shape}\")\n\n# Clean up resources when done\nclear_serve_cache()\n</code></pre>"},{"location":"user_manual/user_manual/#performance-comparison","title":"Performance Comparison","text":"<p>The serve API provides substantial performance improvements, especially for repeated predictions:</p> <pre><code>import time\nfrom culicidaelab.serve import serve, clear_serve_cache\n\n# Traditional approach\nclassifier = MosquitoClassifier(settings=settings, load_model=True)\nstart = time.time()\nresult1 = classifier.predict(\"image.jpg\")\ntraditional_time = time.time() - start\n\n# Serve API - first call (loads model)\nstart = time.time()\nresult2 = serve(\"image.jpg\", predictor_type=\"classifier\")\nserve_first_time = time.time() - start\n\n# Serve API - subsequent calls (uses cache)\nstart = time.time()\nresult3 = serve(\"image.jpg\", predictor_type=\"classifier\")\nserve_cached_time = time.time() - start\n\nprint(f\"Traditional: {traditional_time:.3f}s\")\nprint(f\"Serve (first): {serve_first_time:.3f}s\")\nprint(f\"Serve (cached): {serve_cached_time:.3f}s\")  # Typically 10-100x faster\n\nclear_serve_cache()\n</code></pre>"},{"location":"user_manual/user_manual/#web-api-integration","title":"Web API Integration","text":"<p>The serve API is perfect for web services and REST APIs:</p> <pre><code>from fastapi import FastAPI, UploadFile\nfrom culicidaelab.serve import serve\nimport json\n\napp = FastAPI()\n\n@app.post(\"/predict/{predictor_type}\")\nasync def predict(predictor_type: str, file: UploadFile):\n    # Read uploaded image\n    image_bytes = await file.read()\n\n    # Run prediction using serve API\n    result = serve(image_bytes, predictor_type=predictor_type)\n\n    # Return structured JSON response\n    return json.loads(result.model_dump_json())\n\n@app.on_event(\"shutdown\")\nasync def shutdown():\n    clear_serve_cache()\n</code></pre>"},{"location":"user_manual/user_manual/#62-utility-functions-for-discovery","title":"6.2. Utility Functions for Discovery","text":"<p>CulicidaeLab provides utility functions to programmatically discover available models and datasets:</p> <pre><code>from culicidaelab import list_models, list_datasets\n\n# Discover available models\navailable_models = list_models()\nprint(\"Available models:\")\nfor model in available_models:\n    print(f\"  - {model}\")\n\n# Discover available datasets\navailable_datasets = list_datasets()\nprint(\"\\nAvailable datasets:\")\nfor dataset in available_datasets:\n    print(f\"  - {dataset}\")\n</code></pre>"},{"location":"user_manual/user_manual/#63-memory-management-and-context-managers","title":"6.3. Memory Management and Context Managers","text":"<p>For memory-efficient processing, use context managers to automatically load and unload models:</p> <pre><code># Temporary model loading - automatically unloads after use\nwith classifier.model_context():\n    result = classifier.predict(image_rgb)\n    # Process result here\n# Model automatically unloaded after context\n\n# Batch processing with automatic cleanup\nimages = [\"img1.jpg\", \"img2.jpg\", \"img3.jpg\"]\nresults = []\n\nwith classifier.model_context():\n    for image_path in images:\n        result = classifier.predict(image_path)\n        results.append(result)\n# Model unloaded after processing all images\n</code></pre>"},{"location":"user_manual/user_manual/#64-batch-processing-and-evaluation","title":"6.4. Batch Processing and Evaluation","text":"<p>For advanced users who need to process large datasets or assess model performance, each predictor supports enhanced batch operations:</p>"},{"location":"user_manual/user_manual/#enhanced-batch-processing","title":"Enhanced Batch Processing","text":"<pre><code># Batch processing with progress tracking\nimages = [image1, image2, image3, ...]  # List of images\nresults = classifier.predict_batch(\n    input_data_batch=images,\n    show_progress=True  # Shows progress bar\n)\n\n# Process results\nfor i, result in enumerate(results):\n    top_pred = result.top_prediction()\n    print(f\"Image {i+1}: {top_pred.species_name} ({top_pred.confidence:.2%})\")\n</code></pre>"},{"location":"user_manual/user_manual/#model-evaluation","title":"Model Evaluation","text":"<pre><code># Evaluate model performance against ground truth\nground_truths = [\"species1\", \"species2\", \"species3\", ...]  # True labels\n\nevaluation_report = classifier.evaluate_batch(\n    input_data_batch=images,\n    ground_truth_batch=ground_truths,\n    show_progress=True\n)\n\n# Display evaluation metrics\nprint(\"\\nEvaluation Results:\")\nfor metric, value in evaluation_report.items():\n    if isinstance(value, float):\n        print(f\"  {metric}: {value:.4f}\")\n    else:\n        print(f\"  {metric}: {value}\")\n\n# Visualize confusion matrix and metrics\nclassifier.visualize_report(evaluation_report)\n</code></pre>"},{"location":"user_manual/user_manual/#65-production-deployment-best-practices","title":"6.5. Production Deployment Best Practices","text":""},{"location":"user_manual/user_manual/#resource-management","title":"Resource Management","text":"<ul> <li>Use <code>clear_serve_cache()</code> to free GPU memory when switching between different predictor types</li> <li>Implement proper error handling for production environments</li> <li>Monitor memory usage in long-running applications</li> </ul>"},{"location":"user_manual/user_manual/#performance-optimization","title":"Performance Optimization","text":"<ul> <li>Use the serve API for production deployments</li> <li>Batch process multiple images when possible</li> <li>Consider using context managers for temporary model loading</li> </ul>"},{"location":"user_manual/user_manual/#scalability","title":"Scalability","text":"<ul> <li>The serve API's caching mechanism makes it ideal for web services</li> <li>Structured outputs are JSON-serializable for easy API responses</li> <li>ONNX backends provide consistent performance across different hardware</li> </ul> <p>For more detailed information about advanced features, deployment strategies, and API reference, please refer to the complete documentation and explore the code examples provided in the repository.</p>"}]}