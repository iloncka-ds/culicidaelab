# Краткое руководство

Это руководство поможет вам пройти путь от нуля до вашей первой классификации комара менее чем за пять минут. Мы рассмотрим один полный пример кода, который вы можете скопировать, вставить и запустить, чтобы увидеть `CulicidaeLab` в действии.

Пример покажет вам, как:

1.  Инициализировать библиотеку с помощью центрального объекта `settings`.
2.  Загрузить изображение комара.
3.  Запустить `MosquitoClassifier` для предсказания его вида.
4.  Визуализировать результат.

### Предварительные требования

Перед запуском кода у вас должно быть:

1.  **Установлен `CulicidaeLab`**. Если вы еще не установили его, пожалуйста, следуйте **[Руководству по установке](./installation.md)**.
2.  **Тестовое изображение**. Создайте папку с именем `test_imgs` в корневом каталоге вашего проекта. Поместите в нее изображение комара и назовите его `mosquito.jpg`.

Структура вашего проекта должна выглядеть так:
```
ваш_проект/
├── test_imgs/
│   └── mosquito.jpg
└── ваш_скрипт.py
```

---

### Полный пример: от изображения до классификации

Скопируйте блок кода ниже в ваш скрипт Python или Jupyter Notebook и запустите его. Библиотека автоматически загрузит и закэширует необходимую модель при первом запуске.

```python
# 1. Импорты: Получаем все необходимые инструменты
import cv2
import matplotlib.pyplot as plt
from pathlib import Path

# Импортируем основную точку входа и классификатор из CulicidaeLab
from culicidaelab import get_settings
from culicidaelab.predictors import MosquitoClassifier

# --- Основной скрипт ---

# 2. Инициализация: Настраиваем библиотеку и классификатор
print("Инициализация CulicidaeLab...")
# Получаем центральный объект настроек, который управляет всеми конфигурациями.
settings = get_settings()
# Просим объект настроек создать классификатор. Это рекомендуемый способ.
classifier = MosquitoClassifier(settings=settings)
print("Классификатор готов.")


# 3. Загрузка изображения: Подготавливаем данные для предсказания
print("Загрузка изображения...")
image_path = Path("test_imgs") / "mosquito.jpg"
try:
    # Используем OpenCV для чтения файла изображения
    image = cv2.imread(str(image_path))
    # Библиотека ожидает изображения в формате RGB, поэтому мы конвертируем из формата BGR по умолчанию в OpenCV
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    print("Изображение успешно загружено.")
except Exception as e:
    print(f"Ошибка: Не удалось загрузить изображение из {image_path}.")
    print("Пожалуйста, убедитесь, что файл существует и путь указан верно.")
    exit()


# 4. Выполнение предсказания: Получаем результат классификации
print("Выполнение предсказания...")
# Менеджер `model_context()` эффективно управляет загрузкой/выгрузкой модели из памяти.
with classifier.model_context():
    predictions = classifier.predict(image_rgb)
print("Предсказание завершено.")

# Объект `predictions` представляет собой список кортежей (имя_вида, оценка_уверенности),
# отсортированный от наиболее к наименее вероятному.
top_prediction = predictions[0]
print(f"\n---> Лучший результат: {top_prediction[0]} (Уверенность: {top_prediction[1]:.2%})")


# 5. Визуализация результата: Просматриваем предсказание на изображении
print("\nВизуализация результата...")
# Метод `.visualize()` наносит лучшие предсказания непосредственно на изображение.
with classifier.model_context():
    annotated_image = classifier.visualize(image_rgb, predictions)

# Отображаем исходное и аннотированное изображения рядом для сравнения
plt.figure(figsize=(15, 7))

plt.subplot(1, 2, 1)
plt.imshow(image_rgb)
plt.title("Исходное изображение")
plt.axis("off")

plt.subplot(1, 2, 2)
plt.imshow(annotated_image)
plt.title("Результат классификации")
plt.axis("off")

plt.tight_layout()
plt.show()
print("Готово!")
```
