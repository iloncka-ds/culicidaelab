{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# CulicidaeLab Datasets Module Example\n\nThis notebook demonstrates how to use the datasets module in CulicidaeLab.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Third-party imports\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nimport numpy as np\nimport requests\n\nfrom datasets import load_dataset\nfrom collections import defaultdict\n\nfrom culicidaelab.core.settings import get_settings\nfrom culicidaelab.core.provider_service import ProviderService\nfrom culicidaelab.datasets.datasets_manager import DatasetsManager"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- 1. Initializing DatasetsManager ---\")\nsettings = get_settings()\nprovider_service = ProviderService(settings)\nmanager = DatasetsManager(settings, provider_service)\nprint(\"DatasetsManager initialized successfully.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- 2. Listing all available datasets ---\")\navailable_datasets = manager.list_datasets()\nprint(f\"Available datasets found in configuration: {available_datasets}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- 3. Getting info for 'classification' dataset ---\")\ntry:\n    info = manager.get_dataset_info(\"classification\")\n    print(f\"  - Name: {info.name}\")\n    print(f\"  - Path/ID: {info.path}\")\n    print(f\"  - Provider: {info.provider_name}\")\n    print(f\"  - Classes: {info.classes}\")\nexcept KeyError as e:\n    print(e)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- 4. Loading 'classification' dataset for the first time ---\")\nprint(\"This will trigger the provider to 'download' and then 'load' the data.\")\nclassification_data = manager.load_dataset(\"classification\", split=\"test\")\nprint(\"\\nDataset loaded successfully!\")\nprint(f\"Returned data: {classification_data}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "print(\"\\n--- 5. Listing currently loaded (cached) datasets ---\")\nloaded_list = manager.list_loaded_datasets()\nprint(f\"Manager reports these datasets are loaded: {loaded_list}\")\nprint(f\"Internal cache state: {manager.loaded_datasets}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Define the dataset name\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_name = \"iloncka/mosquito-species-classification-dataset\"\nAPI_URL = f\"https://datasets-server.huggingface.co/croissant-crumbs?dataset={dataset_name}\"\n\n\ndef get_metadata(dataset_name):\n    \"\"\"Fetch metadata for a given dataset from Hugging Face.\"\"\"\n    api_url = f\"https://datasets-server.huggingface.co/croissant-crumbs?dataset={dataset_name}\"\n    response = requests.get(api_url, timeout=10)\n    response.raise_for_status()\n    return response.json()\n\n\nmetadata = get_metadata(dataset_name)\nprint(metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset = load_dataset(\n    \"iloncka/mosquito-species-classification-dataset\",\n    split=\"test\",\n)  # , streaming=True, trust_remote_code=True\ndataset_head = dataset.take(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "set(dataset[\"label\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Specify the dataset, config, and split you want to query\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "dataset_name = \"iloncka/mosquito-species-classification-dataset\"  # e.g., \"nyu-mll/glue\"\nconfig_name = \"default\"  # e.g., \"cola\"\nsplit_name = \"test\"  # e.g., \"train\", \"validation\"\n\n# Construct the API URL\nAPI_URL = (\n    f\"https://datasets-server.huggingface.co/statistics?dataset={dataset_name}&config={config_name}&split={split_name}\"\n)\n\n\n# Function to query the API\ndef query():\n    response = requests.get(API_URL, timeout=10)\n    return response.json()\n\n\n# Fetch and print unique labels\ndataset_info = query()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def get_dataset_summary(dataset_name, dataset_info):\n    \"\"\"\n    Generate a summary of dataset information from the dataset statistics.\n\n    Parameters:\n    -----------\n    dataset_info : dict\n        Dictionary containing dataset statistics and information\n\n    Returns:\n    --------\n    dict\n        Organized summary of the dataset\n    \"\"\"\n    summary = {\n        \"dataset_name\": dataset_name,\n        \"total_samples\": dataset_info[\"num_examples\"],\n        \"columns\": {},\n        \"label_distribution\": None,\n        \"image_info\": None,\n    }\n\n    # Process each column's statistics\n    for column in dataset_info[\"statistics\"]:\n        col_name = column[\"column_name\"]\n        col_type = column[\"column_type\"]\n        stats = column[\"column_statistics\"]\n\n        # Special handling for label column\n        if col_type == \"string_label\":\n            summary[\"label_distribution\"] = {\n                \"num_classes\": stats[\"n_unique\"],\n                \"class_distribution\": stats[\"frequencies\"],\n            }\n\n        # Special handling for image column\n        elif col_type == \"image\":\n            summary[\"image_info\"] = {\n                \"dimensions\": f\"{int(stats['min'])}x{int(stats['max'])}\",\n                \"num_images\": dataset_info[\"num_examples\"],\n            }\n\n        # Store basic column information\n        summary[\"columns\"][col_name] = {\n            \"type\": col_type,\n            \"missing_values\": {\n                \"count\": stats.get(\"nan_count\", 0),\n                \"percentage\": stats.get(\"nan_proportion\", 0) * 100,\n            },\n        }\n\n        # Add additional statistics if available\n        if \"mean\" in stats:\n            summary[\"columns\"][col_name][\"statistics\"] = {\n                \"mean\": stats[\"mean\"],\n                \"std\": stats[\"std\"],\n                \"min\": stats[\"min\"],\n                \"max\": stats[\"max\"],\n            }\n\n    return summary\n\n\n# Print summary in a readable format\ndef print_dataset_summary(summary):\n    print(f\"Dataset Summary {summary['dataset_name']}:\")\n    print(f\"Total samples: {summary['total_samples']}\")\n    print(\"\\nImage Information:\")\n    if summary[\"image_info\"]:\n        print(f\"Dimensions: {summary['image_info']['dimensions']}\")\n        print(f\"Number of images: {summary['image_info']['num_images']}\")\n\n    print(\"\\nLabel Distribution:\")\n    if summary[\"label_distribution\"]:\n        print(f\"Number of classes: {summary['label_distribution']['num_classes']}\")\n        print(\"\\nSamples per class:\")\n        for class_name, count in summary[\"label_distribution\"][\"class_distribution\"].items():\n            print(f\"  {class_name}: {count}\")\n\n    print(\"\\nColumns:\")\n    for col_name, col_info in summary[\"columns\"].items():\n        print(f\"\\n{col_name}:\")\n        print(f\"  Type: {col_info['type']}\")\n        # Print missing values info, keeping line length <= 120\n        missing_count = col_info[\"missing_values\"][\"count\"]\n        missing_pct = col_info[\"missing_values\"][\"percentage\"]\n        print(f\"  Missing values: {missing_count} ({missing_pct:.2f}%)\")\n        if \"statistics\" in col_info:\n            print(\"  Statistics:\")\n            print(f\"    Mean: {col_info['statistics']['mean']:.2f}\")\n            print(f\"    Std: {col_info['statistics']['std']:.2f}\")\n            print(f\"    Min: {col_info['statistics']['min']}\")\n            print(f\"    Max: {col_info['statistics']['max']}\")\n\n\n# Example usage:\nsummary = get_dataset_summary(\n    dataset_name,\n    dataset_info,\n)  # Replace dataset_info with your response\n\n# Print the summary\nprint_dataset_summary(summary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def find_min_max_classes(dataset_info):\n    \"\"\"\n    Find classes with minimum and maximum number of samples in the dataset.\n\n    Parameters:\n    -----------\n    dataset_info : dict\n        Dictionary containing dataset statistics and information\n\n    Returns:\n    --------\n    dict\n        Information about minimum and maximum classes\n    \"\"\"\n    # Get the label frequencies from the statistics\n    label_stats = None\n    for column in dataset_info[\"statistics\"]:\n        if column[\"column_type\"] == \"string_label\":\n            label_stats = column[\"column_statistics\"][\"frequencies\"]\n            break\n\n    if not label_stats:\n        return None\n\n    # Find min and max classes\n    min_class = min(label_stats.items(), key=lambda x: x[1])\n    max_class = max(label_stats.items(), key=lambda x: x[1])\n\n    result = {\n        \"minimum\": {\"class_name\": min_class[0], \"sample_count\": min_class[1]},\n        \"maximum\": {\"class_name\": max_class[0], \"sample_count\": max_class[1]},\n        \"difference\": max_class[1] - min_class[1],\n    }\n\n    return result\n\n\n# Example usage:\nmin_max_info = find_min_max_classes(\n    dataset_info,\n)  # Replace dataset_info with your response\n\n# Print the results in a readable format\nif min_max_info:\n    print(\"Class Distribution Analysis:\")\n    print(\"\\nMinimum samples per class:\")\n    print(f\"  Class: {min_max_info['minimum']['class_name']}\")\n    print(f\"  Count: {min_max_info['minimum']['sample_count']} samples\")\n\n    print(\"\\nMaximum samples per class:\")\n    print(f\"  Class: {min_max_info['maximum']['class_name']}\")\n    print(f\"  Count: {min_max_info['maximum']['sample_count']} samples\")\n\n    print(f\"\\nDifference between max and min: {min_max_info['difference']} samples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def create_distribution_plot(\n    dataset,\n    dataset_info,\n    color=\"green\",\n    figsize=(15, 10),\n    output_file=\"class_distribution.png\",\n):\n    \"\"\"\n    Create a horizontal bar plot of class distribution.\n\n    Parameters:\n    -----------\n    dataset : HuggingFace IterableDataset\n        The dataset containing images and labels\n    dataset_info : dict\n        Dictionary containing dataset statistics and information\n    figsize : tuple, default=(15, 10)\n        Figure size (width, height)\n    output_file : str, default='class_distribution.png'\n        Output file name\n    \"\"\"\n    # Get label frequencies from dataset_info\n    label_stats = None\n    for column in dataset_info[\"statistics\"]:\n        if column[\"column_type\"] == \"string_label\":\n            label_stats = column[\"column_statistics\"][\"frequencies\"]\n            break\n\n    if not label_stats:\n        print(\"No label statistics found in dataset_info\")\n        return\n\n    # Sort classes by sample count\n    sorted_items = sorted(label_stats.items(), key=lambda x: x[1], reverse=True)\n    classes, counts = zip(*sorted_items)\n\n    # Create figure with custom size\n    _, ax = plt.subplots(figsize=figsize)\n\n    # Create horizontal bars\n    y_pos = np.arange(len(classes))\n    ax.barh(y_pos, counts, align=\"center\", color=color, alpha=0.8)\n\n    # Customize the plot\n    ax.set_yticks(y_pos)\n    # Format class names by replacing underscores with spaces and capitalize\n    formatted_classes = [c.replace(\"_\", \" \").title() for c in classes]\n    ax.set_yticklabels(formatted_classes, fontsize=16)\n\n    # Add value labels on the bars\n    for i, v in enumerate(counts):\n        ax.text(v + 0.5, i, str(v), va=\"center\", fontsize=20)\n\n    # Add title and labels\n    plt.title(\"Distribution of Mosquito Species in Dataset\", pad=20, fontsize=18)\n    plt.xlabel(\"Number of Samples\", fontsize=14)\n\n    # Adjust layout to prevent label cutoff\n    plt.tight_layout()\n\n    # Save the plot\n    plt.savefig(output_file, dpi=300, bbox_inches=\"tight\")\n    print(f\"Distribution plot saved as {output_file}\")\n\n    # Display the plot\n    plt.show()\n\n\n# Example usage - create both plots\ncreate_distribution_plot(dataset, dataset_info)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def create_tree_visualization(\n    dataset_info,\n    figsize=(15, 10),\n    output_file=\"tree_distribution.png\",\n):\n    \"\"\"\n    Create a tree-like visualization with branch lengths proportional to species count.\n    \"\"\"\n    # Get label frequencies from dataset_info\n    label_stats = None\n    for column in dataset_info[\"statistics\"]:\n        if column[\"column_type\"] == \"string_label\":\n            label_stats = column[\"column_statistics\"][\"frequencies\"]\n            break\n\n    if not label_stats:\n        print(\"No label statistics found in dataset_info\")\n        return\n\n    # Group species by genus\n    genus_groups = defaultdict(list)\n    genus_totals = defaultdict(int)\n\n    for species, count in label_stats.items():\n        genus = species.split(\"_\")[0]\n        genus_groups[genus].append((species, count))\n        genus_totals[genus] += count\n\n    # Sort genera by total count\n    sorted_genera = sorted(genus_totals.items(), key=lambda x: x[1], reverse=True)\n\n    # Create figure\n    fig, ax = plt.subplots(figsize=figsize)\n\n    # Calculate scaling factors\n    max_count = max(label_stats.values())\n    min_count = min(label_stats.values())\n    max_genus_count = max(genus_totals.values())\n    min_genus_count = min(genus_totals.values())\n\n    # Calculate positions\n    total_species = sum(len(group) for group in genus_groups.values())\n    y_positions = np.linspace(0.1, 0.9, total_species)\n    trunk_x = 0.15  # Position of main vertical line\n    max_branch_length = 0.4  # Maximum branch length\n\n    current_y_index = 0\n    text_offset = 0.02\n\n    # Color map for genera\n    colors = plt.cm.tab20(np.linspace(0, 1, len(genus_groups)))\n\n    # Draw main trunk segments between genera\n    # Draw main trunk segments between genera\n    # prev_end removed (was unused)\n    for (genus, _), color in zip(sorted_genera, colors):\n        species_count = len(genus_groups[genus])\n        start_y = y_positions[current_y_index]\n        end_y = y_positions[current_y_index + species_count - 1]\n\n        # Draw main trunk segment for this genus\n        ax.plot([trunk_x, trunk_x], [start_y, end_y], color=\"k\", linewidth=3)\n\n        # prev_end = end_y  # Removed unused variable\n        current_y_index += species_count\n\n    # Reset current_y_index for species drawing\n    current_y_index = 0\n\n    # Draw branches for each genus\n    for (genus, total_count), color in zip(sorted_genera, colors):\n        species_list = genus_groups[genus]\n        species_count = len(species_list)\n\n        # Calculate genus branch position and length\n        genus_y = np.mean(\n            y_positions[current_y_index : current_y_index + species_count],\n        )\n        genus_branch_length = 0.02  # Fixed length for genus branches\n\n        # Calculate line thickness based on count\n        thickness = 1 + 3 * (total_count - min_genus_count) / (max_genus_count - min_genus_count)\n\n        # Draw genus branch\n        ax.plot(\n            [trunk_x, trunk_x + genus_branch_length],\n            [genus_y, genus_y],\n            \"-\",\n            color=color,\n            linewidth=thickness,\n        )\n\n        # Add genus name\n        ax.text(\n            trunk_x - 0.02,\n            genus_y,\n            f\"{genus.title()}\\n({total_count} total)\",\n            horizontalalignment=\"right\",\n            verticalalignment=\"center\",\n            fontsize=18,\n            fontweight=\"bold\",\n        )\n\n        # Draw vertical connector for species\n        if species_count > 1:\n            ax.plot(\n                [trunk_x + genus_branch_length, trunk_x + genus_branch_length],\n                [\n                    y_positions[current_y_index],\n                    y_positions[current_y_index + species_count - 1],\n                ],\n                \"-\",\n                color=color,\n                linewidth=1,\n                alpha=1,\n            )\n\n        # Draw species branches\n        for i, (species, count) in enumerate(\n            sorted(species_list, key=lambda x: x[1], reverse=True),\n        ):\n            y_pos = y_positions[current_y_index + i]\n\n            # Calculate species branch length based on count\n            species_branch_length = max_branch_length * 0.5 * (count - min_count) / (max_count - min_count)\n\n            # Draw species branch\n            species_thickness = 0.5 + 2 * (count - min_count) / (max_count - min_count)\n            ax.plot(\n                [\n                    trunk_x + genus_branch_length,\n                    trunk_x + genus_branch_length + species_branch_length,\n                ],\n                [y_pos, y_pos],\n                \"-\",\n                color=color,\n                linewidth=species_thickness,\n            )\n\n            # Add species name with genus\n            species_name = species.replace(\n                \"_\",\n                \" \",\n            ).title()  # Include full name with genus\n            ax.text(\n                trunk_x + genus_branch_length + species_branch_length + text_offset,\n                y_pos,\n                f\"{species_name} ({count})\",\n                verticalalignment=\"center\",\n                fontsize=16,\n            )\n\n        current_y_index += species_count\n\n    # Customize the plot\n    ax.set_xlim(0, 1)\n    ax.set_ylim(0, 1)\n    ax.axis(\"off\")\n\n    # Add title\n    plt.suptitle(\n        \"Mosquito Species Distribution by Genus and Species\",\n        y=0.95,\n        fontsize=18,\n    )\n\n    # Add total samples count and legend\n    total_samples = sum(label_stats.values())\n    plt.figtext(\n        0.02,\n        0.02,\n        f\"Total samples: {total_samples}\\n\"\n        f\"Number of genera: {len(genus_groups)}\\n\"\n        f\"Number of species: {len(label_stats)}\\n\"\n        f\"Branch length \u221d sample count\",\n        fontsize=18,\n    )\n\n    # Save the plot\n    plt.savefig(output_file, dpi=300, bbox_inches=\"tight\")\n    print(f\"Tree visualization saved as {output_file}\")\n\n    # Display the plot\n    plt.show()\n\n\n# Example usage\ncreate_tree_visualization(dataset_info)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
